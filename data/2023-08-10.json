[{"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial intelligence is bringing ever new functionalities to the realm ofmobile devices that are now considered essential (e.g., camera and voiceassistants, recommender systems). Yet, operating artificial intelligence takesup a substantial amount of energy. However, artificial intelligence is alsobeing used to enable more energy-efficient solutions for mobile systems. Hence,artificial intelligence has two faces in that regard, it is both a key enablerof desired (efficient) mobile functionalities and a major power draw on thesedevices, playing a part in both the solution and the problem. In this paper, wepresent a review of the literature of the past decade on the usage ofartificial intelligence within the realm of green mobile computing. From theanalysis of 34 papers, we highlight the emerging patterns and map the fieldinto 13 main topics that are summarized in details.Our results showcase that the field is slowly increasing in the past years,more specifically, since 2019. Regarding the double impact AI has on the mobileenergy consumption, the energy consumption of AI-based mobile systems isunder-studied in comparison to the usage of AI for energy-efficient mobilecomputing, and we argue for more exploratory studies in that direction. Weobserve that although most studies are framed as solution papers (94%), thelarge majority do not make those solutions publicly available to the community.Moreover, we also show that most contributions are purely academic (28 out of34 papers) and that we need to promote the involvement of the mobile softwareindustry in this field.", "output": "The Two Faces of AI in Green Mobile Computing: A Literature Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Does artificial intelligence (AI) pose existential risks to humanity? Somecritics feel this question is getting too much attention, and want to push itaside in favour of conversations about the immediate risks of AI. These criticsnow include the journal Nature, where a recent editorial urges us to 'stoptalking about tomorrow's AI doomsday when AI poses risks today.' We argue thatthis is a serious failure of judgement, on Nature's part. In science, as ineveryday life, we expect influential actors to consider the consequences oferror. As the world's leading scientific journal, Nature is certainly aninfluential actor, especially so in the absence of robust global regulation ofAI. Yet it has manifestly failed to consider the cost of error in this case.", "output": "Nature and the Machines."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning is a distributed mechanism that trained large-scale neuralnetwork models with the participation of multiple clients and data remains ontheir devices, only sharing the local model updates. With this feature,federated learning is considered a secure solution for data privacy issues.However, the typical FL structure relies on the client-server, which leads tothe single-point-of-failure (SPoF) attack, and the random selection of clientsfor model training compromised the model accuracy. Furthermore, adversaries tryfor inference attacks i.e., attack on privacy leads to gradient leakageattacks. We proposed the blockchain-based optimized client selection andprivacy-preserved framework in this context. We designed the three kinds ofsmart contracts such as 1) registration of clients 2) forward bidding to selectoptimized clients for FL model training 3) payment settlement and reward smartcontracts. Moreover, fully homomorphic encryption with Cheon, Kim, Kim, andSong (CKKS) method is implemented before transmitting the local model updatesto the server. Finally, we evaluated our proposed method on the benchmarkdataset and compared it with state-of-the-art studies. Consequently, weachieved a higher accuracy rate and privacy-preserved FL framework withdecentralized nature.", "output": "Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative AI, the most popular current approach to AI, consists of largelanguage models (LLMs) that are trained to produce outputs that are plausible,but not necessarily correct. Although their abilities are often uncanny, theyare lacking in aspects of reasoning, leading LLMs to be less than completelytrustworthy. Furthermore, their results tend to be both unpredictable anduninterpretable.We lay out 16 desiderata for future AI, and discuss an alternative approachto AI which could theoretically address many of the limitations associated withcurrent approaches: AI educated with curated pieces of explicit knowledge andrules of thumb, enabling an inference engine to automatically deduce thelogical entailments of all that knowledge. Even long arguments produced thisway can be both trustworthy and interpretable, since the full step-by-step lineof reasoning is always available, and for each step the provenance of theknowledge used can be documented and audited. There is however a catch: if thelogical language is expressive enough to fully represent the meaning ofanything we can say in English, then the inference engine runs much too slowly.That's why symbolic AI systems typically settle for some fast but much lessexpressive logic, such as knowledge graphs. We describe how one AI system, Cyc,has developed ways to overcome that tradeoff and is able to reason in higherorder logic in real time.We suggest that any trustworthy general AI will need to hybridize theapproaches, the LLM approach and more formal approach, and lay out a path torealizing that dream.", "output": "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative Artificial Intelligence (AI) has seen mainstream adoption lately,especially in the form of consumer-facing, open-ended, text and imagegenerating models. However, the use of such systems raises significant ethicaland safety concerns, including privacy violations, misinformation andintellectual property theft. The potential for generative AI to displace humancreativity and livelihoods has also been under intense scrutiny. To mitigatethese risks, there is an urgent need of policies and regulations responsibleand ethical development in the field of generative AI. Existing and proposedcentralized regulations by governments to rein in AI face criticisms such asnot having sufficient clarity or uniformity, lack of interoperability acrosslines of jurisdictions, restricting innovation, and hindering free marketcompetition. Decentralized protections via crowdsourced safety tools andmechanisms are a potential alternative. However, they have clear deficienciesin terms of lack of adequacy of oversight and difficulty of enforcement ofethical and safety standards, and are thus not enough by themselves as aregulation mechanism. We propose a marriage of these two strategies via aframework we call Dual Governance. This framework proposes a cooperativesynergy between centralized government regulations in a U.S. specific contextand safety mechanisms developed by the community to protect stakeholders fromthe harms of generative AI. By implementing the Dual Governance framework, weposit that innovation and creativity can be promoted while ensuring safe andethical deployment of generative AI.", "output": "Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we assess the security of AI code generators via datapoisoning, i.e., an attack that injects malicious samples into the trainingdata to generate vulnerable code. We poison the training data by injectingincreasing amounts of code containing security vulnerabilities and assess theattack's success on different state-of-the-art models for code generation. Ouranalysis shows that AI code generators are vulnerable to even a small amount ofdata poisoning. Moreover, the attack does not impact the correctness of codegenerated by pre-trained models, making it hard to detect.", "output": "Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The growing use of voice user interfaces has led to a surge in the collectionand storage of speech data. While data collection allows for the development ofefficient tools powering most speech services, it also poses serious privacyissues for users as centralized storage makes private personal speech datavulnerable to cyber threats. With the increasing use of voice-based digitalassistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with theincreasing ease with which personal speech data can be collected, the risk ofmalicious use of voice-cloning and speaker/gender/pathological/etc. recognitionhas increased.This thesis proposes solutions for anonymizing speech and evaluating thedegree of the anonymization. In this work, anonymization refers to makingpersonal speech data unlinkable to an identity while maintaining the usefulness(utility) of the speech signal (e.g., access to linguistic content). We startby identifying several challenges that evaluation protocols need to consider toevaluate the degree of privacy protection properly. We clarify howanonymization systems must be configured for evaluation purposes and highlightthat many practical deployment configurations do not permit privacy evaluation.Furthermore, we study and examine the most common voice conversion-basedanonymization system and identify its weak points before suggesting new methodsto overcome some limitations. We isolate all components of the anonymizationsystem to evaluate the degree of speaker PPI associated with each of them.Then, we propose several transformation methods for each component to reduce asmuch as possible speaker PPI while maintaining utility. We promoteanonymization algorithms based on quantization-based transformation as analternative to the most-used and well-known noise-based approach. Finally, weendeavor a new attack method to invert anonymization.", "output": "Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical insurance claims are of organized crimes related to patients,physicians, diagnostic centers, and insurance providers, forming a chainreaction that must be monitored constantly. These kinds of frauds affect thefinancial growth of both insured people and health insurance companies. TheConvolution Neural Network architecture is used to detect fraudulent claimsthrough a correlation study of regression models, which helps to detect moneylaundering on different claims given by different providers. Supervised andunsupervised classifiers are used to detect fraud and non-fraud claims.", "output": "Correlating Medi- Claim Service by Deep Learning Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large Language Models (LLMs) are advanced Artificial Intelligence (AI)systems that have undergone extensive training using large datasets in order tounderstand and produce language that closely resembles that of humans. Thesemodels have reached a level of proficiency where they are capable ofsuccessfully completing university exams across several disciplines andgenerating functional code to handle novel problems. This research investigatesthe coding proficiency of ChatGPT 3.5, a LLM released by OpenAI in November2022, which has gained significant recognition for its impressive textgenerating and code creation capabilities. The skill of the model in creatingcode snippets is evaluated across 10 various programming languages and 4different software domains. Based on the findings derived from this research,major unexpected behaviors and limitations of the model have been identified.This study aims to identify potential areas for development and examine theramifications of automated code generation on the evolution of programminglanguages and on the tech industry.", "output": "A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, large language models (LLMs) fine-tuned to follow human instructionhave exhibited significant capabilities in various English NLP tasks. However,their performance in grammatical error correction (GEC) tasks, particularly innon-English languages, remains significantly unexplored. In this paper, wedelve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task madecomplex due to Arabic's rich morphology. Our findings suggest that variousprompting methods, coupled with (in-context) few-shot learning, demonstrateconsiderable effectiveness, with GPT-4 achieving up to $65.49$Ftextsubscript{1} score under expert prompting (approximately $5$ pointshigher than our established baseline). This highlights the potential of LLMs inlow-resource settings, offering a viable approach for generating usefulsynthetic data for model training. Despite these positive results, we find thatinstruction fine-tuned models, regardless of their size, significantlyunderperform compared to fully fine-tuned models of significantly smallersizes. This disparity highlights a substantial room for improvements for LLMs.Inspired by methods from low-resource machine translation, we also develop amethod exploiting synthetic data that significantly outperforms previous modelson two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with$72.19%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.", "output": "ChatGPT for Arabic Grammatical Error Correction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Arctic amplification has altered the climate patterns both regionally andglobally, resulting in more frequent and more intense extreme weather events inthe past few decades. The essential part of Arctic amplification is theunprecedented sea ice loss as demonstrated by satellite observations.Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales hasbeen a major research question with fundamental challenges at play. In additionto physics-based Earth system models, researchers have been applying multiplestatistical and machine learning models for sea ice forecasting. Looking at thepotential of data-driven approaches to study sea ice variations, we proposeMT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning modelfor forecasting Arctic sea ice concentration (SIC). The model uses anencoder-decoder architecture with skip connections and processes multi-temporalinput streams to regenerate spatial maps at future timesteps. Using bi-monthlyand monthly satellite retrieved sea ice data from NSIDC as well as atmosphericand oceanic variables from ERA5 reanalysis product during 1979-2021, we showthat our proposed model provides promising predictive performance for per-pixelSIC forecasting with up to 60% decrease in prediction error for a lead time of6 months as compared to its state-of-the-art counterparts.", "output": "MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We demonstrate how to parse Geach's Donkey sentences in a compositionaldistributional model of meaning. We build on previous work on the DisCoCat(Distributional Compositional Categorical) framework, including extensions thatmodel discourse, determiners, and relative pronouns. We present a type-logicalsyntax for parsing donkey sentences, for which we define both relational andvector space semantics.", "output": "DisCoCat for Donkey Sentences."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Steganography and steganalysis are two interrelated aspects of the field ofinformation security. Steganography seeks to conceal communications, whereassteganalysis is aimed to either find them or even, if possible, recover thedata they contain. Steganography and steganalysis have attracted a great dealof interest, particularly from law enforcement. Steganography is often used bycybercriminals and even terrorists to avoid being captured while in possessionof incriminating evidence, even encrypted, since cryptography is prohibited orrestricted in many countries. Therefore, knowledge of cutting-edge techniquesto uncover concealed information is crucial in exposing illegal acts. Over thelast few years, a number of strong and reliable steganography and steganalysistechniques have been introduced in the literature. This review paper provides acomprehensive overview of deep learning-based steganalysis techniques used todetect hidden information within digital media. The paper covers all types ofcover in steganalysis, including image, audio, and video, and discusses themost commonly used deep learning techniques. In addition, the paper exploresthe use of more advanced deep learning techniques, such as deep transferlearning (DTL) and deep reinforcement learning (DRL), to enhance theperformance of steganalysis systems. The paper provides a systematic review ofrecent research in the field, including data sets and evaluation metrics usedin recent studies. It also presents a detailed analysis of DTL-basedsteganalysis approaches and their performance on different data sets. Thereview concludes with a discussion on the current state of deep learning-basedsteganalysis, challenges, and future research directions.", "output": "Deep Learning for Diverse Data Types Steganalysis: A Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Today, the great performance of Deep Neural Networks(DNN) has been proven invarious fields. One of its most attractive applications is to produce artisticdesigns. A carpet that is known as a piece of art is one of the most importantitems in a house, which has many enthusiasts all over the world. The firststage of producing a carpet is to prepare its map, which is a difficult,time-consuming, and expensive task. In this research work, our purpose is touse DNN for generating a Modern Persian Carpet Map. To reach this aim, threedifferent DNN style transfer methods are proposed and compared against eachother. In the proposed methods, the Style-Swap method is utilized to create theinitial carpet map, and in the following, to generate more diverse designs,methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition,some methods are examined and introduced for coloring the produced carpet maps.The designed maps are evaluated via the results of filled questionnaires wherethe outcomes of user evaluations confirm the popularity of generated carpetmaps. Eventually, for the first time, intelligent methods are used in producingcarpet maps, and it reduces human intervention. The proposed methods cansuccessfully produce diverse carpet designs, and at a higher speed thantraditional ways.", "output": "Generating Modern Persian Carpet Map by Style-transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to learn continuously from an incoming data stream withoutcatastrophic forgetting is critical to designing intelligent systems. Manyapproaches to continual learning rely on stochastic gradient descent and itsvariants that employ global error updates, and hence need to adopt strategiessuch as memory buffers or replay to circumvent its stability, greed, andshort-term memory limitations. To address this limitation, we have developed abiologically inspired lightweight neural network architecture that incorporatessynaptic plasticity mechanisms and neuromodulation and hence learns throughlocal error signals to enable online continual learning without stochasticgradient descent.Our approach leads to superior online continual learning performance onSplit-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to othermemory-constrained learning approaches and matches that of the state-of-the-artmemory-intensive replay-based approaches. We further demonstrate theeffectiveness of our approach by integrating key design concepts into otherbackpropagation-based continual learning algorithms, significantly improvingtheir accuracy. Our results provide compelling evidence for the importance ofincorporating biological principles into machine learning models and offerinsights into how we can leverage them to design more efficient and robustsystems for online continual learning.", "output": "Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although some current AIs surpass human abilities especially in closed worldssuch as board games, their performance in the messy real world is limited. Theymake strange mistakes and do not notice them. They cannot be instructed easily,fail to use common sense, and lack curiosity. They do not make goodcollaborators. Neither systems built using the traditional manually-constructedsymbolic AI approach nor systems built using generative and deep learning AIapproaches including large language models (LLMs) can meet the challenges. Theyare not well suited for creating robust and trustworthy AIs. Although it isoutside of mainstream AI approaches, developmental bootstrapping shows promise.In developmental bootstrapping, AIs develop competences like human children do.They start with innate competences. Like humans, they interact with theenvironment and learn from their interactions. They incrementally extend theirinnate competences with self-developed competences. They interact and learnfrom people and establish perceptual, cognitive, and common grounding.Following a bootstrapping process, they acquire the competences that they need.However, developmental robotics has not yet produced AIs with robustadult-level competences. Projects have typically stopped at the Toddler Barriercorresponding to human infant development at about two years of age, beforespeech is fluent. They also do not bridge the Reading Barrier, where they canskillfully and skeptically tap into the vast socially developed recordedinformation resources that power LLMs. The next competences in human cognitivedevelopment involve intrinsic motivation, imitation learning, imagination,coordination, and communication. This paper lays out the logic, prospects,gaps, and challenges for extending the practice of developmental bootstrappingto create robust and resilient AIs.", "output": "Developmental Bootstrapping of AIs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The emerging field of action prediction plays a vital role in variouscomputer vision applications such as autonomous driving, activity analysis andhuman-computer interaction. Despite significant advancements, accuratelypredicting future actions remains a challenging problem due to highdimensionality, complex dynamics and uncertainties inherent in video data.Traditional supervised approaches require large amounts of labelled data, whichis expensive and time-consuming to obtain. This paper introduces a novelself-supervised video strategy for enhancing action prediction inspired by DINO(self-distillation with no labels). The Temporal-DINO approach employs twomodels; a 'student' processing past frames; and a 'teacher' processing bothpast and future frames, enabling a broader temporal context. During training,the teacher guides the student to learn future context by only observing pastframes. The strategy is evaluated on ROAD dataset for the action predictiondownstream task using 3D-ResNet, Transformer, and LSTM architectures. Theexperimental results showcase significant improvements in predictionperformance across these architectures, with our method achieving an averageenhancement of 9.9% Precision Points (PP), highlighting its effectiveness inenhancing the backbones' capabilities of capturing long-term dependencies.Furthermore, our approach demonstrates efficiency regarding the pretrainingdataset size and the number of epochs required. This method overcomeslimitations present in other approaches, including considering various backbonearchitectures, addressing multiple prediction horizons, reducing reliance onhand-crafted augmentations, and streamlining the pretraining process into asingle stage. These findings highlight the potential of our approach in diversevideo-based tasks such as activity recognition, motion planning, and sceneunderstanding.", "output": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As large language models improve, there is increasing interest in techniquesthat leverage these models' capabilities to refine their own outputs. In thiswork, we introduce Shepherd, a language model specifically tuned to critiqueresponses and suggest refinements, extending beyond the capabilities of anuntuned model to identify diverse errors and provide suggestions to remedythem. At the core of our approach is a high quality feedback dataset, which wecurate from community feedback and human annotations. Even though Shepherd issmall (7B parameters), its critiques are either equivalent or preferred tothose from established models including ChatGPT. Using GPT-4 for evaluation,Shepherd reaches an average win-rate of 53-87% compared to competitivealternatives. In human evaluation, Shepherd strictly outperforms other modelsand on average closely ties with ChatGPT.", "output": "Shepherd: A Critic for Language Model Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a new cognitive model, acting as the main component of anAGI agent. The model is introduced in its mature intelligence state, and as anextension of previous models, DENN, and especially AKREM, by includingoperational models (frames/classes) and will. This model's core assumption isthat cognition is about operating on accumulated knowledge, with the guidanceof an appropriate will. Also, we assume that the actions, part of knowledge,are learning to be aligned with will, during the evolution phase that precedesthe mature intelligence state. In addition, this model is mainly based on theduality principle in every known intelligent aspect, such as exhibiting bothtop-down and bottom-up model learning, generalization verse specialization, andmore. Furthermore, a holistic approach is advocated for AGI designing, andcognition under constraints or efficiency is proposed, in the form ofreusability and simplicity. Finally, reaching this mature state is describedvia a cognitive evolution from infancy to adulthood, utilizing a consolidationprinciple. The final product of this cognitive model is a dynamic operationalmemory of models and instances. Lastly, some examples and preliminary ideas forthe evolution phase to reach the mature state are presented.", "output": "Model of models -- Part 1."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances with large language models (LLM) illustrate their diversecapabilities. We propose a novel algorithm, staged speculative decoding, toaccelerate LLM inference in small-batch, on-device scenarios. We address thelow arithmetic intensity of small-batch inference by improving upon previouswork in speculative decoding. First, we restructure the speculative batch as atree, which reduces generation costs and increases the expected tokens perbatch. Second, we add a second stage of speculative decoding. Taken together,we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-Lmodel while perfectly preserving output quality.", "output": "Accelerating LLM Inference with Staged Speculative Decoding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous conversational agents, i.e. chatbots, are becoming an increasinglycommon mechanism for enterprises to provide support to customers and partners.In order to rate chatbots, especially ones powered by Generative AI tools likeLarge Language Models (LLMs) we need to be able to accurately assess theirperformance. This is where chatbot benchmarking becomes important. In thispaper, we propose the use of a novel benchmark that we call the E2E (End toEnd) benchmark, and show how the E2E benchmark can be used to evaluate accuracyand usefulness of the answers provided by chatbots, especially ones powered byLLMs. We evaluate an example chatbot at different levels of sophisticationbased on both our E2E benchmark, as well as other available metrics commonlyused in the state of art, and observe that the proposed benchmark show betterresults compared to others. In addition, while some metrics proved to beunpredictable, the metric associated with the E2E benchmark, which uses cosinesimilarity performed well in evaluating chatbots. The performance of our bestmodels shows that there are several benefits of using the cosine similarityscore as a metric in the E2E benchmark.", "output": "Benchmarking LLM powered Chatbots: Methods and Metrics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Analyzing the pattern of semantic variation in long real-world texts such asbooks or transcripts is interesting from the stylistic, cognitive, andlinguistic perspectives. It is also useful for applications such as textsegmentation, document summarization, and detection of semantic novelty. Therecent emergence of several vector-space methods for sentence embedding hasmade such analysis feasible. However, this raises the issue of how consistentand meaningful the semantic representations produced by various methods are inthemselves. In this paper, we compare several recent sentence embedding methodsvia time-series of semantic similarity between successive sentences andmatrices of pairwise sentence similarity for multiple books of literature. Incontrast to previous work using target tasks and curated datasets to comparesentence embedding methods, our approach provides an evaluation of the methods'in the wild'. We find that most of the sentence embedding methods considereddo infer highly correlated patterns of semantic similarity in a given document,but show interesting differences.", "output": "A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative AI, in particular text-based \"foundation models\" (large modelstrained on a huge variety of information including the internet), can generatespeech that could be problematic under a wide range of liability regimes.Machine learning practitioners regularly \"red team\" models to identify andmitigate such problematic speech: from \"hallucinations\" falsely accusing peopleof serious misconduct to recipes for constructing an atomic bomb. A keyquestion is whether these red-teamed behaviors actually present any liabilityrisk for model creators and deployers under U.S. law, incentivizing investmentsin safety mechanisms. We examine three liability regimes, tying them to commonexamples of red-teamed model behaviors: defamation, speech integral to criminalconduct, and wrongful death. We find that any Section 230 immunity analysis ordownstream liability analysis is intimately wrapped up in the technical detailsof algorithm design. And there are many roadblocks to truly finding models (andtheir associated parties) liable for generated speech. We argue that AI shouldnot be categorically immune from liability in these scenarios and that ascourts grapple with the already fine-grained complexities of platformalgorithms, the technical details of generative AI loom above with thornierquestions. Courts and policymakers should think carefully about what technicaldesign incentives they create as they evaluate these issues.", "output": "Where's the Liability in Harmful AI Speech?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Compressed Neural Networks have the potential to enable deep learning acrossnew applications and smaller computational environments. However, understandingthe range of learning tasks in which such models can succeed is not wellstudied. In this work, we apply sparse and binary-weighted Transformers tomultivariate time series problems, showing that the lightweight models achieveaccuracy comparable to that of dense floating-point Transformers of the samestructure. Our model achieves favorable results across three time serieslearning tasks: classification, anomaly detection, and single-step forecasting.Additionally, to reduce the computational complexity of the attentionmechanism, we apply two modifications, which show little to no decline in modelperformance: 1) in the classification task, we apply a fixed mask to the query,key, and value activations, and 2) for forecasting and anomaly detection, whichrely on predicting outputs at a single point in time, we propose an attentionmask to allow computation only at the current time step. Together, eachcompression technique and attention modification substantially reduces thenumber of non-zero operations necessary in the Transformer. We measure thecomputational savings of our approach over a range of metrics includingparameter count, bit size, and floating point operation (FLOPs) count, showingup to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.", "output": "Sparse Binary Transformers for Multivariate Time Series Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "For prohibitively large-scale Travelling Salesman Problems (TSPs), existingalgorithms face big challenges in terms of both computational efficiency andsolution quality. To address this issue, we propose a hierarchicaldestroy-and-repair (HDR) approach, which attempts to improve an initialsolution by applying a series of carefully designed destroy-and-repairoperations. A key innovative concept is the hierarchical search framework,which recursively fixes partial edges and compresses the input instance into asmall-scale TSP under some equivalence guarantee. This neat search framework isable to deliver highly competitive solutions within a reasonable time. Faircomparisons based on nineteen famous large-scale instances (with 10,000 to10,000,000 cities) show that HDR is highly competitive against existingstate-of-the-art TSP algorithms, in terms of both efficiency and solutionquality. Notably, on two large instances with 3,162,278 and 10,000,000 cities,HDR breaks the world records (i.e., best-known results regardless ofcomputation time), which were previously achieved by LKH and its variants,while HDR is completely independent of LKH. Finally, ablation studies areperformed to certify the importance and validity of the hierarchical searchframework.", "output": "A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Brain-inspired Spiking Neural Networks (SNNs) have the characteristics ofevent-driven and high energy-efficient, which are different from traditionalArtificial Neural Networks (ANNs) when deployed on edge devices such asneuromorphic chips. Most previous work focuses on SNNs training strategies toimprove model performance and brings larger and deeper network architectures.It is difficult to deploy these complex networks on resource-limited edgedevices directly. To meet such demand, people compress SNNs very cautiously tobalance the performance and the computation efficiency. Existing compressionmethods either iteratively pruned SNNs using weights norm magnitude orformulated the problem as a sparse learning optimization. We propose animproved end-to-end Minimax optimization method for this sparse learningproblem to better balance the model performance and the computation efficiency.We also demonstrate that jointly applying compression and finetuning on SNNs isbetter than sequentially, especially for extreme compression ratios. Thecompressed SNN models achieved state-of-the-art (SOTA) performance on variousbenchmark datasets and architectures. Our code is available at", "output": "Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised learning (SSL) which leverages unlabeled datasets forpre-training powerful encoders has achieved significant success in recentyears. These encoders are commonly used as feature extractors for variousdownstream tasks, requiring substantial data and computing resources for theirtraining process. With the deployment of pre-trained encoders in commercialuse, protecting the intellectual property of model owners and ensuring thetrustworthiness of the models becomes crucial. Recent research has shown thatencoders are threatened by backdoor attacks, adversarial attacks, etc.Therefore, a scheme to verify the integrity of pre-trained encoders is neededto protect users. In this paper, we propose SSL-Auth, the first fragilewatermarking scheme for verifying the integrity of encoders withoutcompromising model performance. Our method utilizes selected key samples aswatermark information and trains a verification network to reconstruct thewatermark information, thereby verifying the integrity of the encoder. Bycomparing the reconstruction results of the key samples, maliciousmodifications can be effectively detected, as altered models should not exhibitsimilar reconstruction performance as the original models. Extensiveevaluations on various models and diverse datasets demonstrate theeffectiveness and fragility of our proposed SSL-Auth.", "output": "SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fairness in deep learning models trained with high-dimensional inputs andsubjective labels remains a complex and understudied area. Facial emotionrecognition, a domain where datasets are often racially imbalanced, can lead tomodels that yield disparate outcomes across racial groups. This study focuseson analyzing racial bias by sub-sampling training sets with varied racialdistributions and assessing test performance across these simulations. Ourfindings indicate that smaller datasets with posed faces improve on bothfairness and performance metrics as the simulations approach racial balance.Notably, the F1-score increases by $27.2%$ points, and demographic parityincreases by $15.7%$ points on average across the simulations. However, inlarger datasets with greater facial variation, fairness metrics generallyremain constant, suggesting that racial balance by itself is insufficient toachieve parity in test performance across different racial groups.", "output": "Addressing Racial Bias in Facial Emotion Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large Language Models (LLMs) have shown outstanding performance across widerange of downstream tasks. This competency is attributed to their substantialparameter size and pre-training on extensive corpus. Moreover, LLMs haveexhibited enhanced reasoning capabilities in tackling complex reasoning tasks,owing to the utilization of a method named ``Chain-of-Thought (CoT)prompting''. This method is designed to generate intermediate reasoning stepsthat guide the inference of the final answer. However, it is essential tohighlight that these advanced reasoning abilities appear to emerge in modelswith a minimum of 10 billion parameters, thereby limiting its efficacy insituations where computational resources are constrained. In this paper, weinvestigate the possibility of transferring the reasoning capabilities of LLMsto smaller models via knowledge distillation. Specifically, we propose Sci-CoT,a two-stage framework that separates the processes of generating rationales andinferring answers. This method enables a more efficient use of rationalesduring the answer inference stage, leading to improved performance onscientific question-answering tasks. Utilizing Sci-CoT, our 80-millionparameter model is able to exceed the performance of BLOOM-176B in the ARC-Easydataset under the few shot setting.", "output": "Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While the use of artificial intelligence (AI) for medical image analysis isgaining wide acceptance, the expertise, time and cost required to generateannotated data in the medical field are significantly high, due to limitedavailability of both data and expert annotation. Strongly supervised objectlocalization models require data that is exhaustively annotated, meaning allobjects of interest in an image are identified. This is difficult to achieveand verify for medical images. We present a method for the transformation ofreal data to train any Deep Neural Network to solve the above problems. We showthe efficacy of this approach on both a weakly supervised localization modeland a strongly supervised localization model. For the weakly supervised model,we show that the localization accuracy increases significantly using thegenerated data. For the strongly supervised model, this approach overcomes theneed for exhaustive annotation on real images. In the latter model, we showthat the accuracy, when trained with generated images, closely parallels theaccuracy when trained with exhaustively annotated real images. The results aredemonstrated on images of human urine samples obtained using microscopy.", "output": "Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the present time, all know about World Wide Web and work over the Internetdaily. In this paper, we introduce the search engines working for keywords thatare entered by users to find something. The search engine uses different searchalgorithms for convenient results for providing to the net surfer. Net surfersgo with the top search results but how did the results of web pages get higherranks over search engines? how the search engine got that all the web pages inthe database? This paper gives the answers to all these kinds of basicquestions. Web crawlers working for search engines and robot exclusion protocolrules for web crawlers are also addressed in this research paper. Webmasteruses different restriction facts in robot.txt file to instruct web crawler,some basic formats of robot.txt are also mentioned in this paper.", "output": "web crawler strategies for web pages under robot.txt restriction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Partial differential equations (PDEs) underlie our understanding andprediction of natural phenomena across numerous fields, including physics,engineering, and finance. However, solving parametric PDEs is a complex taskthat necessitates efficient numerical methods. In this paper, we propose anovel approach for solving parametric PDEs using a Finite Element OperatorNetwork (FEONet). Our proposed method leverages the power of deep learning inconjunction with traditional numerical methods, specifically the finite elementmethod, to solve parametric PDEs in the absence of any paired input-outputtraining data. We demonstrate the effectiveness of our approach on severalbenchmark problems and show that it outperforms existing state-of-the-artmethods in terms of accuracy, generalization, and computational flexibility.Our FEONet framework shows potential for application in various fields wherePDEs play a crucial role in modeling complex domains with diverse boundaryconditions and singular behavior. Furthermore, we provide theoreticalconvergence analysis to support our approach, utilizing finite elementapproximation in numerical analysis.", "output": "Finite Element Operator Network for Solving Parametric PDEs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While artificial intelligence (AI) has made many successful applications invarious domains, its adoption in healthcare lags a little bit behind otherhigh-stakes settings. Several factors contribute to this slower uptake,including regulatory frameworks, patient privacy concerns, and dataheterogeneity. However, one significant challenge that impedes theimplementation of AI in healthcare, particularly in orthopedics, is the lack ofexplainability and interpretability around AI models. Addressing the challengeof explainable AI (XAI) in orthopedics requires developing AI models andalgorithms that prioritize transparency and interpretability, allowingclinicians, surgeons, and patients to understand the contributing factorsbehind any AI-powered predictive or descriptive models. The currentcontribution outlines several key challenges and opportunities that manifest inXAI in orthopedic practice. This work emphasizes the need for interdisciplinarycollaborations between AI practitioners, orthopedic specialists, and regulatoryentities to establish standards and guidelines for the adoption of XAI inorthopedics.", "output": "Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the task of probabilistic anomaly attribution in the black-boxregression setting, where the goal is to compute the probability distributionof the attribution score of each input variable, given an observed anomaly. Thetraining dataset is assumed to be unavailable. This task differs from thestandard XAI (explainable AI) scenario, since we wish to explain the anomalousdeviation from a black-box prediction rather than the black-box model itself.We begin by showing that mainstream model-agnostic explanation methods, suchas the Shapley values, are not suitable for this task because of their``deviation-agnostic property.'' We then propose a novel framework forprobabilistic anomaly attribution that allows us to not only computeattribution scores as the predictive mean but also quantify the uncertainty ofthose scores. This is done by considering a generative process forperturbations that counter-factually bring the observed anomalous observationback to normalcy. We introduce a variational Bayes algorithm for deriving thedistributions of per variable attribution scores. To the best of our knowledge,this is the first probabilistic anomaly attribution framework that is free frombeing deviation-agnostic.", "output": "Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an empirical exploration of non-transitivity inperfect-information games, specifically focusing on Xiangqi, a traditionalChinese board game comparable in game-tree complexity to chess and shogi. Byanalyzing over 10,000 records of human Xiangqi play, we highlight the existenceof both transitive and non-transitive elements within the game's strategicstructure. To address non-transitivity, we introduce the JiangJun algorithm, aninnovative combination of Monte-Carlo Tree Search (MCTS) and Policy SpaceResponse Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluatethe algorithm empirically using a WeChat mini program and achieve a Masterlevel with a 99.41% win rate against human players. The algorithm'seffectiveness in overcoming non-transitivity is confirmed by a plethora ofmetrics, such as relative population performance and visualization results. Ourproject site is available aturl{", "output": "JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Music generation has attracted growing interest with the advancement of deepgenerative models. However, generating music conditioned on textualdescriptions, known as text-to-music, remains challenging due to the complexityof musical structures and high sampling rate requirements. Despite the task'ssignificance, prevailing generative models exhibit limitations in musicquality, computational efficiency, and generalization. This paper introducesJEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is adiffusion model incorporating both autoregressive and non-autoregressivetraining. Through in-context learning, JEN-1 performs various generation tasksincluding text-guided music generation, music inpainting, and continuation.Evaluations demonstrate JEN-1's superior performance over state-of-the-artmethods in text-music alignment and music quality while maintainingcomputational efficiency. Our demos are available at<a href=\" http URL</a>", "output": "JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The aim of this study is to evaluate the performance of AI-assistedprogramming in actual mobile development teams that are focused on nativemobile languages like Kotlin and Swift. The extensive case study involves 16participants and 2 technical reviewers, from a software development departmentdesigned to understand the impact of using LLMs trained for code generation inspecific phases of the team, more specifically, technical onboarding andtechnical stack switch. The study uses technical problems dedicated to eachphase and requests solutions from the participants with and without usingAI-Code generators. It measures time, correctness, and technical integrationusing ReviewerScore, a metric specific to the paper and extracted from actualindustry standards, the code reviewers of merge requests. The output isconverted and analyzed together with feedback from the participants in anattempt to determine if using AI-assisted programming tools will have an impacton getting developers onboard in a project or helping them with a smoothtransition between the two native development environments of mobiledevelopment, Android and iOS. The study was performed between May and June 2023with members of the mobile department of a software development company basedin Cluj-Napoca, with Romanian ownership and management.", "output": "Case Study: Using AI-Assisted Code Generation In Mobile Teams."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Children possess the ability to learn multiple cognitive tasks sequentially,which is a major challenge toward the long-term goal of artificial generalintelligence. Existing continual learning frameworks are usually applicable toDeep Neural Networks (DNNs) and lack the exploration on more brain-inspired,energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learningmechanisms during child growth and development, we propose Dynamic StructureDevelopment of Spiking Neural Networks (DSD-SNN) for efficient and adaptivecontinual learning. When learning a sequence of tasks, the DSD-SNN dynamicallyassigns and grows new neurons to new tasks and prunes redundant neurons,thereby increasing memory capacity and reducing computational overhead. Inaddition, the overlapping shared structure helps to quickly leverage allacquired knowledge to new tasks, empowering a single network capable ofsupporting multiple incremental tasks (without the separate sub-network maskfor each task). We validate the effectiveness of the proposed model on multipleclass incremental learning and task incremental learning benchmarks. Extensiveexperiments demonstrated that our model could significantly improveperformance, learning speed and memory capacity, and reduce computationaloverhead. Besides, our DSD-SNN model achieves comparable performance with theDNNs-based methods, and significantly outperforms the state-of-the-art (SOTA)performance for existing SNNs-based continual learning methods.", "output": "Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-language navigation (VLN), which entails an agent to navigate 3Denvironments following human instructions, has shown great advances. However,current agents are built upon panoramic observations, which hinders theirability to perceive 3D scene geometry and easily leads to ambiguous selectionof panoramic view. To address these limitations, we present a BEV Scene Graph(BSG), which leverages multi-step BEV representations to encode scene layoutsand geometric cues of indoor environment under the supervision of 3D detection.During navigation, BSG builds a local BEV representation at each step andmaintains a BEV-based global scene map, which stores and organizes all theonline collected local BEV representations according to their topologicalrelations. Based on BSG, the agent predicts a local BEV grid-level decisionscore and a global graph-level decision score, combined with a sub-viewselection score on panoramic views, for more accurate action prediction. Ourapproach significantly outperforms state-of-the-art methods on REVERIE, R2R,and R4R, showing the potential of BEV perception in VLN.", "output": "Bird's-Eye-View Scene Graph for Vision-Language Navigation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ethics of automated vehicles (AV) has received a great amount ofattention in recent years, specifically in regard to their decisional policiesin accident situations in which human harm is a likely consequence. After adiscussion about the pertinence and cogency of the term 'artificial moralagent' to describe AVs that would accomplish these sorts of decisions, andstarting from the assumption that human harm is unavoidable in some situations,a strategy for AV decision making is proposed using only pre-defined parametersto characterize the risk of possible accidents and also integrating the EthicalValence Theory, which paints AV decision-making as a type of claim mitigation,into multiple possible decision rules to determine the most suitable actiongiven the specific environment and decision context. The goal of this approachis not to define how moral theory requires vehicles to behave, but rather toprovide a computational approach that is flexible enough to accommodate anumber of human 'moral positions' concerning what morality demands and whatroad users may expect, offering an evaluation tool for the social acceptabilityof an automated vehicle's decision making.", "output": "Automated Driving Without Ethics: Meaning, Design and Real-World Implementation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) has emerged as a privacy-preserving paradigm thattrains neural networks on edge devices without collecting data at a centralserver. However, FL encounters an inherent challenge in dealing withnon-independent and identically distributed (non-IID) data among devices. Toaddress this challenge, this paper proposes a hard feature matching datasynthesis (HFMDS) method to share auxiliary data besides local models.Specifically, synthetic data are generated by learning the essentialclass-relevant features of real samples and discarding the redundant features,which helps to effectively tackle the non-IID issue. For better privacypreservation, we propose a hard feature augmentation method to transfer realfeatures towards the decision boundary, with which the synthetic data not onlyimprove the model generalization but also erase the information of realfeatures. By integrating the proposed HFMDS method with FL, we present a novelFL framework with data augmentation to relieve data heterogeneity. Thetheoretical analysis highlights the effectiveness of our proposed datasynthesis method in solving the non-IID challenge. Simulation results furtherdemonstrate that our proposed HFMDS-FL algorithm outperforms the baselines interms of accuracy, privacy preservation, and computational cost on variousbenchmark datasets.", "output": "Feature Matching Data Synthesis for Non-IID Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised sound source localization is usually challenged by themodality inconsistency. In recent studies, contrastive learning basedstrategies have shown promising to establish such a consistent correspondencebetween audio and sound sources in visual scenarios. Unfortunately, theinsufficient attention to the heterogeneity influence in the different modalityfeatures still limits this scheme to be further improved, which also becomesthe motivation of our work. In this study, an Induction Network is proposed tobridge the modality gap more effectively. By decoupling the gradients of visualand audio modalities, the discriminative visual representations of soundsources can be learned with the designed Induction Vector in a bootstrapmanner, which also enables the audio modality to be aligned with the visualmodality consistently. In addition to a visual weighted contrastive loss, anadaptive threshold selection strategy is introduced to enhance the robustnessof the Induction Network. Substantial experiments conducted on SoundNet-Flickrand VGG-Sound Source datasets have demonstrated a superior performance comparedto other state-of-the-art works in different challenging scenarios. The code isavailable at ", "output": "Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Motivated by the advances in deep learning techniques, the application ofUnmanned Aerial Vehicle (UAV)-based object detection has proliferated across arange of fields, including vehicle counting, fire detection, and citymonitoring. While most existing research studies only a subset of thechallenges inherent to UAV-based object detection, there are few studies thatbalance various aspects to design a practical system for energy consumptionreduction. In response, we present the E3-UAV, an edge-based energy-efficientobject detection system for UAVs. The system is designed to dynamically supportvarious UAV devices, edge devices, and detection algorithms, with the aim ofminimizing energy consumption by deciding the most energy-efficient flightparameters (including flight altitude, flight speed, detection algorithm, andsampling rate) required to fulfill the detection requirements of the task. Wefirst present an effective evaluation metric for actual tasks and construct atransparent energy consumption model based on hundreds of actual flight data toformalize the relationship between energy consumption and flight parameters.Then we present a lightweight energy-efficient priority decision algorithmbased on a large quantity of actual flight data to assist the system indeciding flight parameters. Finally, we evaluate the performance of the system,and our experimental results demonstrate that it can significantly decreaseenergy consumption in real-world scenarios. Additionally, we provide fourinsights that can assist researchers and engineers in their efforts to studyUAV-based object detection further.", "output": "E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "By combining related objects, unsupervised machine learning techniques aim toreveal the underlying patterns in a data set. Non-negative Matrix Factorization(NMF) is a data mining technique that splits data matrices by imposingrestrictions on the elements' non-negativity into two matrices: onerepresenting the data partitions and the other to represent the clusterprototypes of the data set. This method has attracted a lot of attention and isused in a wide range of applications, including text mining, clustering,language modeling, music transcription, and neuroscience (gene separation). Theinterpretation of the generated matrices is made simpler by the absence ofnegative values. In this article, we propose a study on multi-modal clusteringalgorithms and present a novel method called multi-modal multi-viewnon-negative matrix factorization, in which we analyze the collaboration ofseveral local NMF models. The experimental results show the value of theproposed approach, which was evaluated using a variety of data sets, and theobtained results are very promising compared to state of art methods.", "output": "Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The application of 3D ground-penetrating radar (3D-GPR) for subgrade distressdetection has gained widespread popularity. To enhance the efficiency andaccuracy of detection, pioneering studies have attempted to adopt automaticdetection techniques, particularly deep learning. However, existing workstypically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of theGPR, resulting in either insufficient spatial information or high computationalcomplexity. To address these challenges, we introduce a novel methodology forthe subgrade distress detection task by leveraging the multi-view informationfrom 3D-GPR data. Moreover, we construct a real multi-view image datasetderived from the original 3D-GPR data for the detection task, which providesricher spatial information compared to A-scan and B-scan data, while reducingcomputational complexity compared to C-scan data. Subsequently, we develop anovel textbf{M}ulti-textbf{V}iew textbf{V}usion and textbf{D}istillationframework, textbf{GPR-MVFD}, specifically designed to optimally utilize themulti-view GPR dataset. This framework ingeniously incorporates multi-viewdistillation and attention-based fusion to facilitate significant featureextraction for subgrade distresses. In addition, a self-adaptive learningmechanism is adopted to stabilize the model training and prevent performancedegeneration in each branch. Extensive experiments conducted on this new GPRbenchmark demonstrate the effectiveness and efficiency of our proposedframework. Our framework outperforms not only the existing GPR baselines, butalso the state-of-the-art methods in the fields of multi-view learning,multi-modal learning, and knowledge distillation. We will release theconstructed multi-view GPR dataset with expert-annotated labels and the sourcecodes of the proposed framework.", "output": "Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Intelligent autonomous path planning is crucial to improve the explorationefficiency of planetary rovers. In this paper, we propose a learning-basedmethod to quickly search for optimal paths in an elevation map, which is calledNNPP. The NNPP model learns semantic information about start and goallocations, as well as map representations, from numerous pre-annotated optimalpath demonstrations, and produces a probabilistic distribution over each pixelrepresenting the likelihood of it belonging to an optimal path on the map. Morespecifically, the paper computes the traversal cost for each grid cell from theslope, roughness and elevation difference obtained from the DEM. Subsequently,the start and goal locations are encoded using a Gaussian distribution anddifferent location encoding parameters are analyzed for their effect on modelperformance. After training, the NNPP model is able to perform path planning onnovel maps. Experiments show that the guidance field generated by the NNPPmodel can significantly reduce the search time for optimal paths under the samehardware conditions, and the advantage of NNPP increases with the scale of themap.", "output": "A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ontologies are used in various domains, with RDF and OWL being prominentstandards for ontology development. RDF is favored for its simplicity andflexibility, while OWL enables detailed domain knowledge representation.However, as ontologies grow larger and more expressive, reasoning complexityincreases, and traditional reasoners struggle to perform efficiently. Despiteoptimization efforts, scalability remains an issue. Additionally, advancementsin automated knowledge base construction have created large and expressiveontologies that are often noisy and inconsistent, posing further challenges forconventional reasoners. To address these challenges, researchers have exploredneuro-symbolic approaches that combine neural networks' learning capabilitieswith symbolic systems' reasoning abilities. In this chapter,we provide anoverview of the existing literature in the field of neuro-symbolic deductivereasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL,discussing the techniques employed, the tasks they address, and other relevantefforts in this area.", "output": "Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many multi-agent systems require inter-agent communication to properlyachieve their goal. By learning the communication protocol alongside the actionprotocol using multi-agent reinforcement learning techniques, the agents gainthe flexibility to determine which information should be shared. However, whenthe number of agents increases we need to create an encoding of the informationcontained in these messages. In this paper, we investigate the effect ofincreasing the amount of information that should be contained in a message andincreasing the number of agents. We evaluate these effects on two differentmessage encoding methods, the mean message encoder and the attention messageencoder. We perform our experiments on a matrix environment. Surprisingly, ourresults show that the mean message encoder consistently outperforms theattention message encoder. Therefore, we analyse the communication protocolused by the agents that use the mean message encoder and can conclude that theagents use a combination of an exponential and a logarithmic function in theircommunication policy to avoid the loss of important information after applyingthe mean message encoder.", "output": "Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Symbolic planning is a powerful technique to solve complex tasks that requirelong sequences of actions and can equip an intelligent agent with complexbehavior. The downside of this approach is the necessity for suitable symbolicrepresentations describing the state of the environment as well as the actionsthat can change it. Traditionally such representations are carefullyhand-designed by experts for distinct problem domains, which limits theirtransferability to different problems and environment complexities. In thispaper, we propose a novel concept to generalize symbolic actions using a givenentity hierarchy and observed similar behavior. In a simulated grid-basedkitchen environment, we show that type-generalized actions can be learned fromfew observations and generalize to novel situations. Incorporating anadditional on-the-fly generalization mechanism during planning, unseen taskcombinations, involving longer sequences, novel entities and unexpectedenvironment behavior, can be solved.", "output": "Learning Type-Generalized Actions for Symbolic Planning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rapid growth of information in the field of Generative ArtificialIntelligence (AI), particularly in the subfields of Natural Language Processing(NLP) and Machine Learning (ML), presents a significant challenge forresearchers and practitioners to keep pace with the latest developments. Toaddress the problem of information overload, this report by the NaturalLanguage Learning Group at Bielefeld University focuses on identifying the mostpopular papers on arXiv, with a specific emphasis on NLP and ML. The objectiveis to offer a quick guide to the most relevant and widely discussed research,aiding both newcomers and established researchers in staying abreast of currenttrends. In particular, we compile a list of the 40 most popular papers based onnormalized citation counts from the first half of 2023. We observe thedominance of papers related to Large Language Models (LLMs) and specificallyChatGPT during the first half of 2023, with the latter showing signs ofdeclining popularity more recently, however. Further, NLP related papers arethe most influential (around 60% of top papers) even though there are twice asmany ML related papers in our data. Core issues investigated in the mostheavily cited papers are: LLM efficiency, evaluation techniques, ethicalconsiderations, embodied agents, and problem-solving with LLMs. Additionally,we examine the characteristics of top papers in comparison to others outsidethe top-40 list (noticing the top paper's focus on LLM related issues andhigher number of co-authors) and analyze the citation distributions in ourdataset, among others.", "output": "NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Congestion Control (CC) plays a fundamental role in optimizing traffic inData Center Networks (DCN). Currently, DCNs mainly implement two main CCprotocols: DCTCP and DCQCN. Both protocols -- and their main variants -- arebased on Explicit Congestion Notification (ECN), where intermediate switchesmark packets when they detect congestion. The ECN configuration is thus acrucial aspect on the performance of CC protocols. Nowadays, network expertsset static ECN parameters carefully selected to optimize the average networkperformance. However, today's high-speed DCNs experience quick and abruptchanges that severely change the network state (e.g., dynamic trafficworkloads, incast events, failures). This leads to under-utilization andsub-optimal performance. This paper presents GraphCC, a novel MachineLearning-based framework for in-network CC optimization. Our distributedsolution relies on a novel combination of Multi-agent Reinforcement Learning(MARL) and Graph Neural Networks (GNN), and it is compatible with widelydeployed ECN-based CC protocols. GraphCC deploys distributed agents on switchesthat communicate with their neighbors to cooperate and optimize the global ECNconfiguration. In our evaluation, we test the performance of GraphCC under awide variety of scenarios, focusing on the capability of this solution to adaptto new scenarios unseen during training (e.g., new traffic workloads, failures,upgrades). We compare GraphCC with a state-of-the-art MARL-based solution forECN tuning -- ACC -- and observe that our proposed solution outperforms thestate-of-the-art baseline in all of the evaluation scenarios, showingimprovements up to $20%$ in Flow Completion Time as well as significantreductions in buffer occupancy ($38.0-85.7%$).", "output": "GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper focuses on the impact of leveraging autonomous offensiveapproaches in Deep Reinforcement Learning (DRL) to train more robust agents byexploring the impact of applying adversarial learning to DRL for autonomoussecurity in Software Defined Networks (SDN). Two algorithms, Double DeepQ-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN orN2D), are compared. NEC2DQN was proposed in 2018 and is a new member of thedeep q-network (DQN) family of algorithms. The attacker has full observabilityof the environment and access to a causative attack that uses statemanipulation in an attempt to poison the learning process. The implementationof the attack is done under a white-box setting, in which the attacker hasaccess to the defender's model and experiences. Two games are played; in thefirst game, DDQN is a defender and N2D is an attacker, and in second game, theroles are reversed. The games are played twice; first, without an activecausative attack and secondly, with an active causative attack. For execution,three sets of game results are recorded in which a single set consists of 10game runs. The before and after results are then compared in order to see ifthere was actually an improvement or degradation. The results show that withminute parameter changes made to the algorithms, there was growth in theattacker's role, since it is able to win games. Implementation of theadversarial learning by the introduction of the causative attack showed thealgorithms are still able to defend the network according to their strengths.", "output": "Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical image analysis using deep learning is often challenged by limitedlabeled data and high annotation costs. Fine-tuning the entire network inlabel-limited scenarios can lead to overfitting and suboptimal performance.Recently, prompt tuning has emerged as a more promising technique thatintroduces a few additional tunable parameters as prompts to a task-agnosticpre-trained model, and updates only these parameters using supervision fromlimited labeled data while keeping the pre-trained model unchanged. However,previous work has overlooked the importance of selective labeling in downstreamtasks, which aims to select the most valuable downstream samples for annotationto achieve the best performance with minimum annotation cost. To address this,we propose a framework that combines selective labeling with prompt tuning(SLPT) to boost performance in limited labels. Specifically, we introduce afeature-aware prompt updater to guide prompt tuning and a TandEm SelectiveLAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection andsupervised selection using prompt-based uncertainty. In addition, we propose adiversified visual prompt tuning strategy to provide multi-prompt-baseddiscrepant predictions for TESLA. We evaluate our method on liver tumorsegmentation and achieve state-of-the-art performance, outperformingtraditional fine-tuning with only 6% of tunable parameters, also achieving 94%of full-data performance by labeling only 5% of the data.", "output": "SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "E-commerce authoring involves creating attractive, abundant, and targetedpromotional content to drive product sales. The emergence of large languagemodels (LLMs) introduces an innovative paradigm, offering a unified solution toaddress various authoring tasks within this scenario. However, mainstream LLMstrained on general corpora with common sense knowledge reveal limitations infitting complex and personalized features unique to e-commerce products andcustomers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility,raising concerns about safeguarding voluminous customer privacy data duringtransmission. This paper proposes the LLaMA-E, the unified and customizedinstruction-following language models focusing on diverse e-commerce authoringtasks. Specifically, the domain experts create the seed instruction set fromthe tasks of ads generation, query-enhanced product title rewriting, productclassification, purchase intent speculation, and general Q&amp;A. These tasksenable the models to comprehensively understand precise e-commerce authoringknowledge by interleaving features covering typical service aspects ofcustomers, sellers, and platforms. The GPT-3.5 is introduced as a teachermodel, which expands the seed instructions to form a training set for theLLaMA-E models with various scales. The experimental results show that theproposed LLaMA-E models achieve state-of-the-art results in quantitative andqualitative evaluations, also exhibiting the advantage in zero-shot scenes. Tothe best of our knowledge, this study is the first to serve the LLMs tospecific e-commerce authoring scenarios.", "output": "LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Metaverse enables users to communicate, collaborate and socialize with eachother through their digital avatars. Due to the spatio-temporalcharacteristics, co-located users are served well by performing their softwarecomponents in a collaborative manner such that a Metaverse service provider(MSP) eliminates redundant data transmission and processing, ultimatelyreducing the total energy consumption. The energyefficient service provision iscrucial for enabling the green and sustainable Metaverse. In this article, wetake an augmented reality (AR) application as an example to achieve this goal.Moreover, we study an economic issue on how the users reserve offloadingservices from the MSP and how the MSP determines an optimal charging pricesince each user is rational to decide whether to accept the offloading serviceby taking into account the monetary cost. A single-leader multi-followerStackelberg game is formulated between the MSP and users while each useroptimizes an offloading probability to minimize the weighted sum of time,energy consumption and monetary cost. Numerical results show that our schemeachieves energy savings and satisfies individual rationality simultaneouslycompared with the conventional schemes. Finally, we identify and discuss opendirections on how several emerging technologies are combined with thesustainable green Metaverse.", "output": "Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Communication is crucial in multi-agent reinforcement learning when agentsare not able to observe the full state of the environment. The most commonapproach to allow learned communication between agents is the use of adifferentiable communication channel that allows gradients to flow betweenagents as a form of feedback. However, this is challenging when we want to usediscrete messages to reduce the message size, since gradients cannot flowthrough a discrete communication channel. Previous work proposed methods todeal with this problem. However, these methods are tested in differentcommunication learning architectures and environments, making it hard tocompare them. In this paper, we compare several state-of-the-art discretizationmethods as well as a novel approach. We do this comparison in the context ofcommunication learning using gradients from other agents and perform tests onseveral environments. In addition, we present COMA-DIAL, a communicationlearning approach based on DIAL and COMA extended with learning rate scalingand adapted exploration. Using COMA-DIAL allows us to perform experiments onmore complex environments. Our results show that the novel ST-DRU method,proposed in this paper, achieves the best results out of all discretizationmethods across the different environments. It achieves the best or close to thebest performance in each of the experiments and is the only method that doesnot fail on any of the tested environments.", "output": "An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial Intelligence Generated Content (AIGC) Services have significantpotential in digital content creation. The distinctive abilities of AIGC, suchas content generation based on minimal input, hold huge potential, especiallywhen integrating with semantic communication (SemCom). In this paper, a novelcomprehensive conceptual model for the integration of AIGC and SemCom isdeveloped. Particularly, a content generation level is introduced on top of thesemantic level that provides a clear outline of how AIGC and SemCom interactwith each other to produce meaningful and effective content. Moreover, a novelframework that employs AIGC technology is proposed as an encoder and decoderfor semantic information, considering the joint optimization of semanticextraction and evaluation metrics tailored to AIGC services. The framework canadapt to different types of content generated, the required quality, and thesemantic information utilized. By employing a Deep Q Network (DQN), a casestudy is presented that provides useful insights into the feasibility of theoptimization problem and its convergence characteristics.", "output": "Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Anomaly detection (AD) in images, identifying significant deviations fromnormality, is a critical issue in computer vision. This paper introduces anovel approach to dimensionality reduction for AD using pre-trainedconvolutional neural network (CNN) that incorporate EfficientNet models. Weinvestigate the importance of component selection and propose two types of treesearch approaches, both employing a greedy strategy, for optimal eigencomponentselection. Our study conducts three main experiments to evaluate theeffectiveness of our approach. The first experiment explores the influence oftest set performance on component choice, the second experiment examines theperformance when we train on one anomaly type and evaluate on all other types,and the third experiment investigates the impact of using a minimum number ofimages for training and selecting them based on anomaly types. Our approachaims to find the optimal subset of components that deliver the highestperformance score, instead of focusing solely on the proportion of varianceexplained by each component and also understand the components behaviour indifferent settings. Our results indicate that the proposed method surpassesboth Principal Component Analysis (PCA) and Negated Principal ComponentAnalysis (NPCA) in terms of detection accuracy, even when using fewercomponents. Thus, our approach provides a promising alternative to conventionaldimensionality reduction techniques in AD, and holds potential to enhance theefficiency and effectiveness of AD systems.", "output": "Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recent development and success of Large Language Models (LLMs)necessitate an evaluation of their performance across diverse NLP tasks indifferent languages. Although several frameworks have been developed and madepublicly available, their customization capabilities for specific tasks anddatasets are often complex for different users. In this study, we introduce theLLMeBench framework. Initially developed to evaluate Arabic NLP tasks usingOpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP taskand model, regardless of language. The framework also features zero- andfew-shot learning settings. A new custom dataset can be added in less than 10minutes, and users can use their own model API keys to evaluate the task athand. The developed framework has been already tested on 31 unique NLP tasksusing 53 publicly available datasets within 90 experimental setups, involvingapproximately 296K data points. We plan to open-source the framework for thecommunity ( A video demonstrating theframework is available online (", "output": "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Predicting stock prices presents a challenging research problem due to theinherent volatility and non-linear nature of the stock market. In recent years,knowledge-enhanced stock price prediction methods have shown groundbreakingresults by utilizing external knowledge to understand the stock market. Despitethe importance of these methods, there is a scarcity of scholarly works thatsystematically synthesize previous studies from the perspective of externalknowledge types. Specifically, the external knowledge can be modeled indifferent data structures, which we group into non-graph-based formats andgraph-based formats: 1) non-graph-based knowledge captures contextualinformation and multimedia descriptions specifically associated with anindividual stock; 2) graph-based knowledge captures interconnected andinterdependent information in the stock market. This survey paper aims toprovide a systematic and comprehensive description of methods for acquiringexternal knowledge from various unstructured data sources and thenincorporating it into stock price prediction models. We also explore fusionmethods for combining external knowledge with historical price features.Moreover, this paper includes a compilation of relevant datasets and delvesinto potential future research directions in this domain.", "output": "Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot SemanticSegmentation (FSS) to simultaneously segment unseen classes and seen classesduring evaluation. Previous works leverage additional branch or prototypicalaggregation to eliminate the constrained setting of FSS. However,representation division and embedding prejudice, which heavily results in poorperformance of GFSS, have not been synthetical considered. We address theaforementioned problems by jointing the prototypical kernel learning andopen-set foreground perception. Specifically, a group of learnable kernels isproposed to perform segmentation with each kernel in charge of a stuff class.Then, we explore to merge the prototypical learning to the update of base-classkernels, which is consistent with the prototype knowledge aggregation offew-shot novel classes. In addition, a foreground contextual perception modulecooperating with conditional bias based inference is adopted to performclass-agnostic as well as open-set foreground detection, thus to mitigate theembedding prejudice and prevent novel targets from being misclassified asbackground. Moreover, we also adjust our method to the Class IncrementalFew-shot Semantic Segmentation (CIFSS) which takes the knowledge of novelclasses in a incremental stream. Extensive experiments on PASCAL-5i andCOCO-20i datasets demonstrate that our method performs better than previousstate-of-the-art.", "output": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) has found many successes in wireless networks;however, the implementation of FL has been hindered by the energy limitation ofmobile devices (MDs) and the availability of training data at MDs. How tointegrate wireless power transfer and mobile crowdsensing towards sustainableFL solutions is a research topic entirely missing from the open literature.This work for the first time investigates a resource allocation problem incollaborative sensing-assisted sustainable FL (S2FL) networks with the goal ofminimizing the total completion time. We investigate a practicalharvesting-sensing-training-transmitting protocol in which energy-limited MDsfirst harvest energy from RF signals, use it to gain a reward for userparticipation, sense the training data from the environment, train the localmodels at MDs, and transmit the model updates to the server. The totalcompletion time minimization problem of jointly optimizing power transfer,transmit power allocation, data sensing, bandwidth allocation, local modeltraining, and data transmission is complicated due to the non-convex objectivefunction, highly non-convex constraints, and strongly coupled variables. Wepropose a computationally-efficient path-following algorithm to obtain theoptimal solution via the decomposition technique. In particular, inner convexapproximations are developed for the resource allocation subproblem, and thesubproblems are performed alternatively in an iterative fashion. Simulationresults are provided to evaluate the effectiveness of the proposed S2FLalgorithm in reducing the completion time up to 21.45% in comparison with otherbenchmark schemes. Further, we investigate an extension of our work fromfrequency division multiple access (FDMA) to non-orthogonal multiple access(NOMA) and show that NOMA can speed up the total completion time 8.36% onaverage of the considered FL system.", "output": "Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advanced Air Mobility (AAM) introduces a new, efficient mode oftransportation with the use of vehicle autonomy and electrified aircraft toprovide increasingly autonomous transportation between previously underservedmarkets. Safe and efficient navigation of low altitude aircraft through highlydense environments requires the integration of a multitude of complexobservations, such as surveillance, knowledge of vehicle dynamics, and weather.The processing and reasoning on these observations pose challenges due to thevarious sources of uncertainty in the information while ensuring cooperationwith a variable number of aircraft in the airspace. These challenges coupledwith the requirement to make safety-critical decisions in real-time rule outthe use of conventional separation assurance techniques. We present adecentralized reinforcement learning framework to provide autonomousself-separation capabilities within AAM corridors with the use of speed andvertical maneuvers. The problem is formulated as a Markov Decision Process andsolved by developing a novel extension to the sample-efficient, off-policy softactor-critic (SAC) algorithm. We introduce the use of attention networks forvariable-length observation processing and a distributed computing architectureto achieve high training sample throughput as compared to existing approaches.A comprehensive numerical study shows that the proposed framework can ensuresafe and efficient separation of aircraft in high density, dynamic environmentswith various sources of uncertainty.", "output": "Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the rise of deep learning, large datasets and complex models have becomecommon, requiring significant computing power. To address this, datadistillation has emerged as a technique to quickly train models with lowermemory and time requirements. However, data distillation on text-based datasetshasn't been explored much because of the challenges rising due to its discretenature. Additionally, existing dataset distillation methods often struggle togeneralize to new architectures. In the paper, we propose several datadistillation techniques for multilingual text classification datasets usinglanguage-model-based learning methods. We conduct experiments to analyze theirperformance in terms of classification strength, and cross-architecturegeneralization. Furthermore, we investigate the language-specific fairness ofthe data summaries generated by these methods. Our approach builds uponexisting techniques, enhancing cross-architecture generalization in the textdata distillation domain.", "output": "Exploring Multilingual Text Data Distillation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., textand image) for a comprehensive understanding of entities. Despite the recentprogress of large-scale MMKGs, existing MMKGs neglect the multi-aspect natureof entities, limiting the ability to comprehend entities from variousperspectives. In this paper, we construct AspectMMKG, the first MMKG withaspect-related images by matching images to different entity aspects.Specifically, we collect aspect-related images from a knowledge base, andfurther extract aspect-related sentences from the knowledge base as queries toretrieve a large number of aspect-related images via an online image searchengine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and645,383 aspect-related images. We demonstrate the usability of AspectMMKG inentity aspect linking (EAL) downstream task and show that previous EAL modelsachieve a new state-of-the-art performance with the help of AspectMMKG. Tofacilitate the research on aspect-related MMKG, we further propose anaspect-related image retrieval (AIR) model, that aims to correct and expandaspect-related images in AspectMMKG. We train an AIR model to learn therelationship between entity image and entity aspect-related images byincorporating entity image, aspect, and aspect image information. Experimentalresults indicate that the AIR model could retrieve suitable images for a givenentity w.r.t different aspects.", "output": "AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transit riders' feedback provided in ridership surveys, customer relationshipmanagement (CRM) channels, and in more recent times, through social media iskey for transit agencies to better gauge the efficacy of their services andinitiatives. Getting a holistic understanding of riders' experience through thefeedback shared in those instruments is often challenging, mostly due to theopen-ended, unstructured nature of text feedback. In this paper, we proposeleveraging traditional transit CRM feedback to develop and deploy atransit-topic-aware large language model (LLM) capable of classifyingopen-ended text feedback to relevant transit-specific topics. First, we utilizesemi-supervised learning to engineer a training dataset of 11 broad transittopics detected in a corpus of 6 years of customer feedback provided to theWashington Metropolitan Area Transit Authority (WMATA). We then use thisdataset to train and thoroughly evaluate a language model based on the RoBERTaarchitecture. We compare our LLM, MetRoBERTa, to classical machine learningapproaches utilizing keyword-based and lexicon representations. Our modeloutperforms those methods across all evaluation metrics, providing an averagetopic classification accuracy of 90%. Finally, we provide a value propositionof this work demonstrating how the language model, alongside additional textprocessing tools, can be applied to add structure to open-ended text sources offeedback like Twitter. The framework and results we present provide a pathwayfor an automated, generalizable approach for ingesting, visualizing, andreporting transit riders' feedback at scale, enabling agencies to betterunderstand and improve customer experience.", "output": "MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In human-AI collaboration systems for critical applications, in order toensure minimal error, users should set an operating point based on modelconfidence to determine when the decision should be delegated to human experts.Samples for which model confidence is lower than the operating point would bemanually analysed by experts to avoid mistakes. Such systems can become trulyuseful only if they consider two aspects: models should be confident only forsamples for which they are accurate, and the number of samples delegated toexperts should be minimized. The latter aspect is especially crucial forapplications where available expert time is limited and expensive, such ashealthcare. The trade-off between the model accuracy and the number of samplesdelegated to experts can be represented by a curve that is similar to an ROCcurve, which we refer to as confidence operating characteristic (COC) curve. Inthis paper, we argue that deep neural networks should be trained by taking intoaccount both accuracy and expert load and, to that end, propose a newcomplementary loss function for classification that maximizes the area underthis COC curve. This promotes simultaneously the increase in network accuracyand the reduction in number of samples delegated to humans. We performexperiments on multiple computer vision and medical image datasets forclassification. Our results demonstrate that the proposed loss improvesclassification accuracy and delegates less number of decisions to experts,achieves better out-of-distribution samples detection and on par calibrationperformance compared to existing loss functions.", "output": "Expert load matters: operating networks at high accuracy and low manual effort."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Language-queried audio source separation (LASS) is a new paradigm forcomputational auditory scene analysis (CASA). LASS aims to separate a targetsound from an audio mixture given a natural language query, which provides anatural and scalable interface for digital audio applications. Recent works onLASS, despite attaining promising separation performance on specific sources(e.g., musical instruments, limited classes of audio events), are unable toseparate audio concepts in the open domain. In this work, we introduceAudioSep, a foundation model for open-domain audio source separation withnatural language queries. We train AudioSep on large-scale multimodal datasetsand extensively evaluate its capabilities on numerous tasks including audioevent separation, musical instrument separation, and speech enhancement.AudioSep demonstrates strong separation performance and impressive zero-shotgeneralization ability using audio captions or text labels as queries,substantially outperforming previous audio-queried and language-queried soundseparation models. For reproducibility of this work, we will release the sourcecode, evaluation benchmark and pre-trained model at:", "output": "Separate Anything You Describe."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Solver competitions play a prominent role in assessing and advancing thestate of the art for solving many problems in AI and beyond. Notably, in manyareas of AI, competitions have had substantial impact in guiding research andapplications for many years, and for a solver to be ranked highly in acompetition carries considerable weight. But to which extent can we expectcompetition results to generalise to sets of problem instances different fromthose used in a particular competition? This is the question we investigatehere, using statistical resampling techniques. We show that the rankingsresulting from the standard interpretation of competition results can be verysensitive to even minor changes in the benchmark instance set used as the basisfor assessment and can therefore not be expected to carry over to other samplesfrom the same underlying instance distribution. To address this problem, weintroduce a novel approach to statistically meaningful analysis of competitionresults based on resampling performance data. Our approach produces confidenceintervals of competition scores as well as statistically robust solver rankingswith bounded error. Applied to recent SAT, AI planning and computer visioncompetitions, our analysis reveals frequent statistical ties in solverperformance as well as some inversions of ranks compared to the officialresults based on simple scoring.", "output": "Competitions in AI -- Robustly Ranking Solvers Using Statistical Resampling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In order to respond effectively in the aftermath of a disaster, emergencyservices and relief organizations rely on timely and accurate information aboutthe affected areas. Remote sensing has the potential to significantly reducethe time and effort required to collect such information by enabling a rapidsurvey of large areas. To achieve this, the main challenge is the automaticextraction of relevant information from remotely sensed data. In this work, weshow how the combination of drone-based data with deep learning methods enablesautomated and large-scale situation assessment. In addition, we demonstrate theintegration of onboard image processing techniques for the deployment ofautonomous drone-based aid delivery. The results show the feasibility of arapid and large-scale image analysis in the field, and that onboard imageprocessing can increase the safety of drone-based aid deliveries.", "output": "Drones4Good: Supporting Disaster Relief Through Remote Sensing and AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The COVID-19 pandemic has forced many employees to work from home.Organizational bulk emails now play a critical role to reach employees withcentral information in this work-from-home environment. However, we know fromour own recent work that organizational bulk email has problems: recipientsfail to retain the bulk messages they received from the organization;recipients and senders have different opinions on which bulk messages wereimportant; and communicators lack technology support to better target anddesign messages. In this position paper, first we review the prior work onevaluating, designing, and prototyping organizational communication systems.Second we review our recent findings and some research techniques we founduseful in studying organizational communication. Last we propose a researchagenda to study organizational communications in remote work environment andsuggest some key questions and potential study directions.", "output": "Organizational Bulk Email Systems: Their Role and Performance in Remote Work."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the text-to-image generation field, recent remarkable progress in StableDiffusion makes it possible to generate rich kinds of novel photorealisticimages. However, current models still face misalignment issues (e.g.,problematic spatial relation understanding and numeration failure) in complexnatural scenes, which impedes the high-faithfulness text-to-image generation.Although recent efforts have been made to improve controllability by givingfine-grained guidance (e.g., sketch and scribbles), this issue has not beenfundamentally tackled since users have to provide such guidance informationmanually. In this work, we strive to synthesize high-fidelity images that aresemantically aligned with a given textual prompt without any guidance. Towardthis end, we propose a coarse-to-fine paradigm to achieve layout planning andimage generation. Concretely, we first generate the coarse-grained layoutconditioned on a given textual prompt via in-context learning based on LargeLanguage Models. Afterward, we propose a fine-grained object-interactiondiffusion method to synthesize high-faithfulness images conditioned on theprompt and the automatically generated layout. Extensive experimentsdemonstrate that our proposed method outperforms the state-of-the-art models interms of layout and image generation. Our code and settings are available aturl{", "output": "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The enormous demand for annotated data brought forth by deep learningtechniques has been accompanied by the problem of annotation noise. Althoughthis issue has been widely discussed in machine learning literature, it hasbeen relatively unexplored in the context of \"multi-label classification\" (MLC)tasks which feature more complicated kinds of noise. Additionally, when thedomain in question has certain logical constraints, noisy annotations oftenexacerbate their violations, making such a system unacceptable to an expert.This paper studies the effect of label noise on domain rule violation incidentsin the MLC task, and incorporates domain rules into our learning algorithm tomitigate the effect of noise. We propose the Domain Obedient Self-supervisedTraining (DOST) paradigm which not only makes deep learning models more alignedto domain rules, but also improves learning performance in key metrics andminimizes the effect of annotation noise. This novel approach uses domainguidance to detect offending annotations and deter rule-violating predictionsin a self-supervised manner, thus making it more \"data efficient\" and domaincompliant. Empirical studies, performed over two large scale multi-labelclassification datasets, demonstrate that our method results in improvementacross the board, and often entirely counteracts the effect of noise.", "output": "DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning methods have shown outstanding classification accuracy inmedical imaging problems, which is largely attributed to the availability oflarge-scale datasets manually annotated with clean labels. However, given thehigh cost of such manual annotation, new medical imaging classificationproblems may need to rely on machine-generated noisy labels extracted fromradiology reports. Indeed, many Chest X-ray (CXR) classifiers have already beenmodelled from datasets with noisy labels, but their training procedure is ingeneral not robust to noisy-label samples, leading to sub-optimal models.Furthermore, CXR datasets are mostly multi-label, so current noisy-labellearning methods designed for multi-class problems cannot be easily adapted. Inthis paper, we propose a new method designed for the noisy multi-label CXRlearning, which detects and smoothly re-labels samples from the dataset, whichis then used to train common multi-label classifiers. The proposed methodoptimises a bag of multi-label descriptors (BoMD) to promote their similaritywith the semantic descriptors produced by BERT models from the multi-labelimage annotation. Our experiments on diverse noisy multi-label training setsand clean testing sets show that our model has state-of-the-art accuracy androbustness in many CXR multi-label classification benchmarks.", "output": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Linear Temporal Logic (LTL) is one of the most popular temporal logics, thatcomes into play in a variety of branches of computer science. Among the variousreasons of its widespread use there are its strong foundational properties: LTLis equivalent to counter-free omega-automata, to star-free omega-regularexpressions, and (by Kamp's theorem) to the First-Order Theory of Linear Orders(FO-TLO). Safety and co-safety languages, where a finite prefix suffices toestablish whether a word does not belong or belongs to the language,respectively, play a crucial role in lowering the complexity of problems likemodel checking and reactive synthesis for LTL. SafetyLTL (resp., coSafetyLTL)is a fragment of LTL where only universal (resp., existential) temporalmodalities are allowed, that recognises safety (resp., co-safety) languagesonly. The main contribution of this paper is the introduction of a fragment ofFO-TLO, called SafetyFO, and of its dual coSafetyFO, which are expressivelycomplete with respect to the LTL-definable safety and co-safety languages. Weprove that they exactly characterize SafetyLTL and coSafetyLTL, respectively, aresult that joins Kamp's theorem, and provides a clearer view of thecharacterization of (fragments of) LTL in terms of first-order languages. Inaddition, it gives a direct, compact, and self-contained proof that any safetylanguage definable in LTL is definable in SafetyLTL as well. As a by-product,we obtain some interesting results on the expressive power of the weak tomorrowoperator of SafetyLTL, interpreted over finite and infinite words. Moreover, weprove that, when interpreted over finite words, SafetyLTL (resp. coSafetyLTL)devoid of the tomorrow (resp., weak tomorrow) operator captures the safety(resp., co-safety) fragment of LTL over finite words.", "output": "A first-order logic characterization of safety and co-safety languages."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a unified and compact scene representation for robotics, whereeach object in the scene is depicted by a latent code capturing geometry andappearance. This representation can be decoded for various tasks such as novelview rendering, 3D reconstruction (e.g. recovering depth, point clouds, orvoxel maps), collision checking, and stable grasp prediction. We build ourrepresentation from a single RGB input image at test time by leveraging recentadvances in Neural Radiance Fields (NeRF) that learn category-level priors onlarge multiview datasets, then fine-tune on novel objects from one or fewviews. We expand the NeRF model for additional grasp outputs and explore waysto leverage this representation for robotics. At test-time, we build therepresentation from a single RGB input image observing the scene from only oneviewpoint. We find that the recovered representation allows rendering fromnovel views, including of occluded object parts, and also for predictingsuccessful stable grasps. Grasp poses can be directly decoded from our latentrepresentation with an implicit grasp decoder. We experimented in bothsimulation and real world and demonstrated the capability for robust roboticgrasping using such compact representation. Website:", "output": "One-Shot Neural Fields for 3D Object Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While text-to-image synthesis currently enjoys great popularity amongresearchers and the general public, the security of these models has beenneglected so far. Many text-guided image generation models rely on pre-trainedtext encoders from external sources, and their users trust that the retrievedmodels will behave as promised. Unfortunately, this might not be the case. Weintroduce backdoor attacks against text-guided generative models anddemonstrate that their text encoders pose a major tampering risk. Our attacksonly slightly alter an encoder so that no suspicious model behavior is apparentfor image generations with clean prompts. By then inserting a single charactertrigger into the prompt, e.g., a non-Latin character or emoji, the adversarycan trigger the model to either generate images with pre-defined attributes orimages following a hidden, potentially malicious description. We empiricallydemonstrate the high effectiveness of our attacks on Stable Diffusion andhighlight that the injection process of a single backdoor takes less than twominutes. Besides phrasing our approach solely as an attack, it can also forcean encoder to forget phrases related to certain concepts, such as nudity orviolence, and help to make image generation safer.", "output": "Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In autonomous driving systems, LiDAR and radar play important roles in theperception of the surrounding environment. LiDAR provides accurate 3D spatialsensing information but cannot work in adverse weather like fog. On the otherhand, the radar signal can be diffracted when encountering raindrops or mistparticles thanks to its wavelength, but it suffers from large noise. Recentstate-of-the-art works reveal that fusion of radar and LiDAR can lead to robustdetection in adverse weather. The existing works adopt convolutional neuralnetwork architecture to extract features from each sensor data stream, thenalign and aggregate the two branch features to predict object detectionresults. However, these methods have low accuracy of bounding box estimationsdue to a simple design of label assignment and fusion strategies. In thispaper, we propose a bird's-eye view fusion learning-based anchor box-freeobject detection system, which fuses the feature derived from the radarrange-azimuth heatmap and the LiDAR point cloud to estimate the possibleobjects. Different label assignment strategies have been designed to facilitatethe consistency between the classification of foreground or background anchorpoints and the corresponding bounding box regressions. In addition, theperformance of the proposed object detector is further enhanced by employing anovel interactive transformer module. The superior performance of the methodsproposed in this paper has been demonstrated using the recently publishedOxford Radar RobotCar dataset. Our system's average precision significantlyoutperforms the best state-of-the-art method by 13.1% and 19.0% at IoU of 0.8under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing,respectively.", "output": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Foundation models are redefining how AI systems are built. Practitioners nowfollow a standard procedure to build their machine learning solutions: from apre-trained foundation model, they fine-tune the weights on the target task ofinterest. So, the Internet is swarmed by a handful of foundation modelsfine-tuned on many diverse tasks: these individual fine-tunings exist inisolation without benefiting from each other. In our opinion, this is a missedopportunity, as these specialized models contain rich and diverse features. Inthis paper, we thus propose model ratatouille, a new strategy to recycle themultiple fine-tunings of the same foundation model on diverse auxiliary tasks.Specifically, we repurpose these auxiliary weights as initializations formultiple parallel fine-tunings on the target task; then, we average allfine-tuned weights to obtain the final model. This recycling strategy aims atmaximizing the diversity in weights by leveraging the diversity in auxiliarytasks. Empirically, it improves the state of the art on the reference DomainBedbenchmark for out-of-distribution generalization. Looking forward, this workcontributes to the emerging paradigm of updatable machine learning where, akinto open-source software development, the community collaborates to reliablyupdate machine learning models. Our code is released:", "output": "Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The past decade has witnessed remarkable advancements in deep learning, owingto the emergence of various architectures, layers, objectives, and optimizationtechniques. These consist of a multitude of variations of attention,normalization, skip connections, transformer, and self-supervised learningmethods, among others. Our goal is to furnish a comprehensive survey ofsignificant recent contributions in these domains to individuals with afundamental grasp of deep learning. Our aspiration is that an integrated andcomprehensive approach of influential recent works will facilitate theformation of new connections between different areas of deep learning. In ourdiscussion, we discuss multiple patterns that summarize the key strategies formany of the successful innovations over the last decade. We also include adiscussion on recent commercially built, closed-source models such as OpenAI'sGPT-4 and Google's PaLM 2.", "output": "A Survey of Deep Learning: From Activations to Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Knowledge from diverse application domains is organized as knowledge graphs(KGs) that are stored in RDF engines accessible in the web via SPARQLendpoints. Expressing a well-formed SPARQL query requires information about thegraph structure and the exact URIs of its components, which is impractical forthe average user. Question answering (QA) systems assist by translating naturallanguage questions to SPARQL. Existing QA systems are typically based onapplication-specific human-curated rules, or require prior information,expensive pre-processing and model adaptation for each targeted KG. Therefore,they are hard to generalize to a broad set of applications and KGs.In this paper, we propose KGQAn, a universal QA system that does not need tobe tailored to each target KG. Instead of curated rules, KGQAn introduces anovel formalization of question understanding as a text generation problem toconvert a question into an intermediate abstract representation via a neuralsequence-to-sequence model. We also develop a just-in-time linker that maps atquery time the abstract representation to a SPARQL query for a specific KG,using only the publicly accessible APIs and the existing indices of the RDFstore, without requiring any pre-processing. Our experiments with several realKGs demonstrate that KGQAn is easily deployed and outperforms by a large marginthe state-of-the-art in terms of quality of answers and processing time,especially for arbitrary KGs, unseen during the training.", "output": "A Universal Question-Answering Platform for Knowledge Graphs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large Language Models (LLMs) have sparked significant interest in theirgenerative capabilities, leading to the development of various commercialapplications. The high cost of using the models drives application builders tomaximize the value of generation under a limited inference budget. This paperpresents a study of optimizing inference hyperparameters such as the number ofresponses, temperature and max tokens, which significantly affects theutility/cost of text generation. We design a framework named EcoOptiGen whichleverages economical hyperparameter optimization and cost-based pruning.Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify itseffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAMLlibrary: url{", "output": "Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There is a recently discovered and intriguing phenomenon called NeuralCollapse: at the terminal phase of training a deep neural network forclassification, the within-class penultimate feature means and the associatedclassifier vectors of all flat classes collapse to the vertices of a simplexEquiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenonby fixing the related classifier weights to a pre-computed ETF to induce neuralcollapse and maximize the separation of the learned features when training withimbalanced data. In this work, we propose to fix the linear classifier of adeep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF,and use a cosine similarity-based auxiliary loss to learn hierarchy-awarepenultimate features that collapse to the HAFrame. We demonstrate that ourapproach reduces the mistake severity of the model's predictions whilemaintaining its top-1 accuracy on several datasets of varying scales withhierarchies of heights ranging from 3 to 12. Code:", "output": "Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The warming of the Arctic, also known as Arctic amplification, is led byseveral atmospheric and oceanic drivers. However, the details of its underlyingthermodynamic causes are still unknown. Inferring the causal effects ofatmospheric processes on sea ice melt using fixed treatment effect strategiesleads to unrealistic counterfactual estimations. Such models are also prone tobias due to time-varying confoundedness. Further, the complex non-linearity inEarth science data makes it infeasible to perform causal inference usingexisting marginal structural techniques. In order to tackle these challenges,we propose TCINet - time-series causal inference model to infer causation undercontinuous treatment using recurrent neural networks and a novel probabilisticbalancing technique. Through experiments on synthetic and observational data,we show how our research can substantially improve the ability to quantifyleading causes of Arctic sea ice melt, further paving paths for causalinference in observational Earth science.", "output": "Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose and release a new vulnerable source code dataset. We curate thedataset by crawling security issue websites, extracting vulnerability-fixingcommits and source codes from the corresponding projects. Our new datasetcontains 18,945 vulnerable functions spanning 150 CWEs and 330,492non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295more projects than all previous datasets combined.Combining our new dataset with previous datasets, we present an analysis ofthe challenges and promising research directions of using deep learning fordetecting software vulnerabilities. We study 11 model architectures belongingto 4 families. Our results show that deep learning is still not ready forvulnerability detection, due to high false positive rate, low F1 score, anddifficulty of detecting hard CWEs. In particular, we demonstrate an importantgeneralization challenge for the deployment of deep learning-based models. Weshow that increasing the volume of training data may not further improve theperformance of deep learning models for vulnerability detection, but might beuseful to improve the generalization ability to unseen projects.We also identify hopeful future research directions. We demonstrate thatlarge language models (LLMs) are a promising research direction for ML-basedvulnerability detection, outperforming Graph Neural Networks (GNNs) withcode-structure features in our experiments. Moreover, developing source codespecific pre-training objectives is a promising research direction to improvethe vulnerability detection performance.", "output": "DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the increasing number and sophistication of malware attacks, malwaredetection systems based on machine learning (ML) grow in importance. At thesame time, many popular ML models used in malware classification are supervisedsolutions. These supervised classifiers often do not generalize well to novelmalware. Therefore, they need to be re-trained frequently to detect new malwarespecimens, which can be time-consuming. Our work addresses this problem in ahybrid framework of theoretical Quantum ML, combined with feature selectionstrategies to reduce the data size and malware classifier training time. Thepreliminary results show that VQC with XGBoost selected features can get a78.91% test accuracy on the simulator. The average accuracy for the modeltrained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM5 qubits machines.", "output": "Can Feature Engineering Help Quantum Machine Learning for Malware Detection?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Zero-shot sketch-based image retrieval (ZS-SBIR) is challenging due to thecross-domain nature of sketches and photos, as well as the semantic gap betweenseen and unseen image distributions. Previous methods fine-tune pre-trainedmodels with various side information and learning strategies to learn a compactfeature space that is shared between the sketch and photo domains and bridgesseen and unseen classes. However, these efforts are inadequate in adaptingdomains and transferring knowledge from seen to unseen classes. In this paper,we present an effective ``Adapt and Align'' approach to address the keychallenges. Specifically, we insert simple and lightweight domain adapters tolearn new abstract concepts of the sketch domain and improve cross-domainrepresentation capabilities. Inspired by recent advances in image-textfoundation models (e.g., CLIP) on zero-shot scenarios, we explicitly align thelearned image embedding with a more semantic text embedding to achieve thedesired knowledge transfer from seen to unseen classes. Extensive experimentson three benchmark datasets and two popular backbones demonstrate thesuperiority of our method in terms of retrieval accuracy and flexibility.", "output": "Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a temporally layered architecture (TLA) for temporally adaptivecontrol with minimal energy expenditure. The TLA layers a fast and a slowpolicy together to achieve temporal abstraction that allows each layer to focuson a different time scale. Our design draws on the energy-saving mechanism ofthe human brain, which executes actions at different timescales depending onthe environment's demands. We demonstrate that beyond energy saving, TLAprovides many additional advantages, including persistent exploration, fewerrequired decisions, reduced jerk, and increased action repetition. We evaluateour method on a suite of continuous control tasks and demonstrate thesignificant advantages of TLA over existing methods when measured over multipleimportant metrics. We also introduce a multi-objective score to qualitativelyassess continuous control policies and demonstrate a significantly better scorefor TLA. Our training algorithm uses minimal communication between the slow andfast layers to train both policies simultaneously, making it viable for futureapplications in distributed control.", "output": "Temporally Layered Architecture for Efficient Continuous Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With read-aloud speech synthesis achieving high naturalness scores, there isa growing research interest in synthesising spontaneous speech. However, humanspontaneous face-to-face conversation has both spoken and non-verbal aspects(here, co-speech gestures). Only recently has research begun to explore thebenefits of jointly synthesising these two modalities in a single system. Theprevious state of the art used non-probabilistic methods, which fail to capturethe variability of human speech and motion, and risk producing oversmoothingartefacts and sub-optimal synthesis quality. We present the firstdiffusion-based probabilistic model, called Diff-TTSG, that jointly learns tosynthesise speech and gestures together. Our method can be trained on smalldatasets from scratch. Furthermore, we describe a set of careful uni- andmulti-modal subjective tests for evaluating integrated speech and gesturesynthesis systems, and use them to validate our proposed approach. Please see for video examples, data, and code.", "output": "Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement learning (RL) for physical design of silicon chips in a Google2021 Nature paper stirred controversy due to poorly documented claims thatraised eyebrows and attracted critical media coverage. The Nature paperwithheld most inputs needed to produce reported results and some critical stepsin the methodology. But two separate evaluations filled in the gaps anddemonstrated that Google RL lags behind human designers, behind a well-knownalgorithm (Simulated Annealing), and also behind generally-available commercialsoftware, while taking longer to run. Crosschecked data show that the integrityof the Nature paper is substantially undermined owing to errors in conduct,analysis and reporting. Before publishing, Google rebuffed internal allegationsof fraud.", "output": "The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time series are the primary data type used to record dynamic systemmeasurements and generated in great volume by both physical sensors and onlineprocesses (virtual sensors). Time series analytics is therefore crucial tounlocking the wealth of information implicit in available data. With the recentadvancements in graph neural networks (GNNs), there has been a surge inGNN-based approaches for time series analysis. These approaches can explicitlymodel inter-temporal and inter-variable relationships, which traditional andother deep neural network-based methods struggle to do. In this survey, weprovide a comprehensive review of graph neural networks for time seriesanalysis (GNN4TS), encompassing four fundamental dimensions: forecasting,classification, anomaly detection, and imputation. Our aim is to guidedesigners and practitioners to understand, build applications, and advanceresearch of GNN4TS. At first, we provide a comprehensive task-oriented taxonomyof GNN4TS. Then, we present and discuss representative research works andintroduce mainstream applications of GNN4TS. A comprehensive discussion ofpotential future research directions completes the survey. This survey, for thefirst time, brings together a vast array of knowledge on GNN-based time seriesresearch, highlighting foundations, practical applications, and opportunitiesof graph neural networks for time series analysis.", "output": "A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Over the last decade, there has been a vast increase in eating disorderdiagnoses and eating disorder-attributed deaths, reaching their zenith duringthe Covid-19 pandemic. This immense growth derived in part from the stressorsof the pandemic but also from increased exposure to social media, which is rifewith content that promotes eating disorders. This study aimed to create amultimodal deep learning model that can determine if a given social media postpromotes eating disorders based on a combination of visual and textual data. Alabeled dataset of Tweets was collected from Twitter, upon which twelve deeplearning models were trained and tested. Based on model performance, the mosteffective deep learning model was the multimodal fusion of the RoBERTa naturallanguage processing model and the MaxViT image classification model, attainingaccuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViTfusion model, deployed to classify an unlabeled dataset of posts from thesocial media sites Tumblr and Reddit, generated results akin to those ofprevious research studies that did not employ artificial intelligence-basedtechniques, indicating that deep learning models can develop insights congruentto those of researchers. Additionally, the model was used to conduct atimeseries analysis of yet unseen Tweets from eight Twitter hashtags,uncovering that, since 2014, the relative abundance of content that promoteseating disorders has decreased drastically within those communities. Despitethis reduction, by 2018, content that promotes eating disorders had eitherstopped declining or increased in ampleness anew on these hashtags.", "output": "A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents AutoHint, a novel framework for automatic promptengineering and optimization for Large Language Models (LLM). While LLMs havedemonstrated remarkable ability in achieving high-quality annotation in varioustasks, the key to applying this ability to specific tasks lies in developinghigh-quality prompts. Thus we propose a framework to inherit the merits of bothin-context learning and zero-shot learning by incorporating enrichedinstructions derived from input-output demonstrations to optimize originalprompt. We refer to the enrichment as the hint and propose a framework toautomatically generate the hint from labeled data. More concretely, startingfrom an initial prompt, our method first instructs a LLM to deduce new hintsfor selected samples from incorrect predictions, and then summarizes fromper-sample hints and adds the results back to the initial prompt to form a new,enriched instruction. The proposed method is evaluated on the BIG-BenchInstruction Induction dataset for both zero-shot and few-short prompts, whereexperiments demonstrate our method is able to significantly boost accuracy formultiple tasks.", "output": "AutoHint: Automatic Prompt Optimization with Hint Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Leveraging network information for predictive modeling has become widespreadin many domains. Within the realm of referral and targeted marketing,influencer detection stands out as an area that could greatly benefit from theincorporation of dynamic network representation due to the ongoing developmentof customer-brand relationships. To elaborate this idea, we introduceINFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic GraphNeural Networks that combines Graph Neural Networks (GNN) and Recurrent NeuralNetworks (RNN) with weighted loss functions, the Synthetic MinorityOversampling TEchnique (SMOTE) adapted for graph data, and a carefully craftedrolling-window strategy. To evaluate predictive performance, we utilize aunique corporate data set with networks of three cities and derive aprofit-driven evaluation methodology for influencer prediction. Our resultsshow how using RNN to encode temporal attributes alongside GNNs significantlyimproves predictive performance. We compare the results of various models todemonstrate the importance of capturing graph representation, temporaldependencies, and using a profit-driven methodology for evaluation.", "output": "INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Restricting the variance of a policy's return is a popular choice inrisk-averse Reinforcement Learning (RL) due to its clear mathematicaldefinition and easy interpretability. Traditional methods directly restrict thetotal return variance. Recent methods restrict the per-step reward variance asa proxy. We thoroughly examine the limitations of these variance-based methods,such as sensitivity to numerical scale and hindering of policy learning, andpropose to use an alternative risk measure, Gini deviation, as a substitute. Westudy various properties of this new risk measure and derive a policy gradientalgorithm to minimize it. Empirical evaluation in domains where risk-aversioncan be clearly defined, shows that our algorithm can mitigate the limitationsof variance-based risk measures and achieves high return with low risk in termsof variance and Gini deviation when others fail to learn a reasonable policy.", "output": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Visual Reinforcement Learning (Visual RL), coupled with high-dimensionalobservations, has consistently confronted the long-standing challenge ofout-of-distribution generalization. Despite the focus on algorithms aimed atresolving visual generalization problems, we argue that the devil is in theexisting benchmarks as they are restricted to isolated tasks and generalizationcategories, undermining a comprehensive evaluation of agents' visualgeneralization capabilities. To bridge this gap, we introduce RL-ViGen: a novelReinforcement Learning Benchmark for Visual Generalization, which containsdiverse tasks and a wide spectrum of generalization types, thereby facilitatingthe derivation of more reliable conclusions. Furthermore, RL-ViGen incorporatesthe latest generalization visual RL algorithms into a unified framework, underwhich the experiment results indicate that no single existing algorithm hasprevailed universally across tasks. Our aspiration is that RL-ViGen will serveas a catalyst in this area, and lay a foundation for the future creation ofuniversal visual generalization RL agents suitable for real-world scenarios.Access to our code and implemented algorithms is provided at", "output": "RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing action recognition methods are typically actor-specific due to theintrinsic topological and apparent differences among the actors. This requiresactor-specific pose estimation (e.g., humans vs. animals), leading tocumbersome model design complexity and high maintenance costs. Moreover, theyoften focus on learning the visual modality alone and single-labelclassification whilst neglecting other available information sources (e.g.,class name text) and the concurrent occurrence of multiple actions. To overcomethese limitations, we propose a new approach called 'actor-agnostic multi-modalmulti-label action recognition,' which offers a unified solution for varioustypes of actors, including humans and animals. We further formulate a novelMulti-modal Semantic Query Network (MSQNet) model in a transformer-based objectdetection framework (e.g., DETR), characterized by leveraging visual andtextual modalities to represent the action classes better. The elimination ofactor-specific model designs is a key advantage, as it removes the need foractor pose estimation altogether. Extensive experiments on five publiclyavailable benchmarks show that our MSQNet consistently outperforms the priorarts of actor-specific alternatives on human and animal single- and multi-labelaction recognition tasks by up to 50%. Code will be released at", "output": "Actor-agnostic Multi-label Action Recognition with Multi-modal Query."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recent large language models (LLMs), e.g., ChatGPT, have been able togenerate human-like and fluent responses when provided with specificinstructions. While admitting the convenience brought by technologicaladvancement, educators also have concerns that students might leverage LLMs tocomplete their writing assignments and pass them off as their original work.Although many AI content detection studies have been conducted as a result ofsuch concerns, most of these prior studies modeled AI content detection as aclassification problem, assuming that a text is either entirely human-writtenor entirely AI-generated. In this study, we investigated AI content detectionin a rarely explored yet realistic setting where the text to be detected iscollaboratively written by human and generative LLMs (i.e., hybrid text). Wefirst formalized the detection task as identifying the transition pointsbetween human-written content and AI-generated content from a given hybrid text(boundary detection). Then we proposed a two-step approach where we (1)separated AI-generated content from human-written content during the encodertraining process; and (2) calculated the distances between every two adjacentprototypes and assumed that the boundaries exist between the two adjacentprototypes that have the furthest distance from each other. Through extensiveexperiments, we observed the following main findings: (1) the proposed approachconsistently outperformed the baseline methods across different experimentsettings; (2) the encoder training process can significantly boost theperformance of the proposed approach; (3) when detecting boundaries forsingle-boundary hybrid essays, the proposed approach could be enhanced byadopting a relatively large prototype size, leading to a 22% improvement in theIn-Domain evaluation and an 18% improvement in the Out-of-Domain evaluation.", "output": "Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The curse-of-dimensionality (CoD) taxes computational resources heavily withexponentially increasing computational cost as the dimension increases. Thisposes great challenges in solving high-dimensional PDEs as Richard Bellmanfirst pointed out over 60 years ago. While there has been some recent successin solving numerically partial differential equations (PDEs) in highdimensions, such computations are prohibitively expensive, and true scaling ofgeneral nonlinear PDEs to high dimensions has never been achieved. In thispaper, we develop a new method of scaling up physics-informed neural networks(PINNs) to solve arbitrary high-dimensional PDEs. The new method, calledStochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEsinto pieces corresponding to different dimensions and samples randomly a subsetof these dimensional pieces in each iteration of training PINNs. Wetheoretically prove the convergence guarantee and other desired properties ofthe proposed method. We experimentally demonstrate that the proposed methodallows us to solve many notoriously hard high-dimensional PDEs, including theHamilton-Jacobi-Bellman (HJB) and the Schr\"{o}dinger equations in thousands ofdimensions very fast on a single GPU using the PINNs mesh-free approach. Forinstance, we solve nontrivial nonlinear PDEs (one HJB equation and oneBlack-Scholes equation) in 100,000 dimensions in 6 hours on a single GPU usingSDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGDcan be applied to any current and future variants of PINNs to scale them up forarbitrary high-dimensional PDEs.", "output": "Tackling the Curse of Dimensionality with Physics-Informed Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-agent reinforcement learning (MARL) has achieved promising results inrecent years. However, most existing reinforcement learning methods require alarge amount of data for model training. In addition, data-efficientreinforcement learning requires the construction of strong inductive biases,which are ignored in the current MARL approaches. Inspired by the symmetryphenomenon in multi-agent systems, this paper proposes a framework forexploiting prior knowledge by integrating data augmentation and a well-designedconsistency loss into the existing MARL methods. In addition, the proposedframework is model-agnostic and can be applied to most of the current MARLalgorithms. Experimental tests on multiple challenging tasks demonstrate theeffectiveness of the proposed framework. Moreover, the proposed framework isapplied to a physical multi-robot testbed to show its superiority.", "output": "ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time series analysis is a fundamental task in various application domains,and deep learning approaches have demonstrated remarkable performance in thisarea. However, many real-world time series data exhibit significant periodic orquasi-periodic dynamics that are often not adequately captured by existing deeplearning-based solutions. This results in an incomplete representation of theunderlying dynamic behaviors of interest. To address this gap, we propose anunsupervised method called Floss that automatically regularizes learnedrepresentations in the frequency domain. The Floss method first automaticallydetects major periodicities from the time series. It then employs periodicshift and spectral density similarity measures to learn meaningfulrepresentations with periodic consistency. In addition, Floss can be easilyincorporated into both supervised, semi-supervised, and unsupervised learningframeworks. We conduct extensive experiments on common time seriesclassification, forecasting, and anomaly detection tasks to demonstrate theeffectiveness of Floss. We incorporate Floss into several representative deeplearning solutions to justify our design choices and demonstrate that it iscapable of automatically discovering periodic dynamics and improvingstate-of-the-art deep learning models.", "output": "Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning (DL) has been successfully applied to encrypted network trafficclassification in experimental settings. However, in production use, it hasbeen shown that a DL classifier's performance inevitably decays over time.Re-training the model on newer datasets has been shown to only partiallyimprove its performance. Manually re-tuning the model architecture to meet theperformance expectations on newer datasets is time-consuming and requiresdomain expertise. We propose AutoML4ETC, a novel tool to automatically designefficient and high-performing neural architectures for encrypted trafficclassification. We define a novel, powerful search space tailored specificallyfor the near real-time classification of encrypted traffic using packet headerbytes. We show that with different search strategies over our search space,AutoML4ETC generates neural architectures that outperform the state-of-the-artencrypted traffic classifiers on several datasets, including public benchmarkdatasets and real-world TLS and QUIC traffic collected from the Orange mobilenetwork. In addition to being more accurate, AutoML4ETC's architectures aresignificantly more efficient and lighter in terms of the number of parameters.Finally, we make AutoML4ETC publicly available for future research.", "output": "AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Cross-domain and cross-compositional generalization of Text-to-SQL semanticparsing is a challenging task. Existing Large Language Model (LLM) basedsolutions rely on inference-time retrieval of few-shot exemplars from thetraining set to synthesize a run-time prompt for each Natural Language (NL)test query. In contrast, we devise an algorithm which performs offline samplingof a minimal set-of few-shots from the training data, with complete coverage ofSQL clauses, operators and functions, and maximal domain coverage within theallowed token length. This allows for synthesis of a fixed Generic Prompt (GP),with a diverse set-of exemplars common across NL test queries, avoidingexpensive test time exemplar retrieval. We further auto-adapt the GP to thetarget database domain (DA-GP), to better handle cross-domain generalization;followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handlecross-compositional generalization. The synthesis of LTMP-DA-GP is an offlinetask, to be performed one-time per new database with minimal humanintervention. Our approach demonstrates superior performance on the KaggleDBQAdataset, designed to evaluate generalizability for the Text-to-SQL task. Wefurther showcase consistent performance improvement of LTMP-DA-GP over GP,across LLMs and databases of KaggleDBQA, highlighting the efficacy and modelagnostic benefits of our prompt based adapt and decompose approach.", "output": "Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Anomaly detection is a challenging task, particularly in systems with manyvariables. Anomalies are outliers that statistically differ from the analyzeddata and can arise from rare events, malfunctions, or system misuse. This studyinvestigated the ability to detect anomalies in global financial marketsthrough Graph Neural Networks (GNN) considering an uncertainty scenariomeasured by a nonextensive entropy. The main findings show that the complexstructure of highly correlated assets decreases in a crisis, and the number ofanomalies is statistically different for nonextensive entropy parametersconsidering before, during, and after crisis.", "output": "Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study Off-Policy Evaluation (OPE) in contextual bandit settings with largeaction spaces. The benchmark estimators suffer from severe bias and variancetradeoffs. Parametric approaches suffer from bias due to difficulty specifyingthe correct model, whereas ones with importance weight suffer from variance. Toovercome these limitations, Marginalized Inverse Propensity Scoring (MIPS) wasproposed to mitigate the estimator's variance via embeddings of an action. Tomake the estimator more accurate, we propose the doubly robust estimator ofMIPS called the Marginalized Doubly Robust (MDR) estimator. Theoreticalanalysis shows that the proposed estimator is unbiased under weaker assumptionsthan MIPS while maintaining variance reduction against IPS, which was the mainadvantage of MIPS. The empirical experiment verifies the supremacy of MDRagainst existing estimators.", "output": "Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recommendation system is a fundamental functionality of online platforms.With the development of computing power of mobile phones, some researchers havedeployed recommendation algorithms on users' mobile devices to address theproblems of data transmission delay and pagination trigger mechanism. However,the existing edge-side mobile rankings cannot completely solve the problem ofpagination trigger mechanism. The mobile ranking can only sort the items on thecurrent page, and the fixed set of candidate items limits the performance ofthe mobile ranking. Besides, after the user has viewed the items of interest tothe user on the current page, the user refresh to get a new page of items. Thiswill affect the user's immersive experience because the user is not satisfiedwith the left items on the current page. In order to address the problem ofpagination trigger mechanism, we propose a completely new module in thepipeline of recommender system named Mobile Supply. The pipeline of recommendersystem is extended to \"retrival-&gt;pre-ranking-&gt;ranking-&gt;re-ranking-&gt;MobileSupply-&gt;mobile ranking\". Specifically, we introduce the concept of list valueand use point-wise paradigm to approximate list-wise estimation to calculatethe maximum revenue that can be achieved by mobile ranking for the currentpage. We also design a new mobile ranking approach named device-aware mobileranking considering the differences of mobile devices tailored to the newpipeline. Extensive offline and online experiments show the superiority of ourproposed method and prove that Mobile Supply can further improve theperformance of edge-side recommender system and user experience. Mobile Supplyhas been deployed on the homepage of a large-scale online food platform and hasyielded considerable profits in our business.", "output": "Mobile Supply: The Last Piece of Jigsaw of Recommender System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose an exhaustive methodology that leverages all levels of featureabstraction, targeting an enhancement in the generalizability of imageclassification to unobserved hospitals. Our approach incorporatesaugmentation-based self-supervision with common distribution shifts inhistopathology scenarios serving as the pretext task. This enables us to deriveinvariant features from training images without relying on training labels,thereby covering different abstraction levels. Moving onto the subsequentabstraction level, we employ a domain alignment module to facilitate furtherextraction of invariant features across varying training hospitals. Torepresent the highly specific features of participating hospitals, an encoderis trained to classify hospital labels, independent of their diagnostic labels.The features from each of these encoders are subsequently disentangled tominimize redundancy and segregate the features. This representation, whichspans a broad spectrum of semantic information, enables the development of amodel demonstrating increased robustness to unseen images from disparatedistributions. Experimental results from the PACS dataset (a domaingeneralization benchmark), a synthetic dataset created by applyinghistopathology-specific jitters to the MHIST dataset (defining differentdomains with varied distribution shifts), and a Renal Cell Carcinoma datasetderived from four image repositories from TCGA, collectively indicate that ourproposed model is adept at managing varying levels of image granularity. Thus,it shows improved generalizability when faced with new, out-of-distributionhospital images.", "output": "ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A major challenge in Explainable AI is in correctly interpreting activationsof hidden neurons: accurate interpretations would provide insights into thequestion of what a deep learning system has internally detected as relevant onthe input, demystifying the otherwise black-box character of deep learningsystems. The state of the art indicates that hidden node activations can, insome cases, be interpretable in a way that makes sense to humans, butsystematic automated methods that would be able to hypothesize and verifyinterpretations of hidden neuron activations are underexplored. In this paper,we provide such a method and demonstrate that it provides meaningfulinterpretations. Our approach is based on using large-scale backgroundknowledge approximately 2 million classes curated from the Wikipedia concepthierarchy together with a symbolic reasoning approach called Concept Inductionbased on description logics, originally developed for applications in theSemantic Web field. Our results show that we can automatically attachmeaningful labels from the background knowledge to individual neurons in thedense layer of a Convolutional Neural Network through a hypothesis andverification process.", "output": "Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "At the Worldwide Developers Conference (WWDC) in June 2023, Apple introducedthe Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, morespecifically it is a Virtual Reality (VR) device with an additional VideoSee-Through (VST) capability. The VST capability turns the Vision Pro also intoan Augmented Reality (AR) device. The AR feature is enabled by streaming thereal world via cameras to the (VR) screens in front of the user's eyes. This isof course not unique and similar to other devices, like the Varjo XR-3.Nevertheless, the Vision Pro has some interesting features, like an inside-outscreen that can show the headset wearers' eyes to \"outsiders\" or a button onthe top, called \"Digital Crown\", that allows you to seamlessly blend digitalcontent with your physical space by turning it. In addition, it is untethered,except for the cable to the battery, which makes the headset more agile,compared to the Varjo XR-3. This could actually come closer to the \"UltimateDisplay\", which Ivan Sutherland had already sketched in 1965. Not available tothe public yet, like the Ultimate Display, we want to take a look into thecrystal ball in this perspective to see if it can overcome some clinicalchallenges that - especially - AR still faces in the medical domain, but alsogo beyond and discuss if the Vision Pro could support clinicians in essentialtasks to spend more time with their patients.", "output": "Apple Vision Pro for Healthcare: \"The Ultimate Display\"? -- Entering the Wonderland of Precision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While language models are powerful and versatile, they often fail to addresshighly complex problems. This is because solving complex problems requiresdeliberate thinking, which has been only minimally guided during training. Inthis paper, we propose a new method called Cumulative Reasoning (CR), whichemploys language models in a cumulative and iterative manner to emulate humanthought processes. By decomposing tasks into smaller components, CR streamlinesthe problem-solving process, rendering it both more manageable and effective.For logical inference tasks, CR consistently outperforms existing methods withan improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% onthe curated FOLIO wiki dataset. In the context of the Game of 24, CR achievesan accuracy of 94%, which signifies a substantial enhancement of 20% over theprevious state-of-the-art method.", "output": "Cumulative Reasoning with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One aim of Process Mining (PM) is the discovery of process models from eventlogs of information systems. PM has been successfully applied toprocess-oriented enterprise systems but is less suited for communication- anddocument-oriented Enterprise Collaboration Systems (ECS). ECS event logs arevery fine-granular and PM applied to their logs results in spaghetti models. Acommon solution for this is event abstraction, i.e., converting low-level logsinto more abstract high-level logs before running discovery algorithms. ECSlogs come with special characteristics that have so far not been fullyaddressed by existing event abstraction approaches. We aim to close this gapwith a tailored ECS event abstraction (ECSEA) approach that trains a model bycomparing recorded actual user activities (high-level traces) with thesystem-generated low-level traces (extracted from the ECS). The model allows usto automatically convert future low-level traces into an abstracted high-levellog that can be used for PM. Our evaluation shows that the algorithm producesaccurate results. ECSEA is a preprocessing method that is essential for theinterpretation of collaborative work activity in ECS, which we call SocialProcess Mining.", "output": "Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) has been widely deployed to enable machine learningtraining on sensitive data across distributed devices. However, thedecentralized learning paradigm and heterogeneity of FL further extend theattack surface for backdoor attacks. Existing FL attack and defensemethodologies typically focus on the whole model. None of them recognizes theexistence of backdoor-critical (BC) layers-a small subset of layers thatdominate the model vulnerabilities. Attacking the BC layers achieves equivalenteffects as attacking the whole model but at a far smaller chance of beingdetected by state-of-the-art (SOTA) defenses. This paper proposes a generalin-situ approach that identifies and verifies BC layers from the perspective ofattackers. Based on the identified BC layers, we carefully craft a new backdoorattack methodology that adaptively seeks a fundamental balance betweenattacking effects and stealthiness under various defense strategies. Extensiveexperiments show that our BC layer-aware backdoor attacks can successfullybackdoor FL under seven SOTA defenses with only 10% malicious clients andoutperform the latest backdoor attack methods.", "output": "Backdoor Federated Learning by Poisoning Backdoor-Critical Layers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Guided synthesis of high-quality 3D scenes is a challenging task. Diffusionmodels have shown promise in generating diverse data, including 3D scenes.However, current methods rely directly on text embeddings for controlling thegeneration, limiting the incorporation of complex spatial relationships betweenobjects. We propose a novel approach for 3D scene diffusion guidance usingscene graphs. To leverage the relative spatial information the scene graphsprovide, we make use of relational graph convolutional blocks within ourdenoising network. We show that our approach significantly improves thealignment between scene description and generated scene.", "output": "3D Scene Diffusion Guidance using Scene Graphs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We unveil how generalizable AI can be used to improve multi-view 3Dpedestrian detection in unlabeled target scenes. One way to increasegeneralization to new scenes is to automatically label target data, which canthen be used for training a detector model. In this context, we investigate twoapproaches for automatically labeling target data: pseudo-labeling using asupervised detector and automatic labeling using an untrained detector (thatcan be applied out of the box without any training). We adopt a trainingframework for optimizing detector models using automatic labeling procedures.This framework encompasses different training sets/modes and multi-roundautomatic labeling strategies. We conduct our analyses on thepublicly-available WILDTRACK and MultiviewX datasets. We show that, by usingthe automatic labeling approach based on an untrained detector, we can obtainsuperior results than directly using the untrained detector or a detectortrained with an existing labeled source dataset. It achieved a MODA about 4%and 1% better than the best existing unlabeled method when using WILDTRACK andMultiviewX as target datasets, respectively.", "output": "Toward unlabeled multi-view 3D pedestrian detection by generalizable AI: techniques and performance analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we describe a method for large-scale 3D cell-tracking through asegmentation selection approach. The proposed method is effective at trackingcells across large microscopy datasets on two fronts: (i) It can solve problemscontaining millions of segmentation instances in terabyte-scale 3D+t datasets;(ii) It achieves competitive results with or without deep learning, whichrequires 3D annotated data, that is scarce in the fluorescence microscopyfield. The proposed method computes cell tracks and segments using a hierarchyof segmentation hypotheses and selects disjoint segments by maximizing theoverlap between adjacent frames. We show that this method achievesstate-of-the-art results in 3D images from the cell tracking challenge and hasa faster integer linear programming formulation. Moreover, our framework isflexible and supports segmentations from off-the-shelf cell segmentation modelsand can combine them into an ensemble that improves tracking. The code isavailable ", "output": "Large-Scale Multi-Hypotheses Cell Tracking Using Ultrametric Contours Maps."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning for unsupervised image segmentation remains challenging due tothe absence of human labels. The common idea is to train a segmentation head,with the supervision of pixel-wise pseudo-labels generated based on therepresentation of self-supervised backbones. By doing so, the model performancedepends much on the distance between the distributions of target datasets andthe pre-training dataset (e.g., ImageNet). In this work, we investigate a newtask, namely unsupervised camouflaged object segmentation (UCOS), where thetarget objects own a common rarely-seen attribute, i.e., camouflage.Unsurprisingly, we find that the state-of-the-art unsupervised models strugglein adapting UCOS, due to the domain gap between the properties of generic andcamouflaged objects. To this end, we formulate the UCOS as a source-freeunsupervised domain adaptation task (UCOS-DA), where both source labels andtarget labels are absent during the whole model training process. Specifically,we define a source model consisting of self-supervised vision transformerspre-trained on ImageNet. On the other hand, the target domain includes a simplelinear layer (i.e., our target model) and unlabeled camouflaged objects. Wethen design a pipeline for foreground-background-contrastive self-adversarialdomain adaptation, to achieve robust UCOS. As a result, our baseline modelachieves superior segmentation performance when compared with competingunsupervised models on the UCOS benchmark, with the training set which's scaleis only one tenth of the supervised COS counterpart.", "output": "Unsupervised Camouflaged Object Segmentation as Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Today, the great performance of Deep Neural Networks(DNN) has been proven invarious fields. One of its most attractive applications is to produce artisticdesigns. A carpet that is known as a piece of art is one of the most importantitems in a house, which has many enthusiasts all over the world. The firststage of producing a carpet is to prepare its map, which is a difficult,time-consuming, and expensive task. In this research work, our purpose is touse DNN for generating a Modern Persian Carpet Map. To reach this aim, threedifferent DNN style transfer methods are proposed and compared against eachother. In the proposed methods, the Style-Swap method is utilized to create theinitial carpet map, and in the following, to generate more diverse designs,methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition,some methods are examined and introduced for coloring the produced carpet maps.The designed maps are evaluated via the results of filled questionnaires wherethe outcomes of user evaluations confirm the popularity of generated carpetmaps. Eventually, for the first time, intelligent methods are used in producingcarpet maps, and it reduces human intervention. The proposed methods cansuccessfully produce diverse carpet designs, and at a higher speed thantraditional ways.", "output": "Generating Modern Persian Carpet Map by Style-transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Drones are being used to assess the situation in various disasters. In thisstudy, we investigate a method to automatically estimate the damage status ofpeople based on their actions in aerial drone images in order to understanddisaster sites faster and save labor. We constructed a new dataset of aerialimages of human actions in a hypothetical disaster that occurred in an urbanarea, and classified the human damage status using 3D ResNet. The resultsshowed that the status with characteristic human actions could be classifiedwith a recall rate of more than 80%, while other statuses with similar humanactions could only be classified with a recall rate of about 50%. In addition,a cloud-based VR presentation application suggested the effectiveness of usingdrones to understand the disaster site and estimate the human condition.", "output": "Estimation of Human Condition at Disaster Site Using Aerial Drone Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spotting facial micro-expression from videos finds various potentialapplications in fields including clinical diagnosis and interrogation,meanwhile this task is still difficult due to the limited scale of trainingdata. To solve this problem, this paper tries to formulate a new task calledmicro-expression generation and then presents a strong baseline which combinesthe first order motion model with facial prior knowledge. Given a target face,we intend to drive the face to generate micro-expression videos according tothe motion patterns of source videos. Specifically, our new model involvesthree modules. First, we extract facial prior features from a region focusingmodule. Second, we estimate facial motion using key points and local affinetransformations with a motion prediction module. Third, expression generationmodule is used to drive the target face to generate videos. We train our modelon public CASME II, SAMM and SMIC datasets and then use the model to generatenew micro-expression videos for evaluation. Our model achieves the first placein the Facial Micro-Expression Challenge 2021 (MEGC2021), where our superiorperformance is verified by three experts with Facial Action Coding Systemcertification. Source code is provided in", "output": "Facial Prior Based First Order Motion Model for Micro-expression Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an efficient way of detecting directed objects bypredicting their center coordinates and direction angle. Since the objects areof uniform size, the proposed model works without predicting the object's widthand height. The dataset used for this problem is presented in HoneybeeSegmentation and Tracking Datasets project. One of the contributions of thiswork is an examination of the ability of the standard real-time objectdetection architecture like YoloV7 to be customized for position and directiondetection. A very efficient, tiny version of the architecture is used in thisapproach. Moreover, only one of three detection heads without anchors issufficient for this task. We also introduce the extended Skew Intersection overUnion (SkewIoU) calculation for rotated boxes - directed IoU (DirIoU), whichincludes an absolute angle difference. DirIoU is used both in the matchingprocedure of target and predicted bounding boxes for mAP calculation, and inthe NMS filtering procedure. The code and models are available at", "output": "YUDO: YOLO for Uniform Directed Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformers have become the primary backbone of the computer visioncommunity due to their impressive performance. However, the unfriendlycomputation cost impedes their potential in the video recognition domain. Tooptimize the speed-accuracy trade-off, we propose Semantic-aware TemporalAccumulation score (STA) to prune spatio-temporal tokens integrally. STA scoreconsiders two critical factors: temporal redundancy and semantic importance.The former depicts a specific region based on whether it is a new occurrence ora seen entity by aggregating token-to-token similarity in consecutive frameswhile the latter evaluates each token based on its contribution to the overallprediction. As a result, tokens with higher scores of STA carry more temporalredundancy as well as lower semantics thus being pruned. Based on the STAscore, we are able to progressively prune the tokens without introducing anyadditional parameters or requiring further re-training. We directly apply theSTA module to off-the-shelf ViT and VideoSwin backbones, and the empiricalresults on Kinetics-400 and Something-Something V2 achieve over 30% computationreduction with a negligible ~0.2% accuracy drop. The code is released at", "output": "Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Noisy labels hurt deep learning-based supervised image classificationperformance as the models may overfit the noise and learn corrupted featureextractors. For natural image classification training with noisy labeled data,model initialization with contrastive self-supervised pretrained weights hasshown to reduce feature corruption and improve classification performance.However, no works have explored: i) how other self-supervised approaches, suchas pretext task-based pretraining, impact the learning with noisy label, andii) any self-supervised pretraining methods alone for medical images in noisylabel settings. Medical images often feature smaller datasets and subtle interclass variations, requiring human expertise to ensure correct classification.Thus, it is not clear if the methods improving learning with noisy labels innatural image datasets such as CIFAR would also help with medical images. Inthis work, we explore contrastive and pretext task-based self-supervisedpretraining to initialize the weights of a deep learning classification modelfor two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100Ktissue histological images and COVID-QU-Ex chest X-ray images. Our results showthat models initialized with pretrained weights obtained from self-supervisedlearning can effectively learn better features and improve robustness againstnoisy labels.", "output": "Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Visual recognition models are prone to learning spurious correlations inducedby an imbalanced training set where certain groups (eg Females) areunder-represented in certain classes (eg Programmers). Generative models offera promising direction in mitigating this bias by generating synthetic data forthe minority samples and thus balancing the training set. However, prior workthat uses these approaches overlooks that visual recognition models could oftenlearn to differentiate between real and synthetic images and thus fail tounlearn the bias in the original dataset. In our work, we propose a noveltwo-stage pipeline to mitigate this issue where 1) we pre-train a model on abalanced synthetic dataset and then 2) fine-tune on the real data. Using thispipeline, we avoid training on both real and synthetic data, thus avoiding thebias between real and synthetic data. Moreover, we learn robust featuresagainst the bias in the first step that mitigate the bias in the second step.Moreover, our pipeline naturally integrates with bias mitigation methods; theycan be simply applied to the fine-tuning step. As our experiments prove, ourpipeline can further improve the performance of bias mitigation methodsobtaining state-of-the-art performance on three large-scale datasets.", "output": "From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "False negatives (FN) in 3D object detection, {em e.g.}, missing predictionsof pedestrians, vehicles, or other obstacles, can lead to potentially dangeroussituations in autonomous driving. While being fatal, this issue is understudiedin many current 3D detection methods. In this work, we propose Hard InstanceProbing (HIP), a general pipeline that identifies textit{FN} in a multi-stagemanner and guides the models to focus on excavating difficult instances. For 3Dobject detection, we instantiate this method as FocalFormer3D, a simple yeteffective detector that excels at excavating difficult objects and improvingprediction recall. FocalFormer3D features a multi-stage query generation todiscover hard objects and a box-level transformer decoder to efficientlydistinguish objects from massive object candidates. Experimental results on thenuScenes and Waymo datasets validate the superior performance of FocalFormer3D.The advantage leads to strong performance on both detection and tracking, inboth LiDAR and multi-modal settings. Notably, FocalFormer3D achieves a 70.5 mAPand 73.9 NDS on nuScenes detection benchmark, while the nuScenes trackingbenchmark shows 72.1 AMOTA, both ranking 1st place on the nuScenes LiDARleaderboard. Our code is available aturl{", "output": "FocalFormer3D : Focusing on Hard Instance for 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Typical black-box optimization approaches in robotics focus on learning frommetric scores. However, that is not always possible, as not all developers haveground truth available. Learning appropriate robot behavior in human-centriccontexts often requires querying users, who typically cannot provide precisemetric scores. Existing approaches leverage human feedback in an attempt tomodel an implicit reward function; however, this reward may be difficult orimpossible to effectively capture. In this work, we introduce SortCMA tooptimize algorithm parameter configurations in high dimensions based onpairwise user preferences. SortCMA efficiently and robustly leverages userinput to find parameter sets without directly modeling a reward. We apply thismethod to tuning a commercial depth sensor without ground truth, and to robotsocial navigation, which involves highly complex preferences over robotbehavior. We show that our method succeeds in optimizing for the user's goalsand perform a user study to evaluate social navigation results.", "output": "Optimizing Algorithms From Pairwise User Preferences."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D lane detection from monocular images is a fundamental yet challenging taskin autonomous driving. Recent advances primarily rely on structural 3Dsurrogates (e.g., bird's eye view) that are built from front-view imagefeatures and camera parameters. However, the depth ambiguity in monocularimages inevitably causes misalignment between the constructed surrogate featuremap and the original image, posing a great challenge for accurate lanedetection. To address the above issue, we present a novel LATR model, anend-to-end 3D lane detector that uses 3D-aware front-view features withouttransformed view representation. Specifically, LATR detects 3D lanes viacross-attention based on query and key-value pairs, constructed using ourlane-aware query generator and dynamic 3D ground positional embedding. On theone hand, each query is generated based on 2D lane-aware features and adopts ahybrid embedding to enhance the lane information. On the other hand, 3D spaceinformation is injected as positional embedding from an iteratively-updated 3Dground plane. LATR outperforms previous state-of-the-art methods on bothsynthetic Apollo and realistic OpenLane by large margins (e.g., 11.4 gains interms of F1 score on OpenLane). Code will be released at", "output": "LATR: 3D Lane Detection from Monocular Images with Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The emerging field of action prediction plays a vital role in variouscomputer vision applications such as autonomous driving, activity analysis andhuman-computer interaction. Despite significant advancements, accuratelypredicting future actions remains a challenging problem due to highdimensionality, complex dynamics and uncertainties inherent in video data.Traditional supervised approaches require large amounts of labelled data, whichis expensive and time-consuming to obtain. This paper introduces a novelself-supervised video strategy for enhancing action prediction inspired by DINO(self-distillation with no labels). The Temporal-DINO approach employs twomodels; a 'student' processing past frames; and a 'teacher' processing bothpast and future frames, enabling a broader temporal context. During training,the teacher guides the student to learn future context by only observing pastframes. The strategy is evaluated on ROAD dataset for the action predictiondownstream task using 3D-ResNet, Transformer, and LSTM architectures. Theexperimental results showcase significant improvements in predictionperformance across these architectures, with our method achieving an averageenhancement of 9.9% Precision Points (PP), highlighting its effectiveness inenhancing the backbones' capabilities of capturing long-term dependencies.Furthermore, our approach demonstrates efficiency regarding the pretrainingdataset size and the number of epochs required. This method overcomeslimitations present in other approaches, including considering various backbonearchitectures, addressing multiple prediction horizons, reducing reliance onhand-crafted augmentations, and streamlining the pretraining process into asingle stage. These findings highlight the potential of our approach in diversevideo-based tasks such as activity recognition, motion planning, and sceneunderstanding.", "output": "Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Currently, Video Instance Segmentation (VIS) aims at segmenting andcategorizing objects in videos from a closed set of training categories thatcontain only a few dozen of categories, lacking the ability to handle diverseobjects in real-world videos. As TAO and BURST datasets release, we have theopportunity to research VIS in long-tailed and open-world scenarios.Traditional VIS methods are evaluated on benchmarks limited to a small numberof common classes, But practical applications require trackers that go beyondthese common classes, detecting and tracking rare and even never-before-seenobjects. Inspired by the latest MOT paper for the long tail task (TrackingEvery Thing in the Wild, Siyuan Li et), for the BURST long tail challenge, wetrain our model on a combination of LVISv0.5 and the COCO dataset using repeatfactor sampling. First, train the detector with segmentation and CEM onLVISv0.5 + COCO dataset. And then, train the instance appearance similarityhead on the TAO dataset. at last, our method (LeTracker) gets 14.9 HOTAall inthe BURST test set, ranking 1st in the benchmark. for the open-worldchallenges, we only use 64 classes (Intersection classes of BURST Train subsetand COCO dataset, without LVIS dataset) annotations data training, and testingon BURST test set data and get 61.4 OWTAall, ranking 1st in the benchmark. Ourcode will be released to facilitate future research.", "output": "1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although many deep-learning-based super-resolution approaches have beenproposed in recent years, because no ground truth is available in the inferencestage, few can quantify the errors and uncertainties of the super-resolvedresults. For scientific visualization applications, however, conveyinguncertainties of the results to scientists is crucial to avoid generatingmisleading or incorrect information. In this paper, we propose PSRFlow, a novelnormalizing flow-based generative model for scientific data super-resolutionthat incorporates uncertainty quantification into the super-resolution process.PSRFlow learns the conditional distribution of the high-resolution data basedon the low-resolution counterpart. By sampling from a Gaussian latent spacethat captures the missing information in the high-resolution data, one cangenerate different plausible super-resolution outputs. The efficient samplingin the Gaussian latent space allows our model to perform uncertaintyquantification for the super-resolved results. During model training, weaugment the training data with samples across various scales to make the modeladaptable to data of different scales, achieving flexible super-resolution fora given input. Our results demonstrate superior performance and robustuncertainty quantification compared with existing methods such as interpolationand GAN-based super-resolution networks.", "output": "PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D understanding and rendering of moving humans from monocular videos is achallenging task. Despite recent progress, the task remains difficult inreal-world scenarios, where obstacles may block the camera view and causepartial occlusions in the captured videos. Existing methods cannot handle suchdefects due to two reasons. First, the standard rendering strategy relies onpoint-point mapping, which could lead to dramatic disparities between thevisible and occluded areas of the body. Second, the naive direct regressionapproach does not consider any feasibility criteria (ie, prior information) forrendering under occlusions. To tackle the above drawbacks, we present OccNeRF,a neural rendering method that achieves better rendering of humans in severelyoccluded scenes. As direct solutions to the two drawbacks, we proposesurface-based rendering by integrating geometry and visibility priors. Wevalidate our method on both simulated and real-world occlusions and demonstrateour method's superiority.", "output": "Rendering Humans from Object-Occluded Monocular Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "LiDAR place recognition approaches based on deep learning suffer asignificant degradation in performance when there is a shift between thedistribution of the training and testing datasets, with re-training oftenrequired to achieve top performance. However, obtaining accurate ground truthon new environments can be prohibitively expensive, especially in complex orGPS-deprived environments. To address this issue we propose GeoAdapt, whichintroduces a novel auxiliary classification head to generate pseudo-labels forre-training on unseen environments in a self-supervised manner. GeoAdapt usesgeometric consistency as a prior to improve the robustness of our generatedpseudo-labels against domain shift, improving the performance and reliabilityof our Test-Time Adaptation approach. Comprehensive experiments show thatGeoAdapt significantly boosts place recognition performance across moderate tosevere domain shifts, and is competitive with fully supervised test-timeadaptation approaches. Our code will be available at", "output": "GeoAdapt: Self-Supervised Test-Time Adaption in LiDAR Place Recognition Using Geometric Priors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Gestures form an important medium of communication between humans andmachines. An overwhelming majority of existing gesture recognition methods aretailored to a scenario where humans and machines are located very close to eachother. This short-distance assumption does not hold true for several types ofinteractions, for example gesture-based interactions with a floor cleaningrobot or with a drone. Methods made for short-distance recognition are unableto perform well on long-distance recognition due to gestures occupying only asmall portion of the input data. Their performance is especially worse inresource constrained settings where they are not able to effectively focustheir limited compute on the gesturing subject. We propose a novel, accurateand efficient method for the recognition of gestures from longer distances. Ituses a dynamic neural network to select features from gesture-containingspatial regions of the input sensor data for further processing. This helps thenetwork focus on features important for gesture recognition while discardingbackground features early on, thus making it more compute efficient compared toother techniques. We demonstrate the performance of our method on the LD-ConGRlong-distance dataset where it outperforms previous state-of-the-art methods onrecognition accuracy and compute efficiency.", "output": "Long-Distance Gesture Recognition using Dynamic Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study focuses on comparing deep learning methods for the segmentationand quantification of uncertainty in prostate segmentation from MRI images. Theaim is to improve the workflow of prostate cancer detection and diagnosis.Seven different U-Net-based architectures, augmented with Monte-Carlo dropout,are evaluated for automatic segmentation of the central zone, peripheral zone,transition zone, and tumor, with uncertainty estimation. The top-performingmodel in this study is the Attention R2U-Net, achieving a mean Intersectionover Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% forsegmenting all zones. Additionally, Attention R2U-Net exhibits the lowestuncertainty values, particularly in the boundaries of the transition zone andtumor, when compared to the other models.", "output": "Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Since the introduction of the Vision Transformer (ViT), researchers havesought to make ViTs more efficient by removing redundant information in theprocessed tokens. While different methods have been explored to achieve thisgoal, we still lack understanding of the resulting reduction patterns and howthose patterns differ across token reduction methods and datasets. To closethis gap, we set out to understand the reduction patterns of 10 different tokenreduction methods using four image classification datasets. By systematicallycomparing these methods on the different classification tasks, we find that theTop-K pruning method is a surprisingly strong baseline. Through in-depthanalysis of the different methods, we determine that: the reduction patternsare generally not consistent when varying the capacity of the backbone model,the reduction patterns of pruning-based methods significantly differ from fixedradial patterns, and the reduction patterns of pruning-based methods arecorrelated across classification datasets. Finally we report that thesimilarity of reduction patterns is a moderate-to-strong proxy for modelperformance. Project page at ", "output": "Which Tokens to Use? Investigating Token Reduction in Vision Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The accurate diagnosis on pathological subtypes for lung cancer is ofsignificant importance for the follow-up treatments and prognosis managements.In this paper, we propose self-generating hybrid feature network (SGHF-Net) foraccurately classifying lung cancer subtypes on computed tomography (CT) images.Inspired by studies stating that cross-scale associations exist in the imagepatterns between the same case's CT images and its pathological images, weinnovatively developed a pathological feature synthetic module (PFSM), whichquantitatively maps cross-modality associations through deep neural networks,to derive the \"gold standard\" information contained in the correspondingpathological images from CT images. Additionally, we designed a radiologicalfeature extraction module (RFEM) to directly acquire CT image information andintegrated it with the pathological priors under an effective feature fusionframework, enabling the entire classification model to generate more indicativeand specific pathologically related features and eventually output moreaccurate predictions. The superiority of the proposed model lies in its abilityto self-generate hybrid features that contain multi-modality image informationbased on a single-modality input. To evaluate the effectiveness, adaptability,and generalization ability of our model, we performed extensive experiments ona large-scale multi-center dataset (i.e., 829 cases from three hospitals) tocompare our model and a series of state-of-the-art (SOTA) classificationmodels. The experimental results demonstrated the superiority of our model forlung cancer subtypes classification with significant accuracy improvements interms of accuracy (ACC), area under the curve (AUC), and F1 score.", "output": "Classification of lung cancer subtypes on CT images with synthetic pathological priors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, a variety of Neural radiance fields methods have garneredremarkable success in high render speed. However, current accelerating methodsis specialized and not compatible for various implicit method, which prevent areal-time composition over different kinds of NeRF works. Since NeRF relies onsampling along rays, it's possible to provide a guidance generally. We proposea general implicit pipeline to rapidly compose NeRF objects. This new methodenables the casting of dynamic shadows within or between objects usinganalytical light sources while allowing multiple NeRF objects to be seamlesslyplaced and rendered together with any arbitrary rigid transformations. Mainly,our work introduces a new surface representation known as Neural Depth Fields(NeDF) that quickly determines the spatial relationship between objects byallowing direct intersection computation between rays and implicit surfaces. Itleverages an intersection neural network to query NeRF for acceleration insteadof depending on an explicit spatial structure.Our proposed method is the firstto enable both the progressive and interactive composition of NeRF objects.Additionally, it also serves as a previewing plugin for a range of existingNeRF works.", "output": "A General Implicit Framework for Fast NeRF Composition and Rendering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Brain-inspired Spiking Neural Networks (SNNs) have the characteristics ofevent-driven and high energy-efficient, which are different from traditionalArtificial Neural Networks (ANNs) when deployed on edge devices such asneuromorphic chips. Most previous work focuses on SNNs training strategies toimprove model performance and brings larger and deeper network architectures.It is difficult to deploy these complex networks on resource-limited edgedevices directly. To meet such demand, people compress SNNs very cautiously tobalance the performance and the computation efficiency. Existing compressionmethods either iteratively pruned SNNs using weights norm magnitude orformulated the problem as a sparse learning optimization. We propose animproved end-to-end Minimax optimization method for this sparse learningproblem to better balance the model performance and the computation efficiency.We also demonstrate that jointly applying compression and finetuning on SNNs isbetter than sequentially, especially for extreme compression ratios. Thecompressed SNN models achieved state-of-the-art (SOTA) performance on variousbenchmark datasets and architectures. Our code is available at", "output": "Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fairness in deep learning models trained with high-dimensional inputs andsubjective labels remains a complex and understudied area. Facial emotionrecognition, a domain where datasets are often racially imbalanced, can lead tomodels that yield disparate outcomes across racial groups. This study focuseson analyzing racial bias by sub-sampling training sets with varied racialdistributions and assessing test performance across these simulations. Ourfindings indicate that smaller datasets with posed faces improve on bothfairness and performance metrics as the simulations approach racial balance.Notably, the F1-score increases by $27.2%$ points, and demographic parityincreases by $15.7%$ points on average across the simulations. However, inlarger datasets with greater facial variation, fairness metrics generallyremain constant, suggesting that racial balance by itself is insufficient toachieve parity in test performance across different racial groups.", "output": "Addressing Racial Bias in Facial Emotion Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Real-world single image denoising is crucial and practical in computervision. Bayesian inversions combined with score priors now have proveneffective for single image denoising but are limited to white Gaussian noise.Moreover, applying existing score-based methods for real-world denoisingrequires not only the explicit train of score priors on the target domain butalso the careful design of sampling procedures for posterior inference, whichis complicated and impractical. To address these limitations, we propose ascore priors-guided deep variational inference, namely ScoreDVI, for practicalreal-world denoising. By considering the deep variational image posterior witha Gaussian form, score priors are extracted based on easily accessible minimumMSE Non-$i.i.d$ Gaussian denoisers and variational samples, which in turnfacilitate optimizing the variational image posterior. Such a procedureadaptively applies cheap score priors to denoising. Additionally, we exploit aNon-$i.i.d$ Gaussian mixture model and variational noise posterior to model thereal-world noise. This scheme also enables the pixel-wise fusion of multipleimage priors and variational image posteriors. Besides, we develop anoise-aware prior assignment strategy that dynamically adjusts the weight ofimage priors in the optimization. Our method outperforms other singleimage-based real-world denoising methods and achieves comparable performance todataset-based unsupervised methods.", "output": "Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While the use of artificial intelligence (AI) for medical image analysis isgaining wide acceptance, the expertise, time and cost required to generateannotated data in the medical field are significantly high, due to limitedavailability of both data and expert annotation. Strongly supervised objectlocalization models require data that is exhaustively annotated, meaning allobjects of interest in an image are identified. This is difficult to achieveand verify for medical images. We present a method for the transformation ofreal data to train any Deep Neural Network to solve the above problems. We showthe efficacy of this approach on both a weakly supervised localization modeland a strongly supervised localization model. For the weakly supervised model,we show that the localization accuracy increases significantly using thegenerated data. For the strongly supervised model, this approach overcomes theneed for exhaustive annotation on real images. In the latter model, we showthat the accuracy, when trained with generated images, closely parallels theaccuracy when trained with exhaustively annotated real images. The results aredemonstrated on images of human urine samples obtained using microscopy.", "output": "Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated Learning (FL) has recently emerged as a promising distributedmachine learning framework to preserve clients' privacy, by allowing multipleclients to upload the gradients calculated from their local data to a centralserver. Recent studies find that the exchanged gradients also take the risk ofprivacy leakage, e.g., an attacker can invert the shared gradients and recoversensitive data against an FL system by leveraging pre-trained generativeadversarial networks (GAN) as prior knowledge. However, performing gradientinversion attacks in the latent space of the GAN model limits their expressionability and generalizability. To tackle these challenges, we proposetextbf{G}radient textbf{I}nversion over textbf{F}eature textbf{D}omains(GIFD), which disassembles the GAN model and searches the feature domains ofthe intermediate layers. Instead of optimizing only over the initial latentcode, we progressively change the optimized layer, from the initial latentspace to intermediate layers closer to the output images. In addition, wedesign a regularizer to avoid unreal image generation by adding a small ${l_1}$ball constraint to the searching range. We also extend GIFD to theout-of-distribution (OOD) setting, which weakens the assumption that thetraining sets of GANs and FL tasks obey the same data distribution. Extensiveexperiments demonstrate that our method can achieve pixel-level reconstructionand is superior to the existing methods. Notably, GIFD also shows greatgeneralizability under different defense strategy settings and batch sizes.", "output": "GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "State-of-the-art multimodal semantic segmentation approaches combining LiDARand color data are usually designed on top of asymmetric information-sharingschemes and assume that both modalities are always available. Regrettably, thisstrong assumption may not hold in real-world scenarios, where sensors are proneto failure or can face adverse conditions (night-time, rain, fog, etc.) thatmake the acquired information unreliable. Moreover, these architectures tend tofail in continual learning scenarios. In this work, we re-frame the task ofmultimodal semantic segmentation by enforcing a tightly-coupled featurerepresentation and a symmetric information-sharing scheme, which allows ourapproach to work even when one of the input modalities is missing. This makesour model reliable even in safety-critical settings, as is the case ofautonomous driving. We evaluate our approach on the SemanticKITTI dataset,comparing it with our closest competitor. We also introduce an ad-hoc continuallearning scheme and show results in a class-incremental continual learningscenario that prove the effectiveness of the approach also in this setting.", "output": "Continual Road-Scene Semantic Segmentation via Feature-Aligned Symmetric Multi-Modal Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Invariance against rotations of 3D objects is an important property inanalyzing 3D point set data. Conventional 3D point set DNNs having rotationinvariance typically obtain accurate 3D shape features via supervised learningby using labeled 3D point sets as training samples. However, due to the rapidincrease in 3D point set data and the high cost of labeling, a framework tolearn rotation-invariant 3D shape features from numerous unlabeled 3D pointsets is required. This paper proposes a novel self-supervised learningframework for acquiring accurate and rotation-invariant 3D point set featuresat object-level. Our proposed lightweight DNN architecture decomposes an input3D point set into multiple global-scale regions, called tokens, that preservethe spatial layout of partial shapes composing the 3D object. We employ aself-attention mechanism to refine the tokens and aggregate them into anexpressive rotation-invariant feature per 3D point set. Our DNN is effectivelytrained by using pseudo-labels generated by a self-distillation framework. Tofacilitate the learning of accurate features, we propose to combine multi-cropand cut-mix data augmentation techniques to diversify 3D point sets fortraining. Through a comprehensive evaluation, we empirically demonstrate that,(1) existing rotation-invariant DNN architectures designed for supervisedlearning do not necessarily learn accurate 3D shape features under aself-supervised learning scenario, and (2) our proposed algorithm learnsrotation-invariant 3D point set features that are more accurate than thoselearned by existing algorithms. Code will be available at", "output": "Self-supervised Learning of Rotation-invariant 3D Point Set Features using Transformer and its Self-distillation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Text design is one of the most critical procedures in poster design, as itrelies heavily on the creativity and expertise of humans to design text imagesconsidering the visual harmony and text-semantic. This study introducesTextPainter, a novel multimodal approach that leverages contextual visualinformation and corresponding text semantics to generate text images.Specifically, TextPainter takes the global-local background image as a hint ofstyle and guides the text image generation with visual harmony. Furthermore, weleverage the language model and introduce a text comprehension module toachieve both sentence-level and word-level style variations. Besides, weconstruct the PosterT80K dataset, consisting of about 80K posters annotatedwith sentence-level bounding boxes and text contents. We hope this dataset willpave the way for further research on multimodal text image generation.Extensive quantitative and qualitative experiments demonstrate that TextPaintercan generatevisually-and-semantically-harmonious text images for posters.", "output": "TextPainter: Multimodal Text Image Generation withVisual-harmony and Text-comprehension for Poster Design."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks (DNNs) demonstrate outstanding performance across mostcomputer vision tasks. Some critical applications, such as autonomous drivingor medical imaging, also require investigation into their behavior and thereasons behind the decisions they make. In this vein, DNN attribution consistsin studying the relationship between the predictions of a DNN and its inputs.Attribution methods have been adapted to highlight the most relevant weights orneurons in a DNN, allowing to more efficiently select which weights or neuronscan be pruned. However, a limitation of these approaches is that weights aretypically compared within each layer separately, while some layers might appearas more critical than others. In this work, we propose to investigate DNN layerimportance, i.e. to estimate the sensitivity of the accuracy w.r.t.perturbations applied at the layer level. To do so, we propose a novel datasetto evaluate our method as well as future works. We benchmark a number ofcriteria and draw conclusions regarding how to assess DNN layer importance and,consequently, how to budgetize layers for increased DNN efficiency (withapplications for DNN pruning and quantization), as well as robustness tohardware failure (e.g. bit swaps).", "output": "SAfER: Layer-Level Sensitivity Assessment for Efficient and Robust Neural Network Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Vision-language navigation (VLN), which entails an agent to navigate 3Denvironments following human instructions, has shown great advances. However,current agents are built upon panoramic observations, which hinders theirability to perceive 3D scene geometry and easily leads to ambiguous selectionof panoramic view. To address these limitations, we present a BEV Scene Graph(BSG), which leverages multi-step BEV representations to encode scene layoutsand geometric cues of indoor environment under the supervision of 3D detection.During navigation, BSG builds a local BEV representation at each step andmaintains a BEV-based global scene map, which stores and organizes all theonline collected local BEV representations according to their topologicalrelations. Based on BSG, the agent predicts a local BEV grid-level decisionscore and a global graph-level decision score, combined with a sub-viewselection score on panoramic views, for more accurate action prediction. Ourapproach significantly outperforms state-of-the-art methods on REVERIE, R2R,and R4R, showing the potential of BEV perception in VLN.", "output": "Bird's-Eye-View Scene Graph for Vision-Language Navigation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human facial skin images contain abundant textural information that can serveas valuable features for attribute classification, such as age, race, andgender. Additionally, facial skin images offer the advantages of easycollection and minimal privacy concerns. However, the availability ofwell-labeled human skin datasets with a sufficient number of images is limited.To address this issue, we introduce a dataset called FaceSkin, whichencompasses a diverse range of ages and races. Furthermore, to broaden theapplication scenarios, we incorporate synthetic skin-patches obtained from 2Dand 3D attack images, including printed paper, replays, and 3D masks. Weevaluate the FaceSkin dataset across distinct categories and presentexperimental results demonstrating its effectiveness in attributeclassification, as well as its potential for various downstream tasks, such asFace anti-spoofing and Age estimation.", "output": "FaceSkin: A Privacy Preserving Facial skin patch Dataset for multi Attributes classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised sound source localization is usually challenged by themodality inconsistency. In recent studies, contrastive learning basedstrategies have shown promising to establish such a consistent correspondencebetween audio and sound sources in visual scenarios. Unfortunately, theinsufficient attention to the heterogeneity influence in the different modalityfeatures still limits this scheme to be further improved, which also becomesthe motivation of our work. In this study, an Induction Network is proposed tobridge the modality gap more effectively. By decoupling the gradients of visualand audio modalities, the discriminative visual representations of soundsources can be learned with the designed Induction Vector in a bootstrapmanner, which also enables the audio modality to be aligned with the visualmodality consistently. In addition to a visual weighted contrastive loss, anadaptive threshold selection strategy is introduced to enhance the robustnessof the Induction Network. Substantial experiments conducted on SoundNet-Flickrand VGG-Sound Source datasets have demonstrated a superior performance comparedto other state-of-the-art works in different challenging scenarios. The code isavailable at ", "output": "Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Objects in videos are typically characterized by continuous smooth motion. Weexploit continuous smooth motion in three ways. 1) Improved accuracy by usingobject motion as an additional source of supervision, which we obtain byanticipating object locations from a static keyframe. 2) Improved efficiency byonly doing the expensive feature computations on a small subset of all frames.Because neighboring video frames are often redundant, we only compute featuresfor a single static keyframe and predict object locations in subsequent frames.3) Reduced annotation cost, where we only annotate the keyframe and use smoothpseudo-motion between keyframes. We demonstrate computational efficiency,annotation efficiency, and improved mean average precision compared to thestate-of-the-art on four datasets: ImageNet VID, EPIC KITCHENS-55,YouTube-BoundingBoxes, and Waymo Open dataset. Our source code is available at", "output": "Objects do not disappear: Video object detection by single-frame object location anticipation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a new sparse unmixing technique using archetypalanalysis (SUnAA). First, we design a new model based on archetypal analysis. Weassume that the endmembers of interest are a convex combination of endmembersprovided by a spectral library and that the number of endmembers of interest isknown. Then, we propose a minimization problem. Unlike most conventional sparseunmixing methods, here the minimization problem is non-convex. We minimize theoptimization objective iteratively using an active set algorithm. Our method isrobust to the initialization and only requires the number of endmembers ofinterest. SUnAA is evaluated using two simulated datasets for which resultsconfirm its better performance over other conventional and advanced techniquesin terms of signal-to-reconstruction error. SUnAA is also applied to Cupritedataset and the results are compared visually with the available geological mapprovided for this dataset. The qualitative assessment demonstrates thesuccessful estimation of the minerals abundances and significantly improves thedetection of dominant minerals compared to the conventional regression-basedsparse unmixing methods. The Python implementation of SUnAA can be found at:", "output": "SUnAA: Sparse Unmixing using Archetypal Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Motivated by the advances in deep learning techniques, the application ofUnmanned Aerial Vehicle (UAV)-based object detection has proliferated across arange of fields, including vehicle counting, fire detection, and citymonitoring. While most existing research studies only a subset of thechallenges inherent to UAV-based object detection, there are few studies thatbalance various aspects to design a practical system for energy consumptionreduction. In response, we present the E3-UAV, an edge-based energy-efficientobject detection system for UAVs. The system is designed to dynamically supportvarious UAV devices, edge devices, and detection algorithms, with the aim ofminimizing energy consumption by deciding the most energy-efficient flightparameters (including flight altitude, flight speed, detection algorithm, andsampling rate) required to fulfill the detection requirements of the task. Wefirst present an effective evaluation metric for actual tasks and construct atransparent energy consumption model based on hundreds of actual flight data toformalize the relationship between energy consumption and flight parameters.Then we present a lightweight energy-efficient priority decision algorithmbased on a large quantity of actual flight data to assist the system indeciding flight parameters. Finally, we evaluate the performance of the system,and our experimental results demonstrate that it can significantly decreaseenergy consumption in real-world scenarios. Additionally, we provide fourinsights that can assist researchers and engineers in their efforts to studyUAV-based object detection further.", "output": "E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The application of 3D ground-penetrating radar (3D-GPR) for subgrade distressdetection has gained widespread popularity. To enhance the efficiency andaccuracy of detection, pioneering studies have attempted to adopt automaticdetection techniques, particularly deep learning. However, existing workstypically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of theGPR, resulting in either insufficient spatial information or high computationalcomplexity. To address these challenges, we introduce a novel methodology forthe subgrade distress detection task by leveraging the multi-view informationfrom 3D-GPR data. Moreover, we construct a real multi-view image datasetderived from the original 3D-GPR data for the detection task, which providesricher spatial information compared to A-scan and B-scan data, while reducingcomputational complexity compared to C-scan data. Subsequently, we develop anovel textbf{M}ulti-textbf{V}iew textbf{V}usion and textbf{D}istillationframework, textbf{GPR-MVFD}, specifically designed to optimally utilize themulti-view GPR dataset. This framework ingeniously incorporates multi-viewdistillation and attention-based fusion to facilitate significant featureextraction for subgrade distresses. In addition, a self-adaptive learningmechanism is adopted to stabilize the model training and prevent performancedegeneration in each branch. Extensive experiments conducted on this new GPRbenchmark demonstrate the effectiveness and efficiency of our proposedframework. Our framework outperforms not only the existing GPR baselines, butalso the state-of-the-art methods in the fields of multi-view learning,multi-modal learning, and knowledge distillation. We will release theconstructed multi-view GPR dataset with expert-annotated labels and the sourcecodes of the proposed framework.", "output": "Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Point cloud registration is a task to estimate the rigid transformationbetween two unaligned scans, which plays an important role in many computervision applications. Previous learning-based works commonly focus on supervisedregistration, which have limitations in practice. Recently, with the advance ofinexpensive RGB-D sensors, several learning-based works utilize RGB-D data toachieve unsupervised registration. However, most of existing unsupervisedmethods follow a cascaded design or fuse RGB-D data in a unidirectional manner,which do not fully exploit the complementary information in the RGB-D data. Toleverage the complementary information more effectively, we propose a networkimplementing multi-scale bidirectional fusion between RGB images and pointclouds generated from depth images. By bidirectionally fusing visual andgeometric features in multi-scales, more distinctive deep features forcorrespondence estimation can be obtained, making our registration moreaccurate. Extensive experiments on ScanNet and 3DMatch demonstrate that ourmethod achieves new state-of-the-art performance. Code will be released at", "output": "PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Anomaly detection has gained considerable attention due to its broad range ofapplications, particularly in industrial defect detection. To address thechallenges of data collection, researchers have introduced zero-/few-shotanomaly detection techniques that require minimal normal images for eachcategory. However, complex industrial scenarios often involve multiple objects,presenting a significant challenge. In light of this, we propose astraightforward yet powerful multi-scale memory comparison framework forzero-/few-shot anomaly detection. Our approach employs a global memory bank tocapture features across the entire image, while an individual memory bankfocuses on simplified scenes containing a single object. The efficacy of ourmethod is validated by its remarkable achievement of 4th place in the zero-shottrack and 2nd place in the few-shot track of the Visual Anomaly and NoveltyDetection (VAND) competition.", "output": "Multi-Scale Memory Comparison for Zero-/Few-Shot Anomaly Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As Facial Recognition System(FRS) is widely applied in areas such as accesscontrol and mobile payments due to its convenience and high accuracy. Thesecurity of facial recognition is also highly regarded. The Face anti-spoofingsystem(FAS) for face recognition is an important component used to enhance thesecurity of face recognition systems. Traditional FAS used images containingidentity information to detect spoofing traces, however there is a risk ofprivacy leakage during the transmission and storage of these images. Besides,the encryption and decryption of these privacy-sensitive data takes too longcompared to inference time by FAS model. To address the above issues, wepropose a face anti-spoofing algorithm based on facial skin patches leveragingpure facial skin patch images as input, which contain no privacy information,no encryption or decryption is needed for these images. We conduct experimentson several public datasets, the results prove that our algorithm hasdemonstrated superiority in both accuracy and speed.", "output": "Enhancing Mobile Privacy and Security: A Face Skin Patch-Based Anti-Spoofing Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing Unbiased Scene Graph Generation (USGG) methods only focus onaddressing the predicate-level imbalance that high-frequency classes dominatepredictions of rare ones, while overlooking the concept-level imbalance.Actually, even if predicates themselves are balanced, there is still asignificant concept-imbalance within them due to the long-tailed distributionof contexts (i.e., subject-object combinations). This concept-level imbalanceposes a more pervasive and challenging issue compared to the predicate-levelimbalance since subject-object pairs are inherently complex in combinations.Hence, we introduce a novel research problem: Generalized Unbiased Scene GraphGeneration (G-USGG), which takes into account both predicate-level andconcept-level imbalance. To the end, we propose the Multi-Concept Learning(MCL) framework, which ensures a balanced learning process across rare/uncommon/ common concepts. MCL first quantifies the concept-level imbalanceacross predicates in terms of different amounts of concepts, representing asmultiple concept-prototypes within the same class. It then effectively learnsconcept-prototypes by applying the Concept Regularization (CR) technique.Furthermore, to achieve balanced learning over different concepts, we introducethe Balanced Prototypical Memory (BPM), which guides SGG models to generatebalanced representations for concept-prototypes. Extensive experimentsdemonstrate the remarkable efficacy of our model-agnostic strategy in enhancingthe performance of benchmark models on both VG-SGG and OI-SGG datasets, leadingto new state-of-the-art achievements in two key aspects: predicate-levelunbiased relation recognition and concept-level compositional generability.", "output": "Generalized Unbiased Scene Graph Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-person motion prediction is a challenging problem due to the dependencyof motion on both individual past movements and interactions with other people.Transformer-based methods have shown promising results on this task, but theymiss the explicit relation representation between joints, such as skeletonstructure and pairwise distance, which is crucial for accurate interactionmodeling. In this paper, we propose the Joint-Relation Transformer, whichutilizes relation information to enhance interaction modeling and improvefuture motion prediction. Our relation information contains the relativedistance and the intra-/inter-person physical constraints. To fuse relation andjoint information, we design a novel joint-relation fusion layer withrelation-aware attention to update both features. Additionally, we supervisethe relation information by forecasting future distance. Experiments show thatour method achieves a 13.4% improvement of 900ms VIM on 3DPW-SoMoF/RC and17.8%/12.0% improvement of 3s MPJPE on CMU-Mpcap/MuPoTS-3D dataset.", "output": "Joint-Relation Transformer for Multi-Person Motion Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Parallel imaging, a fast MRI technique, involves dynamic adjustments based onthe configuration i.e. number, positioning, and sensitivity of the coils withrespect to the anatomy under study. Conventional deep learning-based imagereconstruction models have to be trained or fine-tuned for each configuration,posing a barrier to clinical translation, given the lack of computationalresources and machine learning expertise for clinicians to train models atdeployment. Joint training on diverse datasets learns a single weight set thatmight underfit to deviated configurations. We propose, HyperCoil-Recon, ahypernetwork-based coil configuration task-switching network for multi-coil MRIreconstruction that encodes varying configurations of the numbers of coils in amulti-tasking perspective, posing each configuration as a task. Thehypernetworks infer and embed task-specific weights into the reconstructionnetwork, 1) effectively utilizing the contextual knowledge of common andvarying image features among the various fields-of-view of the coils, and 2)enabling generality to unseen configurations at test time. Experiments revealthat our approach 1) adapts on the fly to various unseen configurations up to32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varyingcoils, and to 120 deviated unseen configurations when trained on 18configurations in a single model, 2) matches the performance of coilconfiguration-specific models, and 3) outperforms configuration-invariantmodels with improvement margins of around 1 dB / 0.03 and 0.3 dB / 0.02 in PSNR/ SSIM for knee and brain data. Our code is available at", "output": "HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural Radiance Field (NeRF) has shown impressive performance in novel viewsynthesis via implicit scene representation. However, it usually suffers frompoor scalability as requiring densely sampled images for each new scene.Several studies have attempted to mitigate this problem by integratingMulti-View Stereo (MVS) technique into NeRF while they still entail acumbersome fine-tuning process for new scenes. Notably, the rendering qualitywill drop severely without this fine-tuning process and the errors mainlyappear around the high-frequency features. In the light of this observation, wedesign WaveNeRF, which integrates wavelet frequency decomposition into MVS andNeRF to achieve generalizable yet high-quality synthesis without any per-sceneoptimization. To preserve high-frequency information when generating 3D featurevolumes, WaveNeRF builds Multi-View Stereo in the Wavelet domain by integratingthe discrete wavelet transform into the classical cascade MVS, whichdisentangles high-frequency information explicitly. With that, disentangledfrequency features can be injected into classic NeRF via a novel hybrid neuralrenderer to yield faithful high-frequency details, and an intuitivefrequency-guided sampling strategy can be designed to suppress artifacts aroundhigh-frequency regions. Extensive experiments over three widely studiedbenchmarks show that WaveNeRF achieves superior generalizable radiance fieldmodeling when only given three images as input.", "output": "WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Contrastive Language-Image Pre-training (CLIP) has recently shownremarkable generalization on \"zero-shot\" training and has applied to manydownstream tasks. We explore the adaptation of CLIP to achieve a more efficientand generalized action recognition method. We propose that the key lies inexplicitly modeling the motion cues flowing in video frames. To that end, wedesign a two-stream motion modeling block to capture motion and spatialinformation at the same time. And then, the obtained motion cues are utilizedto drive a dynamic prompts learner to generate motion-aware prompts, whichcontain much semantic information concerning human actions. In addition, wepropose a multimodal communication block to achieve a collaborative learningand further improve the performance. We conduct extensive experiments onHMDB-51, UCF-101, and Kinetics-400 datasets. Our method outperforms mostexisting state-of-the-art methods by a significant margin on \"few-shot\" and\"zero-shot\" training. We also achieve competitive performance on \"closed-set\"training with extremely few trainable parameters and additional computationalcosts.", "output": "Seeing in Flowing: Adapting CLIP for Action Recognition with Motion Prompts Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, semantic segmentation models trained with image-level textsupervision have shown promising results in challenging open-world scenarios.However, these models still face difficulties in learning fine-grained semanticalignment at the pixel level and predicting accurate object masks. To addressthis issue, we propose MixReorg, a novel and straightforward pre-trainingparadigm for semantic segmentation that enhances a model's ability toreorganize patches mixed across images, exploring both local visual relevanceand global semantic coherence. Our approach involves generating fine-grainedpatch-text pairs data by mixing image patches while preserving thecorrespondence between patches and text. The model is then trained to minimizethe segmentation loss of the mixed images and the two contrastive losses of theoriginal and restored features. With MixReorg as a mask learner, conventionaltext-supervised semantic segmentation models can achieve highly generalizablepixel-semantic alignment ability, which is crucial for open-world segmentation.After training with large-scale image-text data, MixReorg models can be applieddirectly to segment visual objects of arbitrary categories, without the needfor further fine-tuning. Our proposed framework demonstrates strong performanceon popular zero-shot semantic segmentation benchmarks, outperforming GroupViTby significant margins of 5.0%, 6.2%, 2.5%, and 3.4% mIoU on PASCAL VOC2012,PASCAL Context, MS COCO, and ADE20K, respectively.", "output": "MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Current talking face generation methods mainly focus on speech-lipsynchronization. However, insufficient investigation on the facial talkingstyle leads to a lifeless and monotonous avatar. Most previous works fail toimitate expressive styles from arbitrary video prompts and ensure theauthenticity of the generated video. This paper proposes an unsupervisedvariational style transfer model (VAST) to vivify the neutral photo-realisticavatars. Our model consists of three key components: a style encoder thatextracts facial style representations from the given video prompts; a hybridfacial expression decoder to model accurate speech-related movements; avariational style enhancer that enhances the style space to be highlyexpressive and meaningful. With our essential designs on facial style learning,our model is able to flexibly capture the expressive facial style fromarbitrary video prompts and transfer it onto a personalized image renderer in azero-shot manner. Experimental results demonstrate the proposed approachcontributes to a more vivid talking avatar with higher authenticity and richerexpressiveness.", "output": "VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style Transfer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Activation functions are essential components of neural networks. In thispaper, we introduce a new activation function called the Truncated and SignedSquare Root (TSSR) function. This function is distinctive because it is odd,nonlinear, monotone and differentiable. Its gradient is continuous and alwayspositive. Thanks to these properties, it has the potential to improve thenumerical stability of neural networks. Several experiments confirm that theproposed TSSR has better performance than other stat-of-the-art activationfunctions. The proposed function has significant implications for thedevelopment of neural network models and can be applied to a wide range ofapplications in fields such as computer vision, natural language processing,and speech recognition.", "output": "TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent adaptive methods for efficient video recognition mostly follow thetwo-stage paradigm of \"preview-then-recognition\" and have achieved greatsuccess on multiple video benchmarks. However, this two-stage paradigm involvestwo visits of raw frames from coarse-grained to fine-grained during inference(cannot be parallelized), and the captured spatiotemporal features cannot bereused in the second stage (due to varying granularity), being not friendly toefficiency and computation optimization. To this end, inspired by humancognition, we propose a novel recognition paradigm of \"View while Moving\" forefficient long-untrimmed video recognition. In contrast to the two-stageparadigm, our paradigm only needs to access the raw frame once. The two phasesof coarse-grained sampling and fine-grained recognition are combined intounified spatiotemporal modeling, showing great performance. Moreover, weinvestigate the properties of semantic units in video and propose ahierarchical mechanism to efficiently capture and reason about the unit-leveland video-level temporal semantics in long-untrimmed videos respectively.Extensive experiments on both long-untrimmed and short-trimmed videosdemonstrate that our approach outperforms state-of-the-art methods in terms ofaccuracy as well as efficiency, yielding new efficiency and accuracy trade-offsfor video spatiotemporal modeling.", "output": "View while Moving: Efficient Video Recognition in Long-untrimmed Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in full-head reconstruction have been obtained by optimizinga neural field through differentiable surface or volume rendering to representa single scene. While these techniques achieve an unprecedented accuracy, theytake several minutes, or even hours, due to the expensive optimization processrequired. In this work, we introduce InstantAvatar, a method that recoversfull-head avatars from few images (down to just one) in a few seconds oncommodity hardware. In order to speed up the reconstruction process, we proposea system that combines, for the first time, a voxel-grid neural fieldrepresentation with a surface renderer. Notably, a naive combination of thesetwo techniques leads to unstable optimizations that do not converge to validsolutions. In order to overcome this limitation, we present a novel statisticalmodel that learns a prior distribution over 3D head signed distance functionsusing a voxel-grid based architecture. The use of this prior model, incombination with other design choices, results into a system that achieves 3Dhead reconstructions with comparable accuracy as the state-of-the-art with a100x speed-up.", "output": "InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study proposes a simple method for multi-object tracking (MOT) ofplayers in a badminton court. We leverage two off-the-shelf cameras, one on thetop of the court and the other on the side of the court. The one on the top isto track players' trajectories, while the one on the side is to analyze thepixel features of players. By computing the correlations between adjacentframes and engaging the information of the two cameras, MOT of badmintonplayers is obtained. This two-camera approach addresses the challenge of playerocclusion and overlapping in a badminton court, providing player trajectorytracking and multi-angle analysis. The presented system offers insights intothe positions and movements of badminton players, thus serving as a coaching orself-training tool for badminton players to improve their gaming strategies.", "output": "Tracking Players in a Badminton Court by Two Cameras."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, learning-based algorithms have achieved promising performance oncross-spectral image patch matching, which, however, is still far fromsatisfactory for practical application. On the one hand, a lack of large-scaledataset with diverse scenes haunts its further improvement for learning-basedalgorithms, whose performances and generalization rely heavily on the datasetsize and diversity. On the other hand, more emphasis has been put on featurerelation in the spatial domain whereas the scale dependency between featureshas often been ignored, leading to performance degeneration especially whenencountering significant appearance variations for cross-spectral patches. Toaddress these issues, we publish, to be best of our knowledge, the largestvisible and Long-wave Infrared (LWIR) image patch matching dataset, termedVL-CMIM, which contains 1300 pairs of strictly aligned visible and LWIR imagesand over 2 million patch pairs covering diverse scenes such as asteroid, field,country, build, street and water.In addition, a multi-domain feature relationlearning network (MD-FRN) is proposed. Input by the features extracted from afour-branch network, both feature relations in spatial and scale domains arelearned via a spatial correlation module (SCM) and multi-scale adaptiveaggregation module (MSAG), respectively. To further aggregate the multi-domainrelations, a deep domain interactive mechanism (DIM) is applied, where thelearnt spatial-relation and scale-relation features are exchanged and furtherinput into MSCRM and SCM. This mechanism allows our model to learn interactivecross-domain feature relations, leading to improved robustness to significantappearance changes due to different modality.", "output": "Learning multi-domain feature relation for visible and Long-wave Infrared image patch matching."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The design of personalized cranial implants is a challenging and tremendoustask that has become a hot topic in terms of process automation with the use ofdeep learning techniques. The main challenge is associated with the highdiversity of possible cranial defects. The lack of appropriate data sourcesnegatively influences the data-driven nature of deep learning algorithms.Hence, one of the possible solutions to overcome this problem is to rely onsynthetic data. In this work, we propose three volumetric variations of deepgenerative models to augment the dataset by generating synthetic skulls, i.e.Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP),WGAN-GP hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) andIntrospective Variational Autoencoder (IntroVAE). We show that it is possibleto generate dozens of thousands of defective skulls with compatible defectsthat achieve a trade-off between defect heterogeneity and the realistic shapeof the skull. We evaluate obtained synthetic data quantitatively by defectsegmentation with the use of V-Net and qualitatively by their latent spaceexploration. We show that the synthetically generated skulls highly improve thesegmentation process compared to using only the original unaugmented data. Thegenerated skulls may improve the automatic design of personalized cranialimplants for real medical cases.", "output": "Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Dialect classification is used in a variety of applications, such as machinetranslation and speech recognition, to improve the overall performance of thesystem. In a real-world scenario, a deployed dialect classification model canencounter anomalous inputs that differ from the training data distribution,also called out-of-distribution (OOD) samples. Those OOD samples can lead tounexpected outputs, as dialects of those samples are unseen during modeltraining. Out-of-distribution detection is a new research area that hasreceived little attention in the context of dialect classification. Towardsthis, we proposed a simple yet effective unsupervised Mahalanobis distancefeature-based method to detect out-of-distribution samples. We utilize thelatent embeddings from all intermediate layers of a wav2vec 2.0transformer-based dialect classifier model for multi-task learning. Ourproposed approach outperforms other state-of-the-art OOD detection methodssignificantly.", "output": "Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, with the continuous development of the marine industry,underwater image enhancement has attracted plenty of attention. Unfortunately,the propagation of light in water will be absorbed by water bodies andscattered by suspended particles, resulting in color deviation and lowcontrast. To solve these two problems, we propose an Adaptive Transmission andDynamic Color guided network (named ATDCnet) for underwater image enhancement.In particular, to exploit the knowledge of physics, we design an AdaptiveTransmission-directed Module (ATM) to better guide the network. To deal withthe color deviation problem, we design a Dynamic Color-guided Module (DCM) topost-process the enhanced image color. Further, we design anEncoder-Decoder-based Compensation (EDC) structure with attention and amulti-stage feature fusion mechanism to perform color restoration and contrastenhancement simultaneously. Extensive experiments demonstrate thestate-of-the-art performance of the ATDCnet on multiple benchmark datasets.", "output": "Transmission and Color-guided Network for Underwater Image Enhancement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video colorization, aiming at obtaining colorful and plausible results fromgrayish frames, has aroused a lot of interest recently. Nevertheless, how tomaintain temporal consistency while keeping the quality of colorized resultsremains challenging. To tackle the above problems, we present aHistogram-guided Video Colorization with Spatial-Temporal connection structure(named ST-HVC). To fully exploit the chroma and motion information, the jointflow and histogram module is tailored to integrate the histogram and flowfeatures. To manage the blurred and artifact, we design a combination schemeattending to temporal detail and flow feature combination. We further recombinethe histogram, flow and sharpness features via a U-shape network. Extensivecomparisons are conducted with several state-of-the-art image and video-basedmethods, demonstrating that the developed method achieves excellent performanceboth quantitatively and qualitatively in two video datasets.", "output": "Histogram-guided Video Colorization Structure with Spatial-Temporal Connection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video shakiness is an unpleasant distortion of User Generated Content (UGC)videos, which is usually caused by the unstable hold of cameras. In recentyears, many video stabilization algorithms have been proposed, yet no specificand accurate metric enables comprehensively evaluating the stability of videos.Indeed, most existing quality assessment models evaluate video quality as awhole without specifically taking the subjective experience of video stabilityinto consideration. Therefore, these models cannot measure the video stabilityexplicitly and precisely when severe shakes are present. In addition, there isno large-scale video database in public that includes various degrees of shakyvideos with the corresponding subjective scores available, which hinders thedevelopment of Video Quality Assessment for Stability (VQA-S). To this end, webuild a new database named StableDB that contains 1,952 diversely-shaky UGCvideos, where each video has a Mean Opinion Score (MOS) on the degree of videostability rated by 34 subjects. Moreover, we elaborately design a novel VQA-Smodel named StableVQA, which consists of three feature extractors to acquirethe optical flow, semantic, and blur features respectively, and a regressionlayer to predict the final stability score. Extensive experiments demonstratethat the StableVQA achieves a higher correlation with subjective opinions thanthe existing VQA-S models and generic VQA models. The database and codes areavailable at ", "output": "StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical image analysis using deep learning is often challenged by limitedlabeled data and high annotation costs. Fine-tuning the entire network inlabel-limited scenarios can lead to overfitting and suboptimal performance.Recently, prompt tuning has emerged as a more promising technique thatintroduces a few additional tunable parameters as prompts to a task-agnosticpre-trained model, and updates only these parameters using supervision fromlimited labeled data while keeping the pre-trained model unchanged. However,previous work has overlooked the importance of selective labeling in downstreamtasks, which aims to select the most valuable downstream samples for annotationto achieve the best performance with minimum annotation cost. To address this,we propose a framework that combines selective labeling with prompt tuning(SLPT) to boost performance in limited labels. Specifically, we introduce afeature-aware prompt updater to guide prompt tuning and a TandEm SelectiveLAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection andsupervised selection using prompt-based uncertainty. In addition, we propose adiversified visual prompt tuning strategy to provide multi-prompt-baseddiscrepant predictions for TESLA. We evaluate our method on liver tumorsegmentation and achieve state-of-the-art performance, outperformingtraditional fine-tuning with only 6% of tunable parameters, also achieving 94%of full-data performance by labeling only 5% of the data.", "output": "SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Live commerce is the act of selling products online through live streaming.The customer's diverse demands for online products introduce more challenges toLivestreaming Product Recognition. Previous works have primarily focused onfashion clothing data or utilize single-modal input, which does not reflect thereal-world scenario where multimodal data from various categories are present.In this paper, we present LPR4M, a large-scale multimodal dataset that covers34 categories, comprises 3 modalities (image, video, and text), and is 50?larger than the largest publicly available dataset. LPR4M contains diversevideos and noise modality pairs while exhibiting a long-tailed distribution,resembling real-world problems. Moreover, a cRoss-vIew semantiC alignmEnt(RICE) model is proposed to learn discriminative instance features from theimage and video views of the products. This is achieved through instance-levelcontrastive learning and cross-view patch-level feature propagation. A novelPatch Feature Reconstruction loss is proposed to penalize the semanticmisalignment between cross-view patches. Extensive experiments demonstrate theeffectiveness of RICE and provide insights into the importance of datasetdiversity and expressivity. The dataset and code are available at", "output": "Cross-view Semantic Alignment for Livestreaming Product Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Functionally significant coronary artery disease (CAD) is caused by plaquebuildup in the coronary arteries, potentially leading to narrowing of thearterial lumen, i.e. coronary stenosis, that significantly obstructs blood flowto the myocardium. The current reference for establishing the presence of afunctionally significant stenosis is invasive fractional flow reserve (FFR)measurement. To avoid invasive measurements, non-invasive prediction of FFRfrom coronary CT angiography (CCTA) has emerged. For this, machine learningapproaches, characterized by fast inference, are increasingly developed.However, these methods predict a single FFR value per artery i.e. they don'tprovide information about the stenosis location or treatment strategy. Wepropose a deep learning-based method to predict the FFR along the artery fromCCTA scans. This study includes CCTA images of 110 patients who underwentinvasive FFR pullback measurement in 112 arteries. First, a multi planarreconstruction (MPR) of the artery is fed to a variational autoencoder tocharacterize the artery, i.e. through the lumen area and unsupervised arteryencodings. Thereafter, a convolutional neural network (CNN) predicts the FFRalong the artery. The CNN is supervised by multiple loss functions, notably aloss function inspired by the Earth Mover's Distance (EMD) to predict thecorrect location of FFR drops and a histogram-based loss to explicitlysupervise the slope of the FFR curve. To train and evaluate our model,eight-fold cross-validation was performed. The resulting FFR curves show goodagreement with the reference allowing the distinction between diffuse and focalCAD distributions in most cases. Quantitative evaluation yielded a meanabsolute difference in the area under the FFR pullback curve (AUPC) of 1.7. Themethod may pave the way towards fast, accurate, automatic prediction of FFRalong the artery from CCTA.", "output": "Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Static meshes with texture maps have attracted considerable attention in bothindustrial manufacturing and academic research, leading to an urgentrequirement for effective and robust objective quality evaluation. However,current model-based static mesh quality metrics have obvious limitations: mostof them only consider geometry information, while color information is ignored,and they have strict constraints for the meshes' geometrical topology. Othermetrics, such as image-based and point-based metrics, are easily influenced bythe prepossessing algorithms, e.g., projection and sampling, hampering theirability to perform at their best. In this paper, we propose Geodesic PatchSimilarity (GeodesicPSIM), a novel model-based metric to accurately predicthuman perception quality for static meshes. After selecting a group keypoints,1-hop geodesic patches are constructed based on both the reference anddistorted meshes cleaned by an effective mesh cleaning algorithm. A two-steppatch cropping algorithm and a patch texture mapping module refine the size of1-hop geodesic patches and build the relationship between the mesh geometry andcolor information, resulting in the generation of 1-hop textured geodesicpatches. Three types of features are extracted to quantify the distortion:patch color smoothness, patch discrete mean curvature, and patch pixel coloraverage and variance. To the best of our knowledge, GeodesicPSIM is the firstmodel-based metric especially designed for static meshes with texture maps.GeodesicPSIM provides state-of-the-art performance in comparison withimage-based, point-based, and video-based metrics on a newly created andchallenging database. We also prove the robustness of GeodesicPSIM byintroducing different settings of hyperparameters. Ablation studies alsoexhibit the effectiveness of three proposed features and the patch croppingalgorithm.", "output": "GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via Geodesic Patch Similarity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose JEDI, a multi-dataset semi-supervised learning method, whichefficiently combines knowledge from multiple experts, learned on differentdatasets, to train and improve the performance of individual, per dataset,student models. Our approach achieves this by addressing two important problemsin current machine learning research: generalization across datasets andlimitations of supervised training due to scarcity of labeled data. We startwith an arbitrary number of experts, pretrained on their own specific dataset,which form the initial set of student models. The teachers are immediatelyderived by concatenating the feature representations from the penultimatelayers of the students. We then train all models in a student-teachersemi-supervised learning scenario until convergence. In our efficient approach,student-teacher training is carried out jointly and end-to-end, showing thatboth students and teachers improve their generalization capacity duringtraining. We validate our approach on four video action recognition datasets.By simultaneously considering all datasets within a unified semi-supervisedsetting, we demonstrate significant improvements over the initial experts.", "output": "JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Anomaly detection (AD) in images, identifying significant deviations fromnormality, is a critical issue in computer vision. This paper introduces anovel approach to dimensionality reduction for AD using pre-trainedconvolutional neural network (CNN) that incorporate EfficientNet models. Weinvestigate the importance of component selection and propose two types of treesearch approaches, both employing a greedy strategy, for optimal eigencomponentselection. Our study conducts three main experiments to evaluate theeffectiveness of our approach. The first experiment explores the influence oftest set performance on component choice, the second experiment examines theperformance when we train on one anomaly type and evaluate on all other types,and the third experiment investigates the impact of using a minimum number ofimages for training and selecting them based on anomaly types. Our approachaims to find the optimal subset of components that deliver the highestperformance score, instead of focusing solely on the proportion of varianceexplained by each component and also understand the components behaviour indifferent settings. Our results indicate that the proposed method surpassesboth Principal Component Analysis (PCA) and Negated Principal ComponentAnalysis (NPCA) in terms of detection accuracy, even when using fewercomponents. Thus, our approach provides a promising alternative to conventionaldimensionality reduction techniques in AD, and holds potential to enhance theefficiency and effectiveness of AD systems.", "output": "Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalisation of deep neural networks becomes vulnerable when distributionshifts are encountered between train (source) and test (target) domain data.Few-shot domain adaptation mitigates this issue by adapting deep neuralnetworks pre-trained on the source domain to the target domain using a randomlyselected and annotated support set from the target domain. This paper arguesthat randomly selecting the support set can be further improved for effectivelyadapting the pre-trained source models to the target domain. Alternatively, wepropose SelectNAdapt, an algorithm to curate the selection of the target domainsamples, which are then annotated and included in the support set. Inparticular, for the K-shot adaptation problem, we first leverageself-supervision to learn features of the target domain data. Then, we proposea per-class clustering scheme of the learned target domain features and selectK representative target samples using a distance-based scoring function.Finally, we bring our selection setup towards a practical ground by relying onpseudo-labels for clustering semantically similar target domain samples. Ourexperiments show promising results on three few-shot domain adaptationbenchmarks for image recognition compared to related approaches and thestandard random selection.", "output": "SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "End-to-end weakly supervised semantic segmentation aims at optimizing asegmentation model in a single-stage training process based on only imageannotations. Existing methods adopt an online-trained classification branch toprovide pseudo annotations for supervising the segmentation branch. However,this strategy makes the classification branch dominate the whole concurrenttraining process, hindering these two branches from assisting each other. Inour work, we treat these two branches equally by viewing them as diverse waysto generate the segmentation map, and add interactions on both theirsupervision and operation to achieve mutual promotion. For this purpose, abidirectional supervision mechanism is elaborated to force the consistencybetween the outputs of these two branches. Thus, the segmentation branch canalso give feedback to the classification branch to enhance the quality oflocalization seeds. Moreover, our method also designs interaction operationsbetween these two branches to exchange their knowledge to assist each other.Experiments indicate our work outperforms existing end-to-end weakly supervisedsegmentation methods.", "output": "Branches Mutual Promotion for End-to-End Weakly Supervised Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot SemanticSegmentation (FSS) to simultaneously segment unseen classes and seen classesduring evaluation. Previous works leverage additional branch or prototypicalaggregation to eliminate the constrained setting of FSS. However,representation division and embedding prejudice, which heavily results in poorperformance of GFSS, have not been synthetical considered. We address theaforementioned problems by jointing the prototypical kernel learning andopen-set foreground perception. Specifically, a group of learnable kernels isproposed to perform segmentation with each kernel in charge of a stuff class.Then, we explore to merge the prototypical learning to the update of base-classkernels, which is consistent with the prototype knowledge aggregation offew-shot novel classes. In addition, a foreground contextual perception modulecooperating with conditional bias based inference is adopted to performclass-agnostic as well as open-set foreground detection, thus to mitigate theembedding prejudice and prevent novel targets from being misclassified asbackground. Moreover, we also adjust our method to the Class IncrementalFew-shot Semantic Segmentation (CIFSS) which takes the knowledge of novelclasses in a incremental stream. Extensive experiments on PASCAL-5i andCOCO-20i datasets demonstrate that our method performs better than previousstate-of-the-art.", "output": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Due to the extremely low signal-to-noise ratio (SNR) and unknown poses(projection angles and image translation) in cryo-EM experiments,reconstructing 3D structures from 2D images is very challenging. On top ofthese challenges, heterogeneous cryo-EM reconstruction also has an additionalrequirement: conformation classification. An emerging solution to this problemis called amortized inference, implemented using the autoencoder architectureor its variants. Instead of searching for the correctimage-to-pose/conformation mapping for every image in the dataset as innon-amortized methods, amortized inference only needs to train an encoder thatmaps images to appropriate latent spaces representing poses or conformations.Unfortunately, standard amortized-inference-based methods with entangled latentspaces have difficulty learning the distribution of conformations and posesfrom cryo-EM images. In this paper, we propose an unsupervised deep learningarchitecture called \"ACE-HetEM\" based on amortized inference. To explicitlyenforce the disentanglement of conformation classifications and poseestimations, we designed two alternating training tasks in our method:image-to-image task and pose-to-pose task. Results on simulated datasets showthat ACE-HetEM has comparable accuracy in pose estimation and produces evenbetter reconstruction resolution than non-amortized methods. Furthermore, weshow that ACE-HetEM is also applicable to real experimental datasets.", "output": "ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A Point Distribution Model (PDM) is the basis of a Statistical Shape Model(SSM) that relies on a set of landmark points to represent a shape andcharacterize the shape variation. In this work, we present a self-supervisedapproach to extract landmark points from a given registration model for thePDMs. Based on the assumption that the landmarks are the points that have themost influence on registration, existing works learn a point-based registrationmodel with a small number of points to estimate the landmark points thatinfluence the deformation the most. However, such approaches assume that thedeformation can be captured by point-based registration and quality landmarkscan be learned solely with the deformation capturing objective. We argue thatdata with complicated deformations can not easily be modeled with point-basedregistration when only a limited number of points is used to extractinfluential landmark points. Further, landmark consistency is not assured inexisting approaches In contrast, we propose to extract landmarks based on agiven registration model, which is tailored for the target data, so we canobtain more accurate correspondences. Secondly, to establish the anatomicalconsistency of the predicted landmarks, we introduce a landmark discovery lossto explicitly encourage the model to predict the landmarks that areanatomically consistent across subjects. We conduct experiments on anosteoarthritis progression prediction task and show our method outperformsexisting image-based and point-based approaches.", "output": "Self-supervised Landmark Learning with Deformation Reconstruction and Cross-subject Consistency Objectives."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Foreground object search (FOS) aims to find compatible foreground objects fora given background image, producing realistic composite image. We observe thatcompetitive retrieval performance could be achieved by using a discriminator topredict the compatibility of composite image, but this approach hasunaffordable time cost. To this end, we propose a novel FOS method viadistilling composite feature (DiscoFOS). Specifically, the abovementioneddiscriminator serves as teacher network. The student network employs twoencoders to extract foreground feature and background feature. Theirinteraction output is enforced to match the composite image feature from theteacher network. Additionally, previous works did not release their datasets,so we contribute two datasets for FOS task: S-FOSD dataset with syntheticcomposite images and R-FOSD dataset with real composite images. Extensiveexperiments on our two datasets demonstrate the superiority of the proposedmethod over previous approaches. The dataset and code are available at", "output": "Foreground Object Search by Distilling Composite Image Feature."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The availability of large-scale authentic face databases has been crucial tothe significant advances made in face recognition research over the pastdecade. However, legal and ethical concerns led to the recent retraction ofmany of these databases by their creators, raising questions about thecontinuity of future face recognition research without one of its keyresources. Synthetic datasets have emerged as a promising alternative toprivacy-sensitive authentic data for face recognition development. However,recent synthetic datasets that are used to train face recognition models suffereither from limitations in intra-class diversity or cross-class (identity)discrimination, leading to less optimal accuracies, far away from theaccuracies achieved by models trained on authentic data. This paper targetsthis issue by proposing IDiff-Face, a novel approach based on conditionallatent diffusion models for synthetic identity generation with realisticidentity variations for face recognition training. Through extensiveevaluations, our proposed synthetic-based face recognition approach pushed thelimits of state-of-the-art performances, achieving, for example, 98.00%accuracy on the Labeled Faces in the Wild (LFW) benchmark, far ahead from therecent synthetic-based face recognition solutions with 95.40% and bridging thegap to authentic-based face recognition with 99.82% accuracy.", "output": "IDiff-Face: Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning (DL) models are gaining popularity in forest variableprediction using Earth Observation images. However, in practical forestinventories, reference datasets are often represented by plot- or stand-levelmeasurements, while high-quality representative wall-to-wall reference data forend-to-end training of DL models are rarely available. Transfer learningfacilitates expansion of the use of deep learning models into areas withsub-optimal training data by allowing pretraining of the model in areas wherehigh-quality teaching data are available. In this study, we perform a \"modeltransfer\" (or domain adaptation) of a pretrained DL model into a target areausing plot-level measurements and compare performance versus other machinelearning models. We use an earlier developed UNet based model (SeUNet) todemonstrate the approach on two distinct taiga sites with varying foreststructure and composition. Multisource Earth Observation (EO) data arerepresented by a combination of Copernicus Sentinel-1 C-band SAR and Sentinel-2multispectral images, JAXA ALOS-2 PALSAR-2 SAR mosaic and TanDEM-X bistaticinterferometric radar data. The training study site is located in FinnishLapland, while the target site is located in Southern Finland. By leveragingtransfer learning, the prediction of SeUNet achieved root mean squared error(RMSE) of 2.70 m and R$^2$ of 0.882, considerably more accurate thantraditional benchmark methods. We expect such forest-specific DL model transfercan be suitable also for other forest variables and other EO data sources thatare sensitive to forest structure.", "output": "Deep Learning Model Transfer in Forest Mapping using Multi-source Satellite SAR and Optical Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While diffusion models have achieved promising performances in datasynthesis, they might suffer error propagation because of their cascadestructure, where the distributional mismatch spreads and magnifies through thechain of denoising modules. However, a strict analysis is expected since manysequential models such as Conditional Random Field (CRF) are free from errorpropagation. In this paper, we empirically and theoretically verify thatdiffusion models are indeed affected by error propagation and we then propose aregularization to address this problem. Our theoretical analysis reveals thatthe question can be reduced to whether every denoising module of the diffusionmodel is fault-tolerant. We derive insightful transition equations, indicatingthat the module can't recover from input errors and even propagates additionalerrors to the next module. Our analysis directly leads to a consistencyregularization scheme for diffusion models, which explicitly reduces thedistribution gap between forward and backward processes. We further introduce abootstrapping algorithm to reduce the computation cost of the regularizer. Ourexperimental results on multiple image datasets show that our regularizationeffectively handles error propagation and significantly improves theperformance of vanilla diffusion models.", "output": "Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer-based methods have exhibited remarkable potential in single imagesuper-resolution (SISR) by effectively extracting long-range dependencies.However, most of the current research in this area has prioritized the designof transformer blocks to capture global information, while overlooking theimportance of incorporating high-frequency priors, which we believe could bebeneficial. In our study, we conducted a series of experiments and found thattransformer structures are more adept at capturing low-frequency information,but have limited capacity in constructing high-frequency representations whencompared to their convolutional counterparts. Our proposed solution, thecross-refinement adaptive feature modulation transformer (CRAFT), integratesthe strengths of both convolutional and transformer structures. It comprisesthree key components: the high-frequency enhancement residual block (HFERB) forextracting high-frequency information, the shift rectangle window attentionblock (SRWAB) for capturing global information, and the hybrid fusion block(HFB) for refining the global representation. Our experiments on multipledatasets demonstrate that CRAFT outperforms state-of-the-art methods by up to0.29dB while using fewer parameters. The source code will be made available at:", "output": "Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Perception that involves multi-object detection and tracking, and trajectoryprediction are two major tasks of autonomous driving. However, they arecurrently mostly studied separately, which results in most trajectoryprediction modules being developed based on ground truth trajectories withouttaking into account that trajectories extracted from the detection and trackingmodules in real-world scenarios are noisy. These noisy trajectories can have asignificant impact on the performance of the trajectory predictor and can leadto serious prediction errors. In this paper, we build an end-to-end frameworkfor detection, tracking, and trajectory prediction called ODTP (OnlineDetection, Tracking and Prediction). It adopts the state-of-the-art onlinemulti-object tracking model, QD-3DT, for perception and trains the trajectorypredictor, DCENet++, directly based on the detection results without purelyrelying on ground truth trajectories. We evaluate the performance of ODTP onthe widely used nuScenes dataset for autonomous driving. Extensive experimentsshow that ODPT achieves high performance end-to-end trajectory prediction.DCENet++, with the enhanced dynamic maps, predicts more accurate trajectoriesthan its base model. It is also more robust when compared with other generativeand deterministic trajectory prediction models trained on noisy detectionresults.", "output": "An End-to-End Framework of Road User Detection, Tracking, and Prediction from Monocular Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One of the important bottlenecks in training modern object detectors is theneed for labeled images where bounding box annotations have to be produced foreach object present in the image. This bottleneck is further exacerbated inaerial images where the annotators have to label small objects oftendistributed in clusters on high-resolution images. In recent days, themean-teacher approach trained with pseudo-labels and weak-strong augmentationconsistency is gaining popularity for semi-supervised object detection.However, a direct adaptation of such semi-supervised detectors for aerialimages where small clustered objects are often present, might not lead tooptimal results. In this paper, we propose a density crop-guidedsemi-supervised detector that identifies the cluster of small objects duringtraining and also exploits them to improve performance at inference. Duringtraining, image crops of clusters identified from labeled and unlabeled imagesare used to augment the training set, which in turn increases the chance ofdetecting small objects and creating good pseudo-labels for small objects onthe unlabeled images. During inference, the detector is not only able to detectthe objects of interest but also regions with a high density of small objects(density crops) so that detections from the input image and detections fromimage crops are combined, resulting in an overall more accurate objectprediction, especially for small objects. Empirical studies on the popularbenchmarks of VisDrone and DOTA datasets show the effectiveness of our densitycrop-guided semi-supervised detector with an average improvement of more than2% over the basic mean-teacher method in COCO style AP. Our code is availableat: ", "output": "Density Crop-guided Semi-supervised Object Detection in Aerial Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present PAT, a transformer-based network that learns complex temporalco-occurrence action dependencies in a video by exploiting multi-scale temporalfeatures. In existing methods, the self-attention mechanism in transformersloses the temporal positional information, which is essential for robust actiondetection. To address this issue, we (i) embed relative positional encoding inthe self-attention mechanism and (ii) exploit multi-scale temporalrelationships by designing a novel non hierarchical network, in contrast to therecent transformer-based approaches that use a hierarchical structure. We arguethat joining the self-attention mechanism with multiple sub-sampling processesin the hierarchical approaches results in increased loss of positionalinformation. We evaluate the performance of our proposed approach on twochallenging dense multi-label benchmark datasets, and show that PAT improvesthe current state-of-the-art result by 1.1% and 0.6% mAP on the Charades andMultiTHUMOS datasets, respectively, thereby achieving the new state-of-the-artmAP at 26.5% and 44.6%, respectively. We also perform extensive ablationstudies to examine the impact of the different components of our proposednetwork.", "output": "PAT: Position-Aware Transformer for Dense Multi-Label Action Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning has revolutionized industries like computer vision, naturallanguage processing, and speech recognition. However, back propagation, themain method for training deep neural networks, faces challenges likecomputational overhead and vanishing gradients. In this paper, we propose anovel instant parameter update methodology that eliminates the need forcomputing gradients at each layer. Our approach accelerates learning, avoidsthe vanishing gradient problem, and outperforms state-of-the-art methods onbenchmark data sets. This research presents a promising direction for efficientand effective deep neural network training.", "output": "A Novel Method for improving accuracy in neural network by reinstating traditional back propagation technique."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many segmentation networks have been proposed for 3D volumetric segmentationof tumors and organs at risk. Hospitals and clinical institutions seek toaccelerate and minimize the efforts of specialists in image segmentation.Still, in case of errors generated by these networks, clinicians would have tomanually edit the generated segmentation maps. Given a 3D volume and itsputative segmentation map, we propose an approach to identify and measureerroneous regions in the segmentation map. Our method can estimate error at anypoint or node in a 3D mesh generated from a possibly erroneous volumetricsegmentation map, serving as a Quality Assurance tool. We propose a graphneural network-based transformer based on the Nodeformer architecture tomeasure and classify the segmentation errors at any point. We have evaluatedour network on a high-resolution micro-CT dataset of the human inner-ear bonylabyrinth structure by simulating erroneous 3D segmentation maps. Our networkincorporates a convolutional encoder to compute node-centric features from theinput micro-CT data, the Nodeformer to learn the latent graph embeddings, and aMulti-Layer Perceptron (MLP) to compute and classify the node-wise errors. Ournetwork achieves a mean absolute error of ~0.042 over other Graph NeuralNetworks (GNN) and an accuracy of 79.53% over other GNNs in estimating andclassifying the node-wise errors, respectively. We also put forth vertex-normalprediction as a custom pretext task for pre-training the CNN encoder to improvethe network's overall performance. Qualitative analysis shows the efficiency ofour network in correctly classifying errors and reducing misclassifications.", "output": "Geometric Learning-Based Transformer Network for Estimation of Segmentation Errors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advancements in Digital Document Restoration (DDR) have led tosignificant breakthroughs in analyzing highly damaged written artifacts. Amongthose, there has been an increasing interest in applying ArtificialIntelligence techniques for virtually unwrapping and automatically detectingink on the Herculaneum papyri collection. This collection consists ofcarbonized scrolls and fragments of documents, which have been digitized viaX-ray tomography to allow the development of ad-hoc deep learning-based DDRsolutions. In this work, we propose a modification of the Fast FourierConvolution operator for volumetric data and apply it in a segmentationarchitecture for ink detection on the challenging Herculaneum papyri,demonstrating its suitability via deep experimental analysis. To encourage theresearch on this task and the application of the proposed operator to othertasks involving volumetric data, we will release our implementation(", "output": "Volumetric Fast Fourier Convolution for Detecting Ink on the Carbonized Herculaneum Papyri."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In order to respond effectively in the aftermath of a disaster, emergencyservices and relief organizations rely on timely and accurate information aboutthe affected areas. Remote sensing has the potential to significantly reducethe time and effort required to collect such information by enabling a rapidsurvey of large areas. To achieve this, the main challenge is the automaticextraction of relevant information from remotely sensed data. In this work, weshow how the combination of drone-based data with deep learning methods enablesautomated and large-scale situation assessment. In addition, we demonstrate theintegration of onboard image processing techniques for the deployment ofautonomous drone-based aid delivery. The results show the feasibility of arapid and large-scale image analysis in the field, and that onboard imageprocessing can increase the safety of drone-based aid deliveries.", "output": "Drones4Good: Supporting Disaster Relief Through Remote Sensing and AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video Semantic Role Labeling (VidSRL) aims to detect the salient events fromgiven videos, by recognizing the predict-argument event structures and theinterrelationships between events. While recent endeavors have put forthmethods for VidSRL, they can be mostly subject to two key drawbacks, includingthe lack of fine-grained spatial scene perception and the insufficientlymodeling of video temporality. Towards this end, this work explores a novelholistic spatio-temporal scene graph (namely HostSG) representation based onthe existing dynamic scene graph structures, which well model both thefine-grained spatial semantics and temporal dynamics of videos for VidSRL.Built upon the HostSG, we present a nichetargeting VidSRL framework. Ascene-event mapping mechanism is first designed to bridge the gap between theunderlying scene structure and the high-level event semantic structure,resulting in an overall hierarchical scene-event (termed ICE) graph structure.We further perform iterative structure refinement to optimize the ICE graph,such that the overall structure representation can best coincide with end taskdemand. Finally, three subtask predictions of VidSRL are jointly decoded, wherethe end-to-end paradigm effectively avoids error propagation. On the benchmarkdataset, our framework boosts significantly over the current best-performingmodel. Further analyses are shown for a better understanding of the advances ofour methods.", "output": "Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic Role Labeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The purpose of the research is to determine if currently availableself-supervised learning techniques can accomplish human level comprehension ofvisual images using the same degree and amount of sensory input that peopleacquire from. Initial research on this topic solely considered data volumescaling. Here, we scale both the volume of data and the quality of the image.This scaling experiment is a self-supervised learning method that may be donewithout any outside financing. We find that scaling up data volume and pictureresolution at the same time enables human-level item detection performance atsub-human sizes.We run a scaling experiment with vision transformers trained onup to 200000 images up to 256 ppi.", "output": "A degree of image identification at sub-human scales could be possible with more advanced clusters."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the text-to-image generation field, recent remarkable progress in StableDiffusion makes it possible to generate rich kinds of novel photorealisticimages. However, current models still face misalignment issues (e.g.,problematic spatial relation understanding and numeration failure) in complexnatural scenes, which impedes the high-faithfulness text-to-image generation.Although recent efforts have been made to improve controllability by givingfine-grained guidance (e.g., sketch and scribbles), this issue has not beenfundamentally tackled since users have to provide such guidance informationmanually. In this work, we strive to synthesize high-fidelity images that aresemantically aligned with a given textual prompt without any guidance. Towardthis end, we propose a coarse-to-fine paradigm to achieve layout planning andimage generation. Concretely, we first generate the coarse-grained layoutconditioned on a given textual prompt via in-context learning based on LargeLanguage Models. Afterward, we propose a fine-grained object-interactiondiffusion method to synthesize high-faithfulness images conditioned on theprompt and the automatically generated layout. Extensive experimentsdemonstrate that our proposed method outperforms the state-of-the-art models interms of layout and image generation. Our code and settings are available aturl{", "output": "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing methods for interactive segmentation in radiance fields entailscene-specific optimization and thus cannot generalize across different scenes,which greatly limits their applicability. In this work we make the firstattempt at Scene-Generalizable Interactive Segmentation in Radiance Fields(SGISRF) and propose a novel SGISRF method, which can perform 3D objectsegmentation for novel (unseen) scenes represented by radiance fields, guidedby only a few interactive user clicks in a given set of multi-view 2D images.In particular, the proposed SGISRF focuses on addressing three crucialchallenges with three specially designed techniques. First, we devise theCross-Dimension Guidance Propagation to encode the scarce 2D user clicks intoinformative 3D guidance representations. Second, the Uncertainty-Eliminated 3DSegmentation module is designed to achieve efficient yet effective 3Dsegmentation. Third, Concealment-Revealed Supervised Learning scheme isproposed to reveal and correct the concealed 3D segmentation errors resultedfrom the supervision in 2D space with only 2D mask annotations. Extensiveexperiments on two real-world challenging benchmarks covering diverse scenesdemonstrate 1) effectiveness and scene-generalizability of the proposed method,2) favorable performance compared to classical method requiring scene-specificoptimization.", "output": "Scene-Generalizable Interactive Segmentation of Radiance Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Target detection algorithm based on deep learning needs high computer GPUconfiguration, even need to use high performance deep learning workstation,this not only makes the cost increase, also greatly limits the realizability ofthe ground, this paper introduces a kind of lightweight algorithm for targetdetection under the condition of the balance accuracy and computationalefficiency, MobileNet as Backbone performs parameter The processing speed is30fps on the RTX2060 card for images with the CNN separator layer. Theprocessing speed is 30fps on the RTX2060 card for images with a resolution of320*320.", "output": "A lightweight target detection algorithm based on Mobilenet Convolution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-scale representations are crucial for semantic segmentation. Thecommunity has witnessed the flourish of semantic segmentation convolutionalneural networks (CNN) exploiting multi-scale contextual information. Motivatedby that the vision transformer (ViT) is powerful in image classification, somesemantic segmentation ViTs are recently proposed, most of them attainingimpressive results but at a cost of computational economy. In this paper, wesucceed in introducing multi-scale representations into semantic segmentationViT via window attention mechanism and further improves the performance andefficiency. To this end, we introduce large window attention which allows thelocal window to query a larger area of context window at only a littlecomputation overhead. By regulating the ratio of the context area to the queryarea, we enable the $textit{large window attention}$ to capture the contextualinformation at multiple scales. Moreover, the framework of spatial pyramidpooling is adopted to collaborate with $textit{the large window attention}$,which presents a novel decoder named $textbf{la}$rge $textbf{win}$dowattention spatial pyramid pooling (LawinASPP) for semantic segmentation ViT.Our resulting ViT, Lawin Transformer, is composed of an efficient hierachicalvision transformer (HVT) as encoder and a LawinASPP as decoder. The empiricalresults demonstrate that Lawin Transformer offers an improved efficiencycompared to the existing method. Lawin Transformer further sets newstate-of-the-art performance on Cityscapes (84.4% mIoU), ADE20K (56.2% mIoU)and COCO-Stuff datasets. The code will be released at", "output": "Lawin Transformer: Improving Semantic Segmentation Transformer with Multi-Scale Representations via Large Window Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning methods have shown outstanding classification accuracy inmedical imaging problems, which is largely attributed to the availability oflarge-scale datasets manually annotated with clean labels. However, given thehigh cost of such manual annotation, new medical imaging classificationproblems may need to rely on machine-generated noisy labels extracted fromradiology reports. Indeed, many Chest X-ray (CXR) classifiers have already beenmodelled from datasets with noisy labels, but their training procedure is ingeneral not robust to noisy-label samples, leading to sub-optimal models.Furthermore, CXR datasets are mostly multi-label, so current noisy-labellearning methods designed for multi-class problems cannot be easily adapted. Inthis paper, we propose a new method designed for the noisy multi-label CXRlearning, which detects and smoothly re-labels samples from the dataset, whichis then used to train common multi-label classifiers. The proposed methodoptimises a bag of multi-label descriptors (BoMD) to promote their similaritywith the semantic descriptors produced by BERT models from the multi-labelimage annotation. Our experiments on diverse noisy multi-label training setsand clean testing sets show that our model has state-of-the-art accuracy androbustness in many CXR multi-label classification benchmarks.", "output": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "What matters for contrastive learning? We argue that contrastive learningheavily relies on informative features, or \"hard\" (positive or negative)features. Early works include more informative features by applying complexdata augmentations and large batch size or memory bank, and recent works designelaborate sampling approaches to explore informative features. The keychallenge toward exploring such features is that the source multi-view data isgenerated by applying random data augmentations, making it infeasible to alwaysadd useful information in the augmented data. Consequently, the informativenessof features learned from such augmented data is limited. In response, wepropose to directly augment the features in latent space, thereby learningdiscriminative representations without a large amount of input data. We performa meta learning technique to build the augmentation generator that updates itsnetwork parameters by considering the performance of the encoder. However,insufficient input data may lead the encoder to learn collapsed features andtherefore malfunction the augmentation generator. A new margin-injectedregularization is further added in the objective function to avoid the encoderlearning a degenerate mapping. To contrast all features in one gradientback-propagation step, we adopt the proposed optimization-driven unifiedcontrastive loss instead of the conventional contrastive loss. Empirically, ourmethod achieves state-of-the-art results on several benchmark datasets.", "output": "MetAug: Contrastive Learning via Meta Feature Augmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative models have emerged as an essential building block for many imagesynthesis and editing tasks. Recent advances in this field have also enabledhigh-quality 3D or video content to be generated that exhibits eithermulti-view or temporal consistency. With our work, we explore 4D generativeadversarial networks (GANs) that learn unconditional generation of 3D-awarevideos. By combining neural implicit representations with time-awarediscriminator, we develop a GAN framework that synthesizes 3D video supervisedonly with monocular videos. We show that our method learns a rich embedding ofdecomposable 3D structures and motions that enables new visual effects ofspatio-temporal renderings while producing imagery with quality comparable tothat of existing 3D or video GANs.", "output": "3D-Aware Video Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Adversarially robust classifiers possess a trait that non-robust models donot -- Perceptually Aligned Gradients (PAG). Their gradients with respect tothe input align well with human perception. Several works have identified PAGas a byproduct of robust training, but none have considered it as a standalonephenomenon nor studied its own implications. In this work, we focus on thistrait and test whether emph{Perceptually Aligned Gradients imply Robustness}.To this end, we develop a novel objective to directly promote PAG in trainingclassifiers and examine whether models with such gradients are more robust toadversarial attacks. Extensive experiments on multiple datasets andarchitectures validate that models with aligned gradients exhibit significantrobustness, exposing the surprising bidirectional connection between PAG androbustness. Lastly, we show that better gradient alignment leads to increasedrobustness and harness this observation to boost the robustness of existingadversarial training techniques.", "output": "Do Perceptually Aligned Gradients Imply Adversarial Robustness?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning to detect objects, such as humans, in imagery captured by anunmanned aerial vehicle (UAV) usually suffers from tremendous variations causedby the UAV's position towards the objects. In addition, existing UAV-basedbenchmark datasets do not provide adequate dataset metadata, which is essentialfor precise model diagnosis and learning features invariant to thosevariations. In this paper, we introduce Archangel, the first UAV-based objectdetection dataset composed of real and synthetic subsets captured with similarimagining conditions and UAV position and object pose metadata. A series ofexperiments are carefully designed with a state-of-the-art object detector todemonstrate the benefits of leveraging the metadata during model evaluation.Moreover, several crucial insights involving both real and synthetic dataduring model optimization are presented. In the end, we discuss the advantages,limitations, and future directions regarding Archangel to highlight itsdistinct value for the broader machine learning community.", "output": "Archangel: A Hybrid UAV-based Human Detection Benchmark with Position and Pose Metadata."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Estimating accurate lane lines in 3D space remains challenging due to theirsparse and slim nature. Previous works mainly focused on using images for 3Dlane detection, leading to inherent projection error and loss of geometryinformation. To address these issues, we explore the potential of leveragingLiDAR for 3D lane detection, either as a standalone method or in combinationwith existing monocular approaches. In this paper, we propose M$^2$-3DLaneNetto integrate complementary information from multiple sensors. Specifically,M$^2$-3DLaneNet lifts 2D features into 3D space by incorporating geometryinformation from LiDAR data through depth completion. Subsequently, the lifted2D features are further enhanced with LiDAR features through cross-modality BEVfusion. Extensive experiments on the large-scale OpenLane dataset demonstratethe effectiveness of M$^2$-3DLaneNet, regardless of the range (75m or 100m).", "output": "M$^2$-3DLaneNet: Exploring Multi-Modal 3D Lane Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While self-supervised learning techniques are often used to mining implicitknowledge from unlabeled data via modeling multiple views, it is unclear how toperform effective representation learning in a complex and inconsistentcontext. To this end, we propose a methodology, specifically consistency andcomplementarity network (CoCoNet), which avails of strict global inter-viewconsistency and local cross-view complementarity preserving regularization tocomprehensively learn representations from multiple views. On the global stage,we reckon that the crucial knowledge is implicitly shared among views, andenhancing the encoder to capture such knowledge from data can improve thediscriminability of the learned representations. Hence, preserving the globalconsistency of multiple views ensures the acquisition of common knowledge.CoCoNet aligns the probabilistic distribution of views by utilizing anefficient discrepancy metric measurement based on the generalized slicedWasserstein distance. Lastly on the local stage, we propose a heuristiccomplementarity-factor, which joints cross-view discriminative knowledge, andit guides the encoders to learn not only view-wise discriminability but alsocross-view complementary information. Theoretically, we provide theinformation-theoretical-based analyses of our proposed CoCoNet. Empirically, toinvestigate the improvement gains of our approach, we conduct adequateexperimental validations, which demonstrate that CoCoNet outperforms thestate-of-the-art self-supervised methods by a significant margin proves thatsuch implicit consistency and complementarity preserving regularization canenhance the discriminability of latent representations.", "output": "Modeling Multiple Views via Implicitly Preserving Global Consistency and Local Complementarity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work we introduce CUTS (Contrastive and Unsupervised Training forSegmentation), a fully unsupervised deep learning framework for medical imagesegmentation to better utilize the vast majority of imaging data that is notlabeled or annotated. We utilize self-supervision from pixels and their localneighborhoods in the images themselves. Our unsupervised approach optimizes atraining objective that leverages concepts from contrastive learning andautoencoding. Our framework segments medical images with a novel two-stageapproach without relying on any labeled data at any stage. The first stageinvolves the creation of a \"pixel-centered patch\" that embeds every pixel alongwith its surrounding patch, using a vector representation in a high-dimensionallatent embedding space. The second stage utilizes diffusion condensation, amulti-scale topological data analysis approach, to dynamically coarse-grainthese embedding vectors at all levels of granularity. The final outcome is aseries of coarse-to-fine segmentations that highlight image structures atvarious scales. In this work, we show successful multi-scale segmentation onnatural images, retinal fundus images, and brain MRI images. Our frameworkdelineates structures and patterns at different scales which, in the cases ofmedical images, may carry distinct information relevant to clinicalinterpretation. Quantitatively, our framework demonstrates improvements rangingfrom 10% to 200% on dice coefficient and Hausdorff distance compared toexisting unsupervised methods across three medical image datasets. As we tacklethe problem of segmenting medical images at multiple meaningful granularitieswithout relying on any label, we hope to demonstrate the possibility tocircumvent tedious and repetitive manual annotations in future practice.", "output": "CUTS: A Fully Unsupervised Framework for Medical Image Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a unified and compact scene representation for robotics, whereeach object in the scene is depicted by a latent code capturing geometry andappearance. This representation can be decoded for various tasks such as novelview rendering, 3D reconstruction (e.g. recovering depth, point clouds, orvoxel maps), collision checking, and stable grasp prediction. We build ourrepresentation from a single RGB input image at test time by leveraging recentadvances in Neural Radiance Fields (NeRF) that learn category-level priors onlarge multiview datasets, then fine-tune on novel objects from one or fewviews. We expand the NeRF model for additional grasp outputs and explore waysto leverage this representation for robotics. At test-time, we build therepresentation from a single RGB input image observing the scene from only oneviewpoint. We find that the recovered representation allows rendering fromnovel views, including of occluded object parts, and also for predictingsuccessful stable grasps. Grasp poses can be directly decoded from our latentrepresentation with an implicit grasp decoder. We experimented in bothsimulation and real world and demonstrated the capability for robust roboticgrasping using such compact representation. Website:", "output": "One-Shot Neural Fields for 3D Object Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While text-to-image synthesis currently enjoys great popularity amongresearchers and the general public, the security of these models has beenneglected so far. Many text-guided image generation models rely on pre-trainedtext encoders from external sources, and their users trust that the retrievedmodels will behave as promised. Unfortunately, this might not be the case. Weintroduce backdoor attacks against text-guided generative models anddemonstrate that their text encoders pose a major tampering risk. Our attacksonly slightly alter an encoder so that no suspicious model behavior is apparentfor image generations with clean prompts. By then inserting a single charactertrigger into the prompt, e.g., a non-Latin character or emoji, the adversarycan trigger the model to either generate images with pre-defined attributes orimages following a hidden, potentially malicious description. We empiricallydemonstrate the high effectiveness of our attacks on Stable Diffusion andhighlight that the injection process of a single backdoor takes less than twominutes. Besides phrasing our approach solely as an attack, it can also forcean encoder to forget phrases related to certain concepts, such as nudity orviolence, and help to make image generation safer.", "output": "Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In autonomous driving systems, LiDAR and radar play important roles in theperception of the surrounding environment. LiDAR provides accurate 3D spatialsensing information but cannot work in adverse weather like fog. On the otherhand, the radar signal can be diffracted when encountering raindrops or mistparticles thanks to its wavelength, but it suffers from large noise. Recentstate-of-the-art works reveal that fusion of radar and LiDAR can lead to robustdetection in adverse weather. The existing works adopt convolutional neuralnetwork architecture to extract features from each sensor data stream, thenalign and aggregate the two branch features to predict object detectionresults. However, these methods have low accuracy of bounding box estimationsdue to a simple design of label assignment and fusion strategies. In thispaper, we propose a bird's-eye view fusion learning-based anchor box-freeobject detection system, which fuses the feature derived from the radarrange-azimuth heatmap and the LiDAR point cloud to estimate the possibleobjects. Different label assignment strategies have been designed to facilitatethe consistency between the classification of foreground or background anchorpoints and the corresponding bounding box regressions. In addition, theperformance of the proposed object detector is further enhanced by employing anovel interactive transformer module. The superior performance of the methodsproposed in this paper has been demonstrated using the recently publishedOxford Radar RobotCar dataset. Our system's average precision significantlyoutperforms the best state-of-the-art method by 13.1% and 19.0% at IoU of 0.8under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing,respectively.", "output": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, learned image compression has achieved remarkable performance. Theentropy model, which estimates the distribution of the latent representation,plays a crucial role in boosting rate-distortion performance. However, mostentropy models only capture correlations in one dimension, while the latentrepresentation contain channel-wise, local spatial, and global spatialcorrelations. To tackle this issue, we propose the Multi-Reference EntropyModel (MEM) and the advanced version, MEM$^+$. These models capture thedifferent types of correlations present in latent representation. Specifically,We first divide the latent representation into slices. When decoding thecurrent slice, we use previously decoded slices as context and employ theattention map of the previously decoded slice to predict global correlations inthe current slice. To capture local contexts, we introduce two enhancedcheckerboard context capturing techniques that avoids performance degradation.Based on MEM and MEM$^+$, we propose image compression models MLIC andMLIC$^+$. Extensive experimental evaluations demonstrate that our MLIC andMLIC$^+$ models achieve state-of-the-art performance, reducing BD-rate by$8.05%$ and $11.39%$ on the Kodak dataset compared to VTM-17.0 when measuredin PSNR. Our code will be available at ", "output": "MLIC: Multi-Reference Entropy Model for Learned Image Compression."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the problem of time-limited robotic exploration in previouslyunseen environments where exploration is limited by a predefined amount oftime. We propose a novel exploration approach using learning-augmentedmodel-based planning. We generate a set of subgoals associated with frontierson the current map and derive a Bellman Equation for exploration with thesesubgoals. Visual sensing and advances in semantic mapping of indoor scenes areexploited for training a deep convolutional neural network to estimateproperties associated with each frontier: the expected unobserved area beyondthe frontier and the expected timesteps (discretized actions) required toexplore it. The proposed model-based planner is guaranteed to explore the wholescene if time permits. We thoroughly evaluate our approach on a large-scalepseudo-realistic indoor dataset (Matterport3D) with the Habitat simulator. Wecompare our approach with classical and more recent RL-based explorationmethods. Our approach surpasses the greedy strategies by 2.1% and the RL-basedexploration methods by 8.4% in terms of coverage.", "output": "Learning-Augmented Model-Based Planning for Visual Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we provide the observation that too few queries assigned aspositive samples in DETR with one-to-one set matching leads to sparsesupervision on the encoder's output which considerably hurt the discriminativefeature learning of the encoder and vice visa for attention learning in thedecoder. To alleviate this, we present a novel collaborative hybrid assignmentstraining scheme, namely $mathcal{C}$o-DETR, to learn more efficient andeffective DETR-based detectors from versatile label assignment manners. Thisnew training scheme can easily enhance the encoder's learning ability inend-to-end detectors by training the multiple parallel auxiliary headssupervised by one-to-many label assignments such as ATSS and Faster RCNN. Inaddition, we conduct extra customized positive queries by extracting thepositive coordinates from these auxiliary heads to improve the trainingefficiency of positive samples in the decoder. In inference, these auxiliaryheads are discarded and thus our method introduces no additional parameters andcomputational cost to the original detector while requiring no hand-craftednon-maximum suppression (NMS). We conduct extensive experiments to evaluate theeffectiveness of the proposed approach on DETR variants, including DAB-DETR,Deformable-DETR, and DINO-Deformable-DETR. The state-of-the-artDINO-Deformable-DETR with Swin-L can be improved from 58.5% to 59.5% AP on COCOval. Surprisingly, incorporated with ViT-L backbone, we achieve 66.0% AP onCOCO test-dev and 67.9% AP on LVIS val, outperforming previous methods by clearmargins with much fewer model sizes. Codes are available aturl{", "output": "DETRs with Collaborative Hybrid Assignments Training."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Novel view synthesis and 3D modeling using implicit neural fieldrepresentation are shown to be very effective for calibrated multi-viewcameras. Such representations are known to benefit from additional geometricand semantic supervision. Most existing methods that exploit additionalsupervision require dense pixel-wise labels or localized scene priors. Thesemethods cannot benefit from high-level vague scene priors provided in terms ofscenes' descriptions. In this work, we aim to leverage the geometric prior ofManhattan scenes to improve the implicit neural radiance field representations.More precisely, we assume that only the knowledge of the indoor scene (underinvestigation) being Manhattan is known -- with no additional informationwhatsoever -- with an unknown Manhattan coordinate frame. Such high-level prioris used to self-supervise the surface normals derived explicitly in theimplicit neural fields. Our modeling allows us to cluster the derived normalsand exploit their orthogonality constraints for self-supervision. Ourexhaustive experiments on datasets of diverse indoor scenes demonstrate thesignificant benefit of the proposed method over the established baselines. Thesource code will be available at", "output": "Surface Normal Clustering for Implicit Representation of Manhattan Scenes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While skin cancer detection has been a valuable deep learning application foryears, its evaluation has often neglected the context in which testing imagesare assessed. Traditional melanoma classifiers assume that their testingenvironments are comparable to the structured images they are trained on. Thispaper challenges this notion and argues that mole size, a critical attribute inprofessional dermatology, can be misleading in automated melanoma detection.While malignant melanomas tend to be larger than benign melanomas, relyingsolely on size can be unreliable and even harmful when contextual scaling ofimages is not possible. To address this issue, this implementation proposes acustom model that performs various data augmentation procedures to preventoverfitting to incorrect parameters and simulate real-world usage of melanomadetection applications. Multiple custom models employing different forms ofdata augmentation are implemented to highlight the most significant features ofmole classifiers. These implementations emphasize the importance of consideringuser unpredictability when deploying such applications. The caution requiredwhen manually modifying data is acknowledged, as it can result in data loss andbiased conclusions. Additionally, the significance of data augmentation in boththe dermatology and deep learning communities is considered.", "output": "Leveraging Contextual Data Augmentation for Generalizable Melanoma Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Foundation models are redefining how AI systems are built. Practitioners nowfollow a standard procedure to build their machine learning solutions: from apre-trained foundation model, they fine-tune the weights on the target task ofinterest. So, the Internet is swarmed by a handful of foundation modelsfine-tuned on many diverse tasks: these individual fine-tunings exist inisolation without benefiting from each other. In our opinion, this is a missedopportunity, as these specialized models contain rich and diverse features. Inthis paper, we thus propose model ratatouille, a new strategy to recycle themultiple fine-tunings of the same foundation model on diverse auxiliary tasks.Specifically, we repurpose these auxiliary weights as initializations formultiple parallel fine-tunings on the target task; then, we average allfine-tuned weights to obtain the final model. This recycling strategy aims atmaximizing the diversity in weights by leveraging the diversity in auxiliarytasks. Empirically, it improves the state of the art on the reference DomainBedbenchmark for out-of-distribution generalization. Looking forward, this workcontributes to the emerging paradigm of updatable machine learning where, akinto open-source software development, the community collaborates to reliablyupdate machine learning models. Our code is released:", "output": "Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The diagnostic quality of computed tomography (CT) scans is usuallyrestricted by the induced patient dose, scan speed, and image quality.Sparse-angle tomographic scans reduce radiation exposure and accelerate dataacquisition, but suffer from image artifacts and noise. Existing imageprocessing algorithms can restore CT reconstruction quality but often requirelarge training data sets or can not be used for truncated objects. This workpresents a self-supervised projection inpainting method that allows optimizingmissing projective views via gradient-based optimization. By reconstructingindependent stacks of projection data, a self-supervised loss is calculated inthe CT image domain and used to directly optimize projection image intensitiesto match the missing tomographic views constrained by the projection geometry.Our experiments on real X-ray microscope (XRM) tomographic mouse tibia bonescans show that our method improves reconstructions by 3.1-7.4%/7.7-17.6% interms of PSNR/SSIM with respect to the interpolation baseline. Our approach isapplicable as a flexible self-supervised projection inpainting tool fortomographic applications.", "output": "Geometric Constraints Enable Self-Supervised Sinogram Inpainting in Sparse-View Tomography."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Localization is an essential capability for mobile robots. A rapidly growingfield of research in this area is Visual Place Recognition (VPR), which is theability to recognize previously seen places in the world based solely onimages. This present work is the first tutorial paper on visual placerecognition. It unifies the terminology of VPR and complements prior researchin two important directions: 1) It provides a systematic introduction fornewcomers to the field, covering topics such as the formulation of the VPRproblem, a general-purpose algorithmic pipeline, an evaluation methodology forVPR approaches, and the major challenges for VPR and how they may be addressed.2) As a contribution for researchers acquainted with the VPR problem, itexamines the intricacies of different VPR problem types regarding input, dataprocessing, and output. The tutorial also discusses the subtleties behind theevaluation of VPR algorithms, e.g., the evaluation of a VPR system that has tofind all matching database images per query, as opposed to just a single match.Practical code examples in Python illustrate to prospective practitioners andresearchers how VPR is implemented and evaluated.", "output": "Visual Place Recognition: A Tutorial."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "There is a recently discovered and intriguing phenomenon called NeuralCollapse: at the terminal phase of training a deep neural network forclassification, the within-class penultimate feature means and the associatedclassifier vectors of all flat classes collapse to the vertices of a simplexEquiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenonby fixing the related classifier weights to a pre-computed ETF to induce neuralcollapse and maximize the separation of the learned features when training withimbalanced data. In this work, we propose to fix the linear classifier of adeep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF,and use a cosine similarity-based auxiliary loss to learn hierarchy-awarepenultimate features that collapse to the HAFrame. We demonstrate that ourapproach reduces the mistake severity of the model's predictions whilemaintaining its top-1 accuracy on several datasets of varying scales withhierarchies of heights ranging from 3 to 12. Code:", "output": "Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Active visual exploration addresses the issue of limited sensor capabilitiesin real-world scenarios, where successive observations are actively chosenbased on the environment. To tackle this problem, we introduce a new techniquecalled Attention-Map Entropy (AME). It leverages the internal uncertainty ofthe transformer-based model to determine the most informative observations. Incontrast to existing solutions, it does not require additional loss components,which simplifies the training. Through experiments, which also mimicretina-like sensors, we show that such simplified training significantlyimproves the performance of reconstruction, segmentation and classification onpublicly available datasets.", "output": "Active Visual Exploration Based on Attention-Map Entropy."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diffusion model (DM) has achieved SOTA performance by modeling the imagesynthesis process into a sequential application of a denoising network.However, different from image synthesis, image restoration (IR) has a strongconstraint to generate results in accordance with ground-truth. Thus, for IR,traditional DMs running massive iterations on a large model to estimate wholeimages or feature maps is inefficient. To address this issue, we propose anefficient DM for IR (DiffIR), which consists of a compact IR prior extractionnetwork (CPEN), dynamic IR transformer (DIRformer), and denoising network.Specifically, DiffIR has two training stages: pretraining and training DM. Inpretraining, we input ground-truth images into CPEN$_{S1}$ to capture a compactIR prior representation (IPR) to guide DIRformer. In the second stage, we trainthe DM to directly estimate the same IRP as pretrained CPEN$_{S1}$ only usingLQ images. We observe that since the IPR is only a compact vector, DiffIR canuse fewer iterations than traditional DM to obtain accurate estimations andgenerate more stable and realistic results. Since the iterations are few, ourDiffIR can adopt a joint optimization of CPEN$_{S2}$, DIRformer, and denoisingnetwork, which can further reduce the estimation error influence. We conductextensive experiments on several IR tasks and achieve SOTA performance whileconsuming less computational costs. Code is available aturl{", "output": "DiffIR: Efficient Diffusion Model for Image Restoration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Grounding 3D object affordance seeks to locate objects' ''actionpossibilities'' regions in the 3D space, which serves as a link betweenperception and operation for embodied agents. Existing studies primarily focuson connecting visual affordances with geometry structures, e.g. relying onannotations to declare interactive regions of interest on the object andestablishing a mapping between the regions and affordances. However, theessence of learning object affordance is to understand how to use it, and themanner that detaches interactions is limited in generalization. Normally,humans possess the ability to perceive object affordances in the physical worldthrough demonstration images or videos. Motivated by this, we introduce a noveltask setting: grounding 3D object affordance from 2D interactions in images,which faces the challenge of anticipating affordance through interactions ofdifferent sources. To address this problem, we devise a novelInteraction-driven 3D Affordance Grounding Network (IAG), which aligns theregion feature of objects from different sources and models the interactivecontexts for 3D object affordance grounding. Besides, we collect a Point-ImageAffordance Dataset (PIAD) to support the proposed task. Comprehensiveexperiments on PIAD demonstrate the reliability of the proposed task and thesuperiority of our method. The project is available at", "output": "Grounding 3D Object Affordance from 2D Interactions in Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Weakly supervised object localization (WSOL) is a challenging task aiming tolocalize objects with only image-level supervision. Recent works apply visualtransformer to WSOL and achieve significant success by exploiting thelong-range feature dependency in self-attention mechanism. However, existingtransformer-based methods synthesize the classification feature maps as thelocalization map, which leads to optimization conflicts between classificationand localization tasks. To address this problem, we propose to learn atask-specific spatial-aware token (SAT) to condition localization in a weaklysupervised manner. Specifically, a spatial token is first introduced in theinput space to aggregate representations for localization task. Then a spatialaware attention module is constructed, which allows spatial token to generateforeground probabilities of different patches by querying and to extractlocalization knowledge from the classification task. Besides, for the problemof sparse and unbalanced pixel-level supervision obtained from the image-levellabel, two spatial constraints, including batch area loss and normalizationloss, are designed to compensate and enhance this supervision. Experiments showthat the proposed SAT achieves state-of-the-art performance on both CUB-200 andImageNet, with 98.45% and 73.13% GT-known Loc, respectively. Even under theextreme setting of using only 1 image per class from ImageNet for training, SATalready exceeds the SOTA method by 2.1% GT-known Loc. Code and models areavailable at ", "output": "Spatial-Aware Token for Weakly Supervised Object Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The development of language models have moved from encoder-decoder todecoder-only designs. In addition, we observe that the two most popularmultimodal tasks, the generative and contrastive tasks, are nontrivial toaccommodate in one architecture, and further need adaptations for downstreamtasks. We propose a novel paradigm of training with a decoder-only model formultimodal tasks, which is surprisingly effective in jointly learning of thesedisparate vision-language tasks. This is done with a simple model, calledMaMMUT. It consists of a single vision encoder and a text decoder, and is ableto accommodate contrastive and generative learning by a novel two-pass approachon the text decoder. We demonstrate that joint learning of these diverseobjectives is simple, effective, and maximizes the weight-sharing of the modelacross these tasks. Furthermore, the same architecture enables straightforwardextensions to open-vocabulary object detection and video-language tasks. Themodel tackles a diverse range of tasks, while being modest in capacity. Ourmodel achieves the state of the art on image-text and text-image retrieval,video question answering and open-vocabulary detection tasks, outperformingmuch larger and more extensively trained foundational models. It shows verycompetitive results on VQA and Video Captioning, especially considering itscapacity. Ablations confirm the flexibility and advantages of our approach.", "output": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Interactive image segmentation enables annotators to efficiently performpixel-level annotation for segmentation tasks. However, the existinginteractive segmentation pipeline suffers from inefficient computations ofinteractive models because of the following two issues. First, annotators'later click is based on models' feedback of annotators' former click. Thisserial interaction is unable to utilize model's parallelism capabilities.Second, in each interaction step, the model handles the invariant image alongwith the sparse variable clicks, resulting in a process that's highlyrepetitive and redundant. For efficient computations, we propose a method namedInterFormer that follows a new pipeline to address these issues. InterFormerextracts and preprocesses the computationally time-consuming part i.e. imageprocessing from the existing process. Specifically, InterFormer employs a largevision transformer (ViT) on high-performance devices to preprocess images inparallel, and then uses a lightweight module called interactive multi-head selfattention (I-MSA) for interactive segmentation. Furthermore, the I-MSA module'sdeployment on low-power devices extends the practical application ofinteractive segmentation. The I-MSA module utilizes the preprocessed featuresto efficiently response to the annotator inputs in real-time. The experimentson several datasets demonstrate the effectiveness of InterFormer, whichoutperforms previous interactive segmentation models in terms of computationalefficiency and segmentation quality, achieve real-time high-quality interactivesegmentation on CPU-only devices. The code is available at", "output": "InterFormer: Real-time Interactive Image Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Three-River-Source region is a highly significant natural reserve inChina that harbors a plethora of botanical resources. To meet the practicalrequirements of botanical research and intelligent plant management, weconstruct a dataset for Plant detection in the Three-River-Source region(PTRS). It comprises 21 types, 6965 high-resolution images of 2160*3840 pixels,captured by diverse sensors and platforms, and featuring objects of varyingshapes and sizes. The PTRS presents us with challenges such as dense occlusion,varying leaf resolutions, and high feature similarity among plants, promptingus to develop a novel object detection network named PlantDet. This networkemploys a window-based efficient self-attention module (ST block) to generaterobust feature representation at multiple scales, improving the detectionefficiency for small and densely-occluded objects. Our experimental resultsvalidate the efficacy of our proposed plant detection benchmark, with aprecision of 88.1%, a mean average precision (mAP) of 77.6%, and a higherrecall compared to the baseline. Additionally, our method effectively overcomesthe issue of missing small objects.", "output": "PlantDet: A benchmark for Plant Detection in the Three-Rivers-Source Region."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The retrieval of 3D objects has gained significant importance in recent yearsdue to its broad range of applications in computer vision, computer graphics,virtual reality, and augmented reality. However, the retrieval of 3D objectspresents significant challenges due to the intricate nature of 3D models, whichcan vary in shape, size, and texture, and have numerous polygons and vertices.To this end, we introduce a novel SHREC challenge track that focuses onretrieving relevant 3D animal models from a dataset using sketch queries andexpedites accessing 3D models through available sketches. Furthermore, a newdataset named ANIMAR was constructed in this study, comprising a collection of711 unique 3D animal models and 140 corresponding sketch queries. Our contestrequires participants to retrieve 3D models based on complex and detailedsketches. We receive satisfactory results from eight teams and 204 runs.Although further improvement is necessary, the proposed task has the potentialto incentivize additional research in the domain of 3D object retrieval,potentially yielding benefits for a wide range of applications. We also provideinsights into potential areas of future research, such as improving techniquesfor feature extraction and matching and creating more diverse datasets toevaluate retrieval performance. ", "output": "SketchANIMAR: Sketch-based 3D Animal Fine-Grained Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D object retrieval is an important yet challenging task that has drawn moreand more attention in recent years. While existing approaches have made stridesin addressing this issue, they are often limited to restricted settings such asimage and sketch queries, which are often unfriendly interactions for commonusers. In order to overcome these limitations, this paper presents a novelSHREC challenge track focusing on text-based fine-grained retrieval of 3Danimal models. Unlike previous SHREC challenge tracks, the proposed task isconsiderably more challenging, requiring participants to develop innovativeapproaches to tackle the problem of text-based retrieval. Despite the increaseddifficulty, we believe this task can potentially drive useful applications inpractice and facilitate more intuitive interactions with 3D objects. Fivegroups participated in our competition, submitting a total of 114 runs. Whilethe results obtained in our competition are satisfactory, we note that thechallenges presented by this task are far from fully solved. As such, weprovide insights into potential areas for future research and improvements. Webelieve we can help push the boundaries of 3D object retrieval and facilitatemore user-friendly interactions via vision-language technologies.", "output": "TextANIMAR: Text-based 3D Animal Fine-Grained Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents the first application of neural architecture search tothe complex task of segmenting visual anomalies. Measurement of anomalysegmentation performance is challenging due to imbalanced anomaly pixels,varying region areas, and various types of anomalies. First, theregion-weighted Average Precision (rwAP) metric is proposed as an alternativeto existing metrics, which does not need to be limited to a specific maximumfalse positive rate. Second, the AutoPatch neural architecture search method isproposed, which enables efficient segmentation of visual anomalies without anytraining. By leveraging a pre-trained supernet, a black-box optimizationalgorithm can directly minimize computational complexity and maximizeperformance on a small validation set of anomalous examples. Finally,compelling results are presented on the widely studied MVTec dataset,demonstrating that AutoPatch outperforms the current state-of-the-art withlower computational complexity, using only one example per type of anomaly. Theresults highlight the potential of automated machine learning to optimizethroughput in industrial quality control. The code for AutoPatch is availableat: ", "output": "Neural Architecture Search for Visual Anomaly Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer models are revolutionizing machine learning, but their innerworkings remain mysterious. In this work, we present a new visualizationtechnique designed to help researchers understand the self-attention mechanismin transformers that allows these models to learn rich, contextualrelationships between elements of a sequence. The main idea behind our methodis to visualize a joint embedding of the query and key vectors used bytransformer models to compute attention. Unlike previous attentionvisualization techniques, our approach enables the analysis of global patternsacross multiple input sequences. We create an interactive visualization tool,AttentionViz (demo: <a href=\" http URL</a>), based on these joint query-keyembeddings, and use it to study attention mechanisms in both language andvision transformers. We demonstrate the utility of our approach in improvingmodel understanding and offering new insights about query-key interactionsthrough several application scenarios and expert feedback.", "output": "AttentionViz: A Global View of Transformer Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Removing degradation from document images not only improves their visualquality and readability, but also enhances the performance of numerousautomated document analysis and recognition tasks. However, existingregression-based methods optimized for pixel-level distortion reduction tend tosuffer from significant loss of high-frequency information, leading todistorted and blurred text edges. To compensate for this major deficiency, wepropose DocDiff, the first diffusion-based framework specifically designed fordiverse challenging document enhancement problems, including documentdeblurring, denoising, and removal of watermarks and seals. DocDiff consists oftwo modules: the Coarse Predictor (CP), which is responsible for recovering theprimary low-frequency content, and the High-Frequency Residual Refinement (HRR)module, which adopts the diffusion models to predict the residual(high-frequency information, including text edges), between the ground-truthand the CP-predicted image. DocDiff is a compact and computationally efficientmodel that benefits from a well-designed network architecture, an optimizedtraining loss objective, and a deterministic sampling process with short timesteps. Extensive experiments demonstrate that DocDiff achieves state-of-the-art(SOTA) performance on multiple benchmark datasets, and can significantlyenhance the readability and recognizability of degraded document images.Furthermore, our proposed HRR module in pre-trained DocDiff is plug-and-playand ready-to-use, with only 4.17M parameters. It greatly sharpens the textedges generated by SOTA deblurring methods without additional joint training.Available codes: ", "output": "DocDiff: Document Enhancement via Residual Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Zero-shot sketch-based image retrieval (ZS-SBIR) is challenging due to thecross-domain nature of sketches and photos, as well as the semantic gap betweenseen and unseen image distributions. Previous methods fine-tune pre-trainedmodels with various side information and learning strategies to learn a compactfeature space that is shared between the sketch and photo domains and bridgesseen and unseen classes. However, these efforts are inadequate in adaptingdomains and transferring knowledge from seen to unseen classes. In this paper,we present an effective ``Adapt and Align'' approach to address the keychallenges. Specifically, we insert simple and lightweight domain adapters tolearn new abstract concepts of the sketch domain and improve cross-domainrepresentation capabilities. Inspired by recent advances in image-textfoundation models (e.g., CLIP) on zero-shot scenarios, we explicitly align thelearned image embedding with a more semantic text embedding to achieve thedesired knowledge transfer from seen to unseen classes. Extensive experimentson three benchmark datasets and two popular backbones demonstrate thesuperiority of our method in terms of retrieval accuracy and flexibility.", "output": "Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Scaling to arbitrarily large bundle adjustment problems requires data andcompute to be distributed across multiple devices. Centralized methods in priorworks are only able to solve small or medium size problems due to overhead incomputation and communication. In this paper, we present a fully decentralizedmethod that alleviates computation and communication bottlenecks to solvearbitrarily large bundle adjustment problems. We achieve this by reformulatingthe reprojection error and deriving a novel surrogate function that decouplesoptimization variables from different devices. This function makes it possibleto use majorization minimization techniques and reduces bundle adjustment toindependent optimization subproblems that can be solved in parallel. We furtherapply Nesterov's acceleration and adaptive restart to improve convergence whilemaintaining its theoretical guarantees. Despite limited peer-to-peercommunication, our method has provable convergence to first-order criticalpoints under mild conditions. On extensive benchmarks with public datasets, ourmethod converges much faster than decentralized baselines with similar memoryusage and communication load. Compared to centralized baselines using a singledevice, our method, while being decentralized, yields more accurate solutionswith significant speedups of up to 953.7x over Ceres and 174.6x over DeepLM.Code: ", "output": "Decentralization and Acceleration Enables Large-Scale Bundle Adjustment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A myriad of algorithms for the automatic analysis of brain MR images isavailable to support clinicians in their decision-making. For brain tumorpatients, the image acquisition time series typically starts with a scan thatis already pathological. This poses problems, as many algorithms are designedto analyze healthy brains and provide no guarantees for images featuringlesions. Examples include but are not limited to algorithms for brain anatomyparcellation, tissue segmentation, and brain extraction. To solve this dilemma,we introduce the BraTS 2023 inpainting challenge. Here, the participants' taskis to explore inpainting techniques to synthesize healthy brain scans fromlesioned ones. The following manuscript contains the task formulation, dataset,and submission procedure. Later it will be updated to summarize the findings ofthe challenge. The challenge is organized as part of the BraTS 2023 challengehosted at the MICCAI 2023 conference in Vancouver, Canada.", "output": "The Brain Tumor Segmentation (BraTS) Challenge 2023: Local Synthesis of Healthy Brain Tissue via Inpainting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With read-aloud speech synthesis achieving high naturalness scores, there isa growing research interest in synthesising spontaneous speech. However, humanspontaneous face-to-face conversation has both spoken and non-verbal aspects(here, co-speech gestures). Only recently has research begun to explore thebenefits of jointly synthesising these two modalities in a single system. Theprevious state of the art used non-probabilistic methods, which fail to capturethe variability of human speech and motion, and risk producing oversmoothingartefacts and sub-optimal synthesis quality. We present the firstdiffusion-based probabilistic model, called Diff-TTSG, that jointly learns tosynthesise speech and gestures together. Our method can be trained on smalldatasets from scratch. Furthermore, we describe a set of careful uni- andmulti-modal subjective tests for evaluating integrated speech and gesturesynthesis systems, and use them to validate our proposed approach. Please see for video examples, data, and code.", "output": "Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces MVDiffusion, a simple yet effective multi-view imagegeneration method for scenarios where pixel-to-pixel correspondences areavailable, such as perspective crops from panorama or multi-view images givengeometry (depth maps and poses). Unlike prior models that rely on iterativeimage warping and inpainting, MVDiffusion concurrently generates all imageswith a global awareness, encompassing high resolution and rich content,effectively addressing the error accumulation prevalent in preceding models.MVDiffusion specifically incorporates a correspondence-aware attentionmechanism, enabling effective cross-view interaction. This mechanism underpinsthree pivotal modules: 1) a generation module that produces low-resolutionimages while maintaining global correspondence, 2) an interpolation module thatdensifies spatial coverage between images, and 3) a super-resolution modulethat upscales into high-resolution outputs. In terms of panoramic imagery,MVDiffusion can generate high-resolution photorealistic images up to1024$times$1024 pixels. For geometry-conditioned multi-view image generation,MVDiffusion demonstrates the first method capable of generating a textured mapof a scene mesh. The project page is at ", "output": "MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diffusion models recently have been successfully applied for the visualsynthesis of strikingly realistic appearing images. This raises strong concernsabout their potential for malicious purposes. In this paper, we propose usingthe lightweight multi Local Intrinsic Dimensionality (multiLID), which has beenoriginally developed in context of the detection of adversarial examples, forthe automatic detection of synthetic images and the identification of theaccording generator networks. In contrast to many existing detectionapproaches, which often only work for GAN-generated images, the proposed methodprovides close to perfect detection results in many realistic use cases.Extensive experiments on known and newly created datasets demonstrate that theproposed multiLID approach exhibits superiority in diffusion detection andmodel identification. Since the empirical evaluations of recent publications onthe detection of generated images are often mainly focused on the\"LSUN-Bedroom\" dataset, we further establish a comprehensive benchmark for thedetection of diffusion-generated images, including samples from severaldiffusion models with different image sizes.", "output": "Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Voxel-based methods have achieved state-of-the-art performance for 3D objectdetection in autonomous driving. However, their significant computational andmemory costs pose a challenge for their application to resource-constrainedvehicles. One reason for this high resource consumption is the presence of alarge number of redundant background points in Lidar point clouds, resulting inspatial redundancy in both 3D voxel and dense BEV map representations. Toaddress this issue, we propose an adaptive inference framework called Ada3D,which focuses on exploiting the input-level spatial redundancy. Ada3Dadaptively filters the redundant input, guided by a lightweight importancepredictor and the unique properties of the Lidar point cloud. Additionally, weutilize the BEV features' intrinsic sparsity by introducing the SparsityPreserving Batch Normalization. With Ada3D, we achieve 40% reduction for 3Dvoxels and decrease the density of 2D BEV feature maps from 100% to 20% withoutsacrificing accuracy. Ada3D reduces the model computational and memory cost by5x, and achieves 1.52x/1.45x end-to-end GPU latency and 1.5x/4.5x GPU peakmemory optimization for the 3D and 2D backbone respectively.", "output": "Ada3D : Exploiting the Spatial Redundancy with Adaptive Inference for Efficient 3D Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing action recognition methods are typically actor-specific due to theintrinsic topological and apparent differences among the actors. This requiresactor-specific pose estimation (e.g., humans vs. animals), leading tocumbersome model design complexity and high maintenance costs. Moreover, theyoften focus on learning the visual modality alone and single-labelclassification whilst neglecting other available information sources (e.g.,class name text) and the concurrent occurrence of multiple actions. To overcomethese limitations, we propose a new approach called 'actor-agnostic multi-modalmulti-label action recognition,' which offers a unified solution for varioustypes of actors, including humans and animals. We further formulate a novelMulti-modal Semantic Query Network (MSQNet) model in a transformer-based objectdetection framework (e.g., DETR), characterized by leveraging visual andtextual modalities to represent the action classes better. The elimination ofactor-specific model designs is a key advantage, as it removes the need foractor pose estimation altogether. Extensive experiments on five publiclyavailable benchmarks show that our MSQNet consistently outperforms the priorarts of actor-specific alternatives on human and animal single- and multi-labelaction recognition tasks by up to 50%. Code will be released at", "output": "Actor-agnostic Multi-label Action Recognition with Multi-modal Query."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel method, LoLep, which regresses Locally-Learned planes froma single RGB image to represent scenes accurately, thus generating better novelviews. Without the depth information, regressing appropriate plane locations isa challenging problem. To solve this issue, we pre-partition the disparityspace into bins and design a disparity sampler to regress local offsets formultiple planes in each bin. However, only using such a sampler makes thenetwork not convergent; we further propose two optimizing strategies thatcombine with different disparity distributions of datasets and propose anocclusion-aware reprojection loss as a simple yet effective geometricsupervision technique. We also introduce a self-attention mechanism to improveocclusion inference and present a Block-Sampling Self-Attention (BS-SA) moduleto address the problem of applying self-attention to large feature maps. Wedemonstrate the effectiveness of our approach and generate state-of-the-artresults on different datasets. Compared to MINE, our approach has an LPIPSreduction of 4.8%-9.0% and an RV reduction of 73.9%-83.5%. We also evaluate theperformance on real-world images and demonstrate the benefits.", "output": "LoLep: Single-View View Synthesis with Locally-Learned Planes and Self-Attention Occlusion Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To facilitate the reuse of existing charts, previous research has examinedhow to obtain a semantic understanding of a chart by deconstructing its visualrepresentation into reusable components, such as encodings. However, existingdeconstruction approaches primarily focus on chart styles, handling only basiclayouts. In this paper, we investigate how to deconstruct chart layouts,focusing on rectangle-based ones, as they cover not only 17 chart types butalso advanced layouts (e.g., small multiples, nested layouts). We develop aninteractive tool, called Mystique, adopting a mixed-initiative approach toextract the axes and legend, and deconstruct a chart's layout into foursemantic components: mark groups, spatial relationships, data encodings, andgraphical constraints. Mystique employs a wizard interface that guides chartauthors through a series of steps to specify how the deconstructed componentsmap to their own data. On 150 rectangle-based SVG charts, Mystique achievesabove 85% accuracy for axis and legend extraction and 96% accuracy for layoutdeconstruction. In a chart reproduction study, participants could easily reuseexisting charts on new datasets. We discuss the current limitations of Mystiqueand future research directions.", "output": "Mystique: Deconstructing SVG Charts for Layout Reuse."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The advent of deep learning has brought a revolutionary transformation toimage denoising techniques. However, the persistent challenge of acquiringnoise-clean pairs for supervised methods in real-world scenarios remainsformidable, necessitating the exploration of more practical self-supervisedimage denoising. This paper focuses on self-supervised image denoising methodsthat offer effective solutions to address this challenge. Our comprehensivereview thoroughly analyzes the latest advancements in self-supervised imagedenoising approaches, categorizing them into three distinct classes: Generalmethods, Blind Spot Network (BSN)-based methods, and Transformer-based methods.For each class, we provide a concise theoretical analysis along with theirpractical applications. To assess the effectiveness of these methods, wepresent both quantitative and qualitative experimental results on variousdatasets, utilizing classical algorithms as benchmarks. Additionally, wecritically discuss the current limitations of these methods and proposepromising directions for future research. By offering a detailed overview ofrecent developments in self-supervised image denoising, this review serves asan invaluable resource for researchers and practitioners in the field,facilitating a deeper understanding of this emerging domain and inspiringfurther advancements.", "output": "Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human motion prediction (HMP) has emerged as a popular research topic due toits diverse applications, but it remains a challenging task due to thestochastic and aperiodic nature of future poses. Traditional methods rely onhand-crafted features and machine learning techniques, which often struggle tomodel the complex dynamics of human motion. Recent deep learning-based methodshave achieved success by learning spatio-temporal representations of motion,but these models often overlook the reliability of motion data. Additionally,the temporal and spatial dependencies of skeleton nodes are distinct. Thetemporal relationship captures motion information over time, while the spatialrelationship describes body structure and the relationships between differentnodes. In this paper, we propose a novel spatio-temporal branching networkusing incremental information for HMP, which decouples the learning oftemporal-domain and spatial-domain features, extracts more motion information,and achieves complementary cross-domain knowledge learning through knowledgedistillation. Our approach effectively reduces noise interference and providesmore expressive information for characterizing motion by separately extractingtemporal and spatial features. We evaluate our approach on standard HMPbenchmarks and outperform state-of-the-art methods in terms of predictionaccuracy.", "output": "Spatio-Temporal Branching for Motion Prediction using Motion Increments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a new Convolutional Neural Network (ConvNet)architecture inspired by a class of partial differential equations (PDEs)called quasi-linear hyperbolic systems. With comparable performance on theimage classification task, it allows for the modification of the weights via acontinuous group of symmetry. This is a significant shift from traditionalmodels where the architecture and weights are essentially fixed. We wish topromote the (internal) symmetry as a new desirable property for a neuralnetwork, and to draw attention to the PDE perspective in analyzing andinterpreting ConvNets in the broader Deep Learning community.", "output": "A Novel Convolutional Neural Network Architecture with a Continuous Symmetry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose an exhaustive methodology that leverages all levels of featureabstraction, targeting an enhancement in the generalizability of imageclassification to unobserved hospitals. Our approach incorporatesaugmentation-based self-supervision with common distribution shifts inhistopathology scenarios serving as the pretext task. This enables us to deriveinvariant features from training images without relying on training labels,thereby covering different abstraction levels. Moving onto the subsequentabstraction level, we employ a domain alignment module to facilitate furtherextraction of invariant features across varying training hospitals. Torepresent the highly specific features of participating hospitals, an encoderis trained to classify hospital labels, independent of their diagnostic labels.The features from each of these encoders are subsequently disentangled tominimize redundancy and segregate the features. This representation, whichspans a broad spectrum of semantic information, enables the development of amodel demonstrating increased robustness to unseen images from disparatedistributions. Experimental results from the PACS dataset (a domaingeneralization benchmark), a synthetic dataset created by applyinghistopathology-specific jitters to the MHIST dataset (defining differentdomains with varied distribution shifts), and a Renal Cell Carcinoma datasetderived from four image repositories from TCGA, collectively indicate that ourproposed model is adept at managing varying levels of image granularity. Thus,it shows improved generalizability when faced with new, out-of-distributionhospital images.", "output": "ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A major challenge in Explainable AI is in correctly interpreting activationsof hidden neurons: accurate interpretations would provide insights into thequestion of what a deep learning system has internally detected as relevant onthe input, demystifying the otherwise black-box character of deep learningsystems. The state of the art indicates that hidden node activations can, insome cases, be interpretable in a way that makes sense to humans, butsystematic automated methods that would be able to hypothesize and verifyinterpretations of hidden neuron activations are underexplored. In this paper,we provide such a method and demonstrate that it provides meaningfulinterpretations. Our approach is based on using large-scale backgroundknowledge approximately 2 million classes curated from the Wikipedia concepthierarchy together with a symbolic reasoning approach called Concept Inductionbased on description logics, originally developed for applications in theSemantic Web field. Our results show that we can automatically attachmeaningful labels from the background knowledge to individual neurons in thedense layer of a Convolutional Neural Network through a hypothesis andverification process.", "output": "Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Point clouds are naturally sparse, while image pixels are dense. Theinconsistency limits feature fusion from both modalities for point-wise sceneflow estimation. Previous methods rarely predict scene flow from the entirepoint clouds of the scene with one-time inference due to the memoryinefficiency and heavy overhead from distance calculation and sorting involvedin commonly used farthest point sampling, KNN, and ball query algorithms forlocal feature aggregation. To mitigate these issues in scene flow learning, weregularize raw points to a dense format by storing 3D coordinates in 2D grids.Unlike the sampling operation commonly used in existing works, the dense 2Drepresentation 1) preserves most points in the given scene, 2) brings in asignificant boost of efficiency, and 3) eliminates the density gap betweenpoints and pixels, allowing us to perform effective feature fusion. We alsopresent a novel warping projection technique to alleviate the information lossproblem resulting from the fact that multiple points could be mapped into onegrid during projection when computing cost volume. Sufficient experimentsdemonstrate the efficiency and effectiveness of our method, outperforming theprior-arts on the FlyingThings3D and KITTI dataset.", "output": "DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Wide-scale use of visual surveillance in public spaces puts individualprivacy at stake while increasing resource consumption (energy, bandwidth, andcomputation). Neuromorphic vision sensors (event-cameras) have been recentlyconsidered a valid solution to the privacy issue because they do not capturedetailed RGB visual information of the subjects in the scene. However, recentdeep learning architectures have been able to reconstruct images from eventcameras with high fidelity, reintroducing a potential threat to privacy forevent-based vision applications. In this paper, we aim to anonymizeevent-streams to protect the identity of human subjects against such imagereconstruction attacks. To achieve this, we propose an end-to-end networkarchitecture jointly optimized for the twofold objective of preserving privacyand performing a downstream task such as person ReId. Our network learns toscramble events, enforcing the degradation of images recovered from the privacyattacker. In this work, we also bring to the community the first everevent-based person ReId dataset gathered to evaluate the performance of ourapproach. We validate our approach with extensive experiments and reportresults on the synthetic event data simulated from the publicly availableSoftBio dataset and our proposed Event-ReId dataset.", "output": "Person Re-Identification without Identification via Event Anonymization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent studies of two-view correspondence learning usually establish anend-to-end network to jointly predict correspondence reliability and relativepose. We improve such a framework from two aspects. First, we propose a LocalFeature Consensus (LFC) plugin block to augment the features of existingmodels. Given a correspondence feature, the block augments its neighboringfeatures with mutual neighborhood consensus and aggregates them to produce anenhanced feature. As inliers obey a uniform cross-view transformation and sharemore consistent learned features than outliers, feature consensus strengthensinlier correlation and suppresses outlier distraction, which makes outputfeatures more discriminative for classifying inliers/outliers. Second, existingapproaches supervise network training with the ground truth correspondences andessential matrix projecting one image to the other for an input image pair,without considering the information from the reverse mapping. We extendexisting models to a Siamese network with a reciprocal loss that exploits thesupervision of mutual projection, which considerably promotes the matchingperformance without introducing additional model parameters. Building uponMSA-Net, we implement the two proposals and experimentally achievestate-of-the-art performance on benchmark datasets.", "output": "Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view Correspondence Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Online social media have become an important forum for exchanging politicalopinions. In response to COVID measures citizens expressed their policypreferences directly on these platforms. Quantifying political preferences inonline social media remains challenging: The vast amount of content requiresscalable automated extraction of political preferences -- however fine grainedpolitical preference extraction is difficult with current machine learning (ML)technology, due to the lack of data sets. Here we present a novel data set oftweets with fine grained political preference annotations. A textclassification model trained on this data is used to extract policy preferencesin a German Twitter corpus ranging from 2019 to 2022. Our results indicate thatin response to the COVID pandemic, expression of political opinions increased.Using a well established taxonomy of policy preferences we analyse fine grainedpolitical views and highlight changes in distinct political categories. Theseanalyses suggest that the increase in policy preference expression is dominatedby the categories pro-welfare, pro-education and pro-governmentaladministration efficiency. All training data and code used in this study aremade publicly available to encourage other researchers to further improveautomated policy preference extraction methods. We hope that our findingscontribute to a better understanding of political statements in online socialmedia and to a better assessment of how COVID measures impact politicalpreferences.", "output": "Changes in Policy Preferences in German Tweets during the COVID Pandemic."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative AI, the most popular current approach to AI, consists of largelanguage models (LLMs) that are trained to produce outputs that are plausible,but not necessarily correct. Although their abilities are often uncanny, theyare lacking in aspects of reasoning, leading LLMs to be less than completelytrustworthy. Furthermore, their results tend to be both unpredictable anduninterpretable.We lay out 16 desiderata for future AI, and discuss an alternative approachto AI which could theoretically address many of the limitations associated withcurrent approaches: AI educated with curated pieces of explicit knowledge andrules of thumb, enabling an inference engine to automatically deduce thelogical entailments of all that knowledge. Even long arguments produced thisway can be both trustworthy and interpretable, since the full step-by-step lineof reasoning is always available, and for each step the provenance of theknowledge used can be documented and audited. There is however a catch: if thelogical language is expressive enough to fully represent the meaning ofanything we can say in English, then the inference engine runs much too slowly.That's why symbolic AI systems typically settle for some fast but much lessexpressive logic, such as knowledge graphs. We describe how one AI system, Cyc,has developed ways to overcome that tradeoff and is able to reason in higherorder logic in real time.We suggest that any trustworthy general AI will need to hybridize theapproaches, the LLM approach and more formal approach, and lay out a path torealizing that dream.", "output": "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative Artificial Intelligence (AI) has seen mainstream adoption lately,especially in the form of consumer-facing, open-ended, text and imagegenerating models. However, the use of such systems raises significant ethicaland safety concerns, including privacy violations, misinformation andintellectual property theft. The potential for generative AI to displace humancreativity and livelihoods has also been under intense scrutiny. To mitigatethese risks, there is an urgent need of policies and regulations responsibleand ethical development in the field of generative AI. Existing and proposedcentralized regulations by governments to rein in AI face criticisms such asnot having sufficient clarity or uniformity, lack of interoperability acrosslines of jurisdictions, restricting innovation, and hindering free marketcompetition. Decentralized protections via crowdsourced safety tools andmechanisms are a potential alternative. However, they have clear deficienciesin terms of lack of adequacy of oversight and difficulty of enforcement ofethical and safety standards, and are thus not enough by themselves as aregulation mechanism. We propose a marriage of these two strategies via aframework we call Dual Governance. This framework proposes a cooperativesynergy between centralized government regulations in a U.S. specific contextand safety mechanisms developed by the community to protect stakeholders fromthe harms of generative AI. By implementing the Dual Governance framework, weposit that innovation and creativity can be promoted while ensuring safe andethical deployment of generative AI.", "output": "Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning prediction of electromagnetic software calculation results hasbeen a widely discussed issue in recent years. But the prediction accuracy wasstill one of the challenges to be solved. In this work, we proposed that theResNets-10 model was used for predicting plasmonic metasurface S11 parameters.The two-stage training was performed by the k-fold cross-validation and smalllearning rate. After the training was completed, the prediction loss foraluminum, gold, and silver metal-insulator-metal metasurfaces was -48.45,-46.47, and -35.54, respectively. Due to the ultralow error value, the proposednetwork can replace the traditional electromagnetic computing method forcalculation within a certain structural range. Besides, this network can finishthe training process less than 1,100 epochs. This means that the networktraining process can effectively lower the design process time. The ResNets-10model we proposed can also be used to design meta-diffractive devices andbiosensors, thereby reducing the time required for the calculation process. Theultralow error of the network indicates that this work contributes to thedevelopment of future artificial intelligence electromagnetic computingsoftware.", "output": "High-Accuracy Prediction of Metal-Insulator-Metal Metasurface with Deep Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning has emerged as a powerful tool in various fields, includingcomputer vision, natural language processing, and speech recognition. It canunravel hidden patterns within large data sets and reveal unparalleledinsights, revolutionizing many industries and disciplines. However, machine anddeep learning models lack interpretability and limited domain-specificknowledge, especially in applications such as physics and engineering.Alternatively, physics-informed machine learning (PIML) techniques integratephysics principles into data-driven models. By combining deep learning withdomain knowledge, PIML improves the generalization of the model, abidance bythe governing physical laws, and interpretability. This paper comprehensivelyreviews PIML applications related to subsurface energy systems, mainly in theoil and gas industry. The review highlights the successful utilization of PIMLfor tasks such as seismic applications, reservoir simulation, hydrocarbonsproduction forecasting, and intelligent decision-making in the exploration andproduction stages. Additionally, it demonstrates PIML's capabilities torevolutionize the oil and gas industry and other emerging areas of interest,such as carbon and hydrogen storage; and geothermal systems by providing moreaccurate and reliable predictions for resource management and operationalefficiency.", "output": "A Critical Review of Physics-Informed Machine Learning Applications in Subsurface Energy Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this research, we investigate the possibility of applying a searchstrategy to genetic algorithms to explore the entire genetic tree structure.Several methods aid in performing tree searches; however, simpler algorithmssuch as breadth-first, depth-first, and iterative techniques arecomputation-heavy and often result in a long execution time. Adversarialtechniques are often the preferred mechanism when performing a probabilisticsearch, yielding optimal results more quickly. The problem we are trying totackle in this paper is the optimization of neural networks using geneticalgorithms. Genetic algorithms (GA) form a tree of possible states and providea mechanism for rewards via the fitness function. Monte Carlo Tree Search(MCTS) has proven to be an effective tree search strategy given states andrewards; therefore, we will combine these approaches to optimally search forthe best result generated with genetic algorithms.", "output": "MCTS guided Genetic Algorithm for optimization of neural network weights."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, multiple data-driven models based on machine learning for weatherforecasting have emerged. These models are highly competitive in terms ofaccuracy compared to traditional numerical weather prediction (NWP) systems. Inparticular, the Pangu-Weather model, which is open source for non-commercialuse, has been validated for its forecasting performance by the European Centrefor Medium-Range Weather Forecasts (ECMWF) and has recently been published inthe journal \"Nature\". In this paper, we evaluate the compatibility of thePangu-Weather model with several commonly used NWP operational analyses throughcase studies. The results indicate that the Pangu-Weather model is compatiblewith different operational analyses from various NWP systems as the modelinitial conditions, and it exhibits a relatively stable forecasting capability.Furthermore, we have verified that improving the quality of global or localinitial conditions significantly contributes to enhancing the forecastingperformance of the Pangu-Weather model.", "output": "The Compatibility between the Pangu Weather Forecasting Model and Meteorological Operational Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Balance assessment during physical rehabilitation often relies onrubric-oriented battery tests to score a patient's physical capabilities,leading to subjectivity. While some objective balance assessments exist, theyare often limited to tracking the center of pressure (COP), which does notfully capture the whole-body postural stability. This study explores the use ofthe center of mass (COM) state space and presents a promising avenue formonitoring the balance capabilities in humans. We employ a musculoskeletalmodel integrated with a balance controller, trained through reinforcementlearning (RL), to investigate balancing capabilities. The RL framework consistsof two interconnected neural networks governing balance recovery and musclecoordination respectively, trained using Proximal Policy Optimization (PPO)with reference state initialization, early termination, and multiple trainingstrategies. By exploring recovery from random initial COM states (position andvelocity) space for a trained controller, we obtain the final BR enclosingsuccessful balance recovery trajectories. Comparing the BRs with analyticalpostural stability limits from a linear inverted pendulum model, we observe asimilar trend in successful COM states but more limited ranges in therecoverable areas. We further investigate the effect of muscle weakness andneural excitation delay on the BRs, revealing reduced balancing capability indifferent regions. Overall, our approach of learning muscular balancecontrollers presents a promising new method for establishing balance recoverylimits and objectively assessing balance capability in bipedal systems,particularly in humans.", "output": "Characterization of Human Balance through a Reinforcement Learning-based Muscle Controller."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) has been widely deployed to enable machine learningtraining on sensitive data across distributed devices. However, thedecentralized learning paradigm and heterogeneity of FL further extend theattack surface for backdoor attacks. Existing FL attack and defensemethodologies typically focus on the whole model. None of them recognizes theexistence of backdoor-critical (BC) layers-a small subset of layers thatdominate the model vulnerabilities. Attacking the BC layers achieves equivalenteffects as attacking the whole model but at a far smaller chance of beingdetected by state-of-the-art (SOTA) defenses. This paper proposes a generalin-situ approach that identifies and verifies BC layers from the perspective ofattackers. Based on the identified BC layers, we carefully craft a new backdoorattack methodology that adaptively seeks a fundamental balance betweenattacking effects and stealthiness under various defense strategies. Extensiveexperiments show that our BC layer-aware backdoor attacks can successfullybackdoor FL under seven SOTA defenses with only 10% malicious clients andoutperform the latest backdoor attack methods.", "output": "Backdoor Federated Learning by Poisoning Backdoor-Critical Layers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical insurance claims are of organized crimes related to patients,physicians, diagnostic centers, and insurance providers, forming a chainreaction that must be monitored constantly. These kinds of frauds affect thefinancial growth of both insured people and health insurance companies. TheConvolution Neural Network architecture is used to detect fraudulent claimsthrough a correlation study of regression models, which helps to detect moneylaundering on different claims given by different providers. Supervised andunsupervised classifiers are used to detect fraud and non-fraud claims.", "output": "Correlating Medi- Claim Service by Deep Learning Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a new aspect for determining the rank of theunimportant filters for filter pruning on convolutional neural networks (CNNs).In the human synaptic system, there are two important channels known asexcitatory and inhibitory neurotransmitters that transmit a signal from aneuron to a cell. Adopting the neuroscientific perspective, we propose asynapse-inspired filter pruning method, namely Dynamic Score (D-Score). D-Scoreanalyzes the independent importance of positive and negative weights in thefilters and ranks the independent importance by assigning scores. Filtershaving low overall scores, and thus low impact on the accuracy of neuralnetworks are pruned. The experimental results on CIFAR-10 and ImageNet datasetsdemonstrate the effectiveness of our proposed method by reducing notableamounts of FLOPs and Params without significant Acc. Drop.", "output": "D-Score: A Synapse-Inspired Approach for Filter Pruning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the modern financial industry system, the structure of products has becomemore and more complex, and the bottleneck constraint of classical computingpower has already restricted the development of the financial industry. Here,we present a photonic chip that implements the unary approach to Europeanoption pricing, in combination with the quantum amplitude estimation algorithm,to achieve a quadratic speedup compared to classical Monte Carlo methods. Thecircuit consists of three modules: a module loading the distribution of assetprices, a module computing the expected payoff, and a module performing thequantum amplitude estimation algorithm to introduce speed-ups. In thedistribution module, a generative adversarial network is embedded for efficientlearning and loading of asset distributions, which precisely capture the markettrends. This work is a step forward in the development of specialized photonicprocessors for applications in finance, with the potential to improve theefficiency and quality of financial services.", "output": "Efficient option pricing with unary-based photonic computing chip and generative adversarial learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this study, we utilize the emerging Physics Informed Neural Networks(PINNs) approach for the first time to predict the flow field of a compressorcascade. The approach is demonstrated on a two-dimensional problem,incorporating Navier-Stokes equations in both the forward and inverse problems.In the forward problem, PINNs effectively predict the flow field of thecompressor. The key advantage over Deep Neural Networks (DNNs) is that thePINNs model incorporates a physical relationship between the relevantquantities, resulting in more precise predictions. PINNs show obviousadvantages over the traditional CFD approaches when dealing with inverseproblems in the absence of partial boundary conditions. PINNs successfullyreconstruct the flow field of the compressor cascade solely based on partialvelocity vectors and wall pressure information. This research providescompelling evidence that PINNs offer turbomachinery designers a promisingalternative to the current dominant CFD methods, delivering higher accuracycompared to DNNs.", "output": "Investigation of compressor cascade flow based on physics-informed neural networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Arctic amplification has altered the climate patterns both regionally andglobally, resulting in more frequent and more intense extreme weather events inthe past few decades. The essential part of Arctic amplification is theunprecedented sea ice loss as demonstrated by satellite observations.Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales hasbeen a major research question with fundamental challenges at play. In additionto physics-based Earth system models, researchers have been applying multiplestatistical and machine learning models for sea ice forecasting. Looking at thepotential of data-driven approaches to study sea ice variations, we proposeMT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning modelfor forecasting Arctic sea ice concentration (SIC). The model uses anencoder-decoder architecture with skip connections and processes multi-temporalinput streams to regenerate spatial maps at future timesteps. Using bi-monthlyand monthly satellite retrieved sea ice data from NSIDC as well as atmosphericand oceanic variables from ERA5 reanalysis product during 1979-2021, we showthat our proposed model provides promising predictive performance for per-pixelSIC forecasting with up to 60% decrease in prediction error for a lead time of6 months as compared to its state-of-the-art counterparts.", "output": "MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Steganography and steganalysis are two interrelated aspects of the field ofinformation security. Steganography seeks to conceal communications, whereassteganalysis is aimed to either find them or even, if possible, recover thedata they contain. Steganography and steganalysis have attracted a great dealof interest, particularly from law enforcement. Steganography is often used bycybercriminals and even terrorists to avoid being captured while in possessionof incriminating evidence, even encrypted, since cryptography is prohibited orrestricted in many countries. Therefore, knowledge of cutting-edge techniquesto uncover concealed information is crucial in exposing illegal acts. Over thelast few years, a number of strong and reliable steganography and steganalysistechniques have been introduced in the literature. This review paper provides acomprehensive overview of deep learning-based steganalysis techniques used todetect hidden information within digital media. The paper covers all types ofcover in steganalysis, including image, audio, and video, and discusses themost commonly used deep learning techniques. In addition, the paper exploresthe use of more advanced deep learning techniques, such as deep transferlearning (DTL) and deep reinforcement learning (DRL), to enhance theperformance of steganalysis systems. The paper provides a systematic review ofrecent research in the field, including data sets and evaluation metrics usedin recent studies. It also presents a detailed analysis of DTL-basedsteganalysis approaches and their performance on different data sets. Thereview concludes with a discussion on the current state of deep learning-basedsteganalysis, challenges, and future research directions.", "output": "Deep Learning for Diverse Data Types Steganalysis: A Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The goal of our research was to investigate the effects of collaborationbetween academia and industry on Natural Language Processing (NLP). To do this,we created a pipeline to extract affiliations and citations from NLP papers anddivided them into three categories: academia, industry, and hybrid(collaborations between academia and industry). Our empirical analysis foundthat there is a trend towards an increase in industry and academia-industrycollaboration publications and that these types of publications tend to have ahigher impact compared to those produced solely within academia.", "output": "Who should I Collaborate with? A Comparative Study of Academia and Industry Research Collaboration in NLP."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to learn continuously from an incoming data stream withoutcatastrophic forgetting is critical to designing intelligent systems. Manyapproaches to continual learning rely on stochastic gradient descent and itsvariants that employ global error updates, and hence need to adopt strategiessuch as memory buffers or replay to circumvent its stability, greed, andshort-term memory limitations. To address this limitation, we have developed abiologically inspired lightweight neural network architecture that incorporatessynaptic plasticity mechanisms and neuromodulation and hence learns throughlocal error signals to enable online continual learning without stochasticgradient descent.Our approach leads to superior online continual learning performance onSplit-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to othermemory-constrained learning approaches and matches that of the state-of-the-artmemory-intensive replay-based approaches. We further demonstrate theeffectiveness of our approach by integrating key design concepts into otherbackpropagation-based continual learning algorithms, significantly improvingtheir accuracy. Our results provide compelling evidence for the importance ofincorporating biological principles into machine learning models and offerinsights into how we can leverage them to design more efficient and robustsystems for online continual learning.", "output": "Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Noisy labels hurt deep learning-based supervised image classificationperformance as the models may overfit the noise and learn corrupted featureextractors. For natural image classification training with noisy labeled data,model initialization with contrastive self-supervised pretrained weights hasshown to reduce feature corruption and improve classification performance.However, no works have explored: i) how other self-supervised approaches, suchas pretext task-based pretraining, impact the learning with noisy label, andii) any self-supervised pretraining methods alone for medical images in noisylabel settings. Medical images often feature smaller datasets and subtle interclass variations, requiring human expertise to ensure correct classification.Thus, it is not clear if the methods improving learning with noisy labels innatural image datasets such as CIFAR would also help with medical images. Inthis work, we explore contrastive and pretext task-based self-supervisedpretraining to initialize the weights of a deep learning classification modelfor two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100Ktissue histological images and COVID-QU-Ex chest X-ray images. Our results showthat models initialized with pretrained weights obtained from self-supervisedlearning can effectively learn better features and improve robustness againstnoisy labels.", "output": "Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Visual recognition models are prone to learning spurious correlations inducedby an imbalanced training set where certain groups (eg Females) areunder-represented in certain classes (eg Programmers). Generative models offera promising direction in mitigating this bias by generating synthetic data forthe minority samples and thus balancing the training set. However, prior workthat uses these approaches overlooks that visual recognition models could oftenlearn to differentiate between real and synthetic images and thus fail tounlearn the bias in the original dataset. In our work, we propose a noveltwo-stage pipeline to mitigate this issue where 1) we pre-train a model on abalanced synthetic dataset and then 2) fine-tune on the real data. Using thispipeline, we avoid training on both real and synthetic data, thus avoiding thebias between real and synthetic data. Moreover, we learn robust featuresagainst the bias in the first step that mitigate the bias in the second step.Moreover, our pipeline naturally integrates with bias mitigation methods; theycan be simply applied to the fine-tuning step. As our experiments prove, ourpipeline can further improve the performance of bias mitigation methodsobtaining state-of-the-art performance on three large-scale datasets.", "output": "From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Over the past two decades, recommendation systems (RSs) have used machinelearning (ML) solutions to recommend items, e.g., movies, books, andrestaurants, to clients of a business or an online platform. Reciperecommendation, however, has not yet received much attention compared to thoseapplications. We introduce RECipe as a multi-purpose recipe recommendationframework with a multi-modal knowledge graph (MMKG) backbone. The motivationbehind RECipe is to go beyond (deep) neural collaborative filtering (NCF) byrecommending recipes to users when they query in natural language or byproviding an image. RECipe consists of 3 subsystems: (1) behavior-basedrecommender, (2) review-based recommender, and (3) image-based recommender.Each subsystem relies on the embedding representations of entities andrelations in the graph. We first obtain (pre-trained) embedding representationsof textual entities, such as reviews or ingredients, from a fine-tuned model ofMicrosoft's MPNet. We initialize the weights of the entities with theseembeddings to train our knowledge graph embedding (KGE) model. For the visualcomponent, i.e., recipe images, we develop a KGE-Guided variational autoencoder(KG-VAE) to learn the distribution of images and their latent representations.Once KGE and KG-VAE models are fully trained, we use them as a multi-purposerecommendation framework. For benchmarking, we created two knowledge graphs(KGs) from public datasets on Kaggle for recipe recommendation. Our experimentsshow that the KGE models have comparable performance to the neural solutions.We also present pre-trained NLP embeddings to address important applicationssuch as zero-shot inference for new users (or the cold start problem) andconditional recommendation with respect to recipe categories. We eventuallydemonstrate the application of RECipe in a multi-purpose recommendationsetting.", "output": "RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We consider the problem of causal effect estimation with an unobservedconfounder, where we observe a proxy variable that is associated with theconfounder. Although Proxy Causal Learning (PCL) uses two proxy variables torecover the true causal effect, we show that a single proxy variable issufficient for causal estimation if the outcome is generated deterministically,generalizing Control Outcome Calibration Approach (COCA). We propose twokernel-based methods for this setting: the first based on the two-stageregression approach, and the second based on a maximum moment restrictionapproach. We prove that both approaches can consistently estimate the causaleffect, and we empirically demonstrate that we can successfully recover thecausal effect on a synthetic dataset.", "output": "Kernel Single Proxy Control for Deterministic Confounding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, uncertainty-aware deep learning methods for multiclass labelingproblems have been developed that provide calibrated class predictionprobabilities and out-of-distribution (OOD) indicators, letting machinelearning (ML) consumers and engineers gauge a model's confidence in itspredictions. However, this extra neural network prediction information ischallenging to scalably convey visually for arbitrary data sources undermultiple uncertainty contexts. To address these challenges, we presentScatterUQ, an interactive system that provides targeted visualizations to allowusers to better understand model performance in context-driven uncertaintysettings. ScatterUQ leverages recent advances in distance-aware neuralnetworks, together with dimensionality reduction techniques, to constructrobust, 2-D scatter plots explaining why a model predicts a test example to be(1) in-distribution and of a particular class, (2) in-distribution but unsureof the class, and (3) out-of-distribution. ML consumers and engineers canvisually compare the salient features of test samples with training examplesthrough the use of a ``hover callback'' to understand model uncertaintyperformance and decide follow up courses of action. We demonstrate theeffectiveness of ScatterUQ to explain model uncertainty for a multiclass imageclassification on a distance-aware neural network trained on Fashion-MNIST andtested on Fashion-MNIST (in distribution) and MNIST digits (out ofdistribution), as well as a deep learning model for a cyber dataset. Wequantitatively evaluate dimensionality reduction techniques to optimize ourcontextually driven UQ visualizations. Our results indicate that the ScatterUQsystem should scale to arbitrary, multiclass datasets. Our code is available at", "output": "ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tensor decomposition of convolutional and fully-connected layers is aneffective way to reduce parameters and FLOP in neural networks. Due to memoryand power consumption limitations of mobile or embedded devices, thequantization step is usually necessary when pre-trained models are deployed. Aconventional post-training quantization approach applied to networks withdecomposed weights yields a drop in accuracy. This motivated us to develop analgorithm that finds tensor approximation directly with quantized factors andthus benefit from both compression techniques while keeping the predictionquality of the model. Namely, we propose to use Alternating Direction Method ofMultipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whoseelements lie on a specified quantization grid. We compress neural networkweights with a devised algorithm and evaluate it's prediction quality andperformance. We compare our approach to state-of-the-art post-trainingquantization methods and demonstrate competitive results and high flexibilityin achiving a desirable quality-performance tradeoff.", "output": "Quantization Aware Factorization for Deep Neural Network Compression."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The act of secretly embedding and extracting a watermark on a cover image toprotect it is known as image watermarking. In recent years, deep learning-basedimage watermarking techniques have been emerging one after another. To studythe state-of-the-art, this survey categorizes cutting-edge deep learning-basedimage watermarking techniques into Embedder-Extractor Joint Training, DeepNetworks as a Feature Transformation, and Hybrid schemes. Research directionsin each category are also analyzed and summarized. Additionally, potentialfuture research directions are discussed to envision future studies.", "output": "Deep Learning based Image Watermarking: A Brief Survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, federated learning (FL) has become a very popular paradigmfor training distributed, large-scale, and privacy-preserving machine learning(ML) systems. In contrast to standard ML, where data must be collected at theexact location where training is performed, FL takes advantage of thecomputational capabilities of millions of edge devices to collaboratively traina shared, global model without disclosing their local private data.Specifically, in a typical FL system, the central server acts only as anorchestrator; it iteratively gathers and aggregates all the local modelstrained by each client on its private data until convergence. Although FLundoubtedly has several benefits over traditional ML (e.g., it protects privatedata ownership by design), it suffers from several weaknesses. One of the mostcritical challenges is to overcome the centralized orchestration of theclassical FL client-server architecture, which is known to be vulnerable tosingle-point-of-failure risks and man-in-the-middle attacks, among others. Tomitigate such exposure, decentralized FL solutions have emerged where all FLclients cooperate and communicate without a central server. This surveycomprehensively summarizes and reviews existing decentralized FL approachesproposed in the literature. Furthermore, it identifies emerging challenges andsuggests promising research directions in this under-explored domain.", "output": "A Survey on Decentralized Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although many deep-learning-based super-resolution approaches have beenproposed in recent years, because no ground truth is available in the inferencestage, few can quantify the errors and uncertainties of the super-resolvedresults. For scientific visualization applications, however, conveyinguncertainties of the results to scientists is crucial to avoid generatingmisleading or incorrect information. In this paper, we propose PSRFlow, a novelnormalizing flow-based generative model for scientific data super-resolutionthat incorporates uncertainty quantification into the super-resolution process.PSRFlow learns the conditional distribution of the high-resolution data basedon the low-resolution counterpart. By sampling from a Gaussian latent spacethat captures the missing information in the high-resolution data, one cangenerate different plausible super-resolution outputs. The efficient samplingin the Gaussian latent space allows our model to perform uncertaintyquantification for the super-resolved results. During model training, weaugment the training data with samples across various scales to make the modeladaptable to data of different scales, achieving flexible super-resolution fora given input. Our results demonstrate superior performance and robustuncertainty quantification compared with existing methods such as interpolationand GAN-based super-resolution networks.", "output": "PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere,perturbing the Total Electron Content (TEC) - referred to as TravelingIonospheric Disturbances (TIDs) that are detectable through the GlobalNavigation Satellite System (GNSS). The GNSS are constellations of satellitesproviding signals from Earth orbit - Europe's Galileo, the United States'Global Positioning System (GPS), Russia's Global'naya NavigatsionnayaSputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection ofTIDs provides an approach for tsunami detection, enhancing early warningsystems by providing open-ocean coverage in geographic areas not serviceable bybuoy-based warning systems. Large volumes of the GNSS data is leveraged by deeplearning, which effectively handles complex non-linear relationships acrossthousands of data streams. We describe a framework leveraging slant totalelectron content (sTEC) from the VARION (Variometric Approach for Real-TimeIonosphere Observation) algorithm by Gramian Angular Difference Fields (fromComputer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs innear-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012Haida-Gwaii earthquakes and tsunamis are used in model training, and thelater-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-samplemodel validation. Using the experimental framework described in the paper, weachieved a 91.7% F1 score. Source code is available at: Our work represents a new frontier indetecting tsunami-driven IGWs in open-ocean, dramatically improving thepotential for natural hazards detection for coastal communities.", "output": "Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the past few years, deep learning (DL) techniques have been introduced fordesigning sparse arrays. These methods offer the advantages of featureengineering and low prediction-stage complexity, which is helpful in tacklingthe combinatorial search inherent to finding a sparse array. In this chapter,we provide a synopsis of several direction finding applications of DL-basedsparse arrays. We begin by examining supervised and transfer learningtechniques that have applications in selecting sparse arrays for a cognitiveradar application. Here, we also discuss the use of meta-heuristic learningalgorithms such as simulated annealing for the case of designingtwo-dimensional sparse arrays. Next, we consider DL-based antenna selection forwireless communications, wherein sparse array problem may also be combined withchannel estimation, beamforming, or localization. Finally, we provide anexample of deep sparse array technique for integrated sensing andcommunications (ISAC) application, wherein a trade-off of radar andcommunications performance makes ISAC sparse array problem very challenging.For each setting, we illustrate the performance of model-based optimization andDL techniques through several numerical experiments. We discuss additionalconsiderations required to ensure robustness of DL-based algorithms againstvarious imperfections in array data.", "output": "Sparse Array Design for Direction Finding using Deep Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This comprehensive review systematically evaluates Machine Learning (ML)methodologies employed in the detection, prediction, and analysis of mentalstress and its consequent mental disorders (MDs). Utilizing a rigorous scopingreview process, the investigation delves into the latest ML algorithms,preprocessing techniques, and data types employed in the context of stress andstress-related MDs. The findings highlight that Support Vector Machine (SVM),Neural Network (NN), and Random Forest (RF) models consistently exhibitsuperior accuracy and robustness among all machine learning algorithmsexamined. Furthermore, the review underscores that physiological parameters,such as heart rate measurements and skin response, are prevalently used asstress predictors in ML algorithms. This is attributed to their richexplanatory information concerning stress and stress-related MDs, as well asthe relative ease of data acquisition. Additionally, the application ofdimensionality reduction techniques, including mappings, feature selection,filtering, and noise reduction, is frequently observed as a crucial steppreceding the training of ML algorithms. The synthesis of this reviewidentifies significant research gaps and outlines future directions for thefield. These encompass areas such as model interpretability, modelpersonalization, the incorporation of naturalistic settings, and real-timeprocessing capabilities for detection and prediction of stress andstress-related MDs.", "output": "Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural networks are vulnerable to backdoor attacks (Trojans), where anattacker poisons the training set with backdoor triggers so that the neuralnetwork learns to classify test-time triggers to the attacker's designatedtarget class. Recent work shows that backdoor poisoning induces over-fitting(abnormally large activations) in the attacked model, which motivates ageneral, post-training clipping method for backdoor mitigation, i.e., withbounds on internal-layer activations learned using a small set of cleansamples. We devise a new such approach, choosing the activation bounds toexplicitly limit classification margins. This method gives superior performanceagainst peer methods for CIFAR-10 image classification. We also show that thismethod has strong robustness against adaptive attacks, X2X attacks, and ondifferent datasets. Finally, we demonstrate a method extension for test-timedetection and correction based on the output differences between the originaland activation-bounded networks. The code of our method is online available.", "output": "Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study online multiclass classification under bandit feedback. We extendthe results of (daniely2013price) by showing that the finiteness of the BanditLittlestone dimension is necessary and sufficient for bandit online multiclasslearnability even when the label space is unbounded. Our result complements therecent work by (hanneke2023multiclass) who show that the Littlestone dimensioncharacterizes online multiclass learnability in the full-information settingwhen the label space is unbounded.", "output": "Multiclass Online Learnability under Bandit Feedback."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Compressed Neural Networks have the potential to enable deep learning acrossnew applications and smaller computational environments. However, understandingthe range of learning tasks in which such models can succeed is not wellstudied. In this work, we apply sparse and binary-weighted Transformers tomultivariate time series problems, showing that the lightweight models achieveaccuracy comparable to that of dense floating-point Transformers of the samestructure. Our model achieves favorable results across three time serieslearning tasks: classification, anomaly detection, and single-step forecasting.Additionally, to reduce the computational complexity of the attentionmechanism, we apply two modifications, which show little to no decline in modelperformance: 1) in the classification task, we apply a fixed mask to the query,key, and value activations, and 2) for forecasting and anomaly detection, whichrely on predicting outputs at a single point in time, we propose an attentionmask to allow computation only at the current time step. Together, eachcompression technique and attention modification substantially reduces thenumber of non-zero operations necessary in the Transformer. We measure thecomputational savings of our approach over a range of metrics includingparameter count, bit size, and floating point operation (FLOPs) count, showingup to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.", "output": "Sparse Binary Transformers for Multivariate Time Series Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This research paper presents a novel approach to enhance optimizationperformance through the hybridization of Gaussian Crunching Search (GCS) andPowell's Method for derivative-free optimization. While GCS has shown promisein overcoming challenges faced by traditional derivative-free optimizationmethods [1], it may not always excel in finding the local minimum. On the otherhand, some traditional methods may have better performance in this regard.However, GCS demonstrates its strength in escaping the trap of local minima andapproaching the global minima. Through experimentation, we discovered that bycombining GCS with certain traditional derivative-free optimization methods, wecan significantly boost performance while retaining the respective advantagesof each method. This hybrid approach opens up new possibilities for optimizingcomplex systems and finding optimal solutions in a range of applications.", "output": "Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell's Method for Derivative-Free Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Heart failure is a debilitating condition that affects millions of peopleworldwide and has a significant impact on their quality of life and mortalityrates. An objective assessment of cardiac pressures remains an important methodfor the diagnosis and treatment prognostication for patients with heartfailure. Although cardiac catheterization is the gold standard for estimatingcentral hemodynamic pressures, it is an invasive procedure that carriesinherent risks, making it a potentially dangerous procedure for some patients.Approaches that leverage non-invasive signals - such as electrocardiogram (ECG)- have the promise to make the routine estimation of cardiac pressures feasiblein both inpatient and outpatient settings. Prior models trained to estimateintracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP))in a supervised fashion have shown good discriminatory ability but have beenlimited to the labeled dataset from the heart failure cohort. To address thisissue and build a robust representation, we apply deep metric learning (DML)and propose a novel self-supervised DML with distance-based mining thatimproves the performance of a model with limited labels. We use a dataset thatcontains over 5.4 million ECGs without concomitant central pressure labels topre-train a self-supervised DML model which showed improved classification ofelevated mPCWP compared to self-supervised contrastive baselines. Additionally,the supervised DML model that is using ECGs with access to 8,172 mPCWP labelsdemonstrated significantly better performance on the mPCWP regression taskcompared to the supervised baseline. Moreover, our data suggest that DML yieldsmodels that are performant across patient subgroups, even when some patientsubgroups are under-represented in the dataset. Our code is available at", "output": "Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study focuses on comparing deep learning methods for the segmentationand quantification of uncertainty in prostate segmentation from MRI images. Theaim is to improve the workflow of prostate cancer detection and diagnosis.Seven different U-Net-based architectures, augmented with Monte-Carlo dropout,are evaluated for automatic segmentation of the central zone, peripheral zone,transition zone, and tumor, with uncertainty estimation. The top-performingmodel in this study is the Attention R2U-Net, achieving a mean Intersectionover Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% forsegmenting all zones. Additionally, Attention R2U-Net exhibits the lowestuncertainty values, particularly in the boundaries of the transition zone andtumor, when compared to the other models.", "output": "Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Bayesian optimization (BO) is widely adopted in black-box optimizationproblems and it relies on a surrogate model to approximate the black-boxresponse function. With the increasing number of black-box optimization taskssolved and even more to solve, the ability to learn from multiple prior tasksto jointly pre-train a surrogate model is long-awaited to further boostoptimization efficiency. In this paper, we propose a simple approach topre-train a surrogate, which is a Gaussian process (GP) with a kernel definedon deep features learned from a Transformer-based encoder, using datasets fromprior tasks with possibly heterogeneous input spaces. In addition, we provide asimple yet effective mix-up initialization strategy for input tokenscorresponding to unseen input variables and therefore accelerate new tasks'convergence. Experiments on both synthetic and real benchmark problemsdemonstrate the effectiveness of our proposed pre-training and transfer BOstrategy over existing methods.", "output": "Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The accurate diagnosis on pathological subtypes for lung cancer is ofsignificant importance for the follow-up treatments and prognosis managements.In this paper, we propose self-generating hybrid feature network (SGHF-Net) foraccurately classifying lung cancer subtypes on computed tomography (CT) images.Inspired by studies stating that cross-scale associations exist in the imagepatterns between the same case's CT images and its pathological images, weinnovatively developed a pathological feature synthetic module (PFSM), whichquantitatively maps cross-modality associations through deep neural networks,to derive the \"gold standard\" information contained in the correspondingpathological images from CT images. Additionally, we designed a radiologicalfeature extraction module (RFEM) to directly acquire CT image information andintegrated it with the pathological priors under an effective feature fusionframework, enabling the entire classification model to generate more indicativeand specific pathologically related features and eventually output moreaccurate predictions. The superiority of the proposed model lies in its abilityto self-generate hybrid features that contain multi-modality image informationbased on a single-modality input. To evaluate the effectiveness, adaptability,and generalization ability of our model, we performed extensive experiments ona large-scale multi-center dataset (i.e., 829 cases from three hospitals) tocompare our model and a series of state-of-the-art (SOTA) classificationmodels. The experimental results demonstrated the superiority of our model forlung cancer subtypes classification with significant accuracy improvements interms of accuracy (ACC), area under the curve (AUC), and F1 score.", "output": "Classification of lung cancer subtypes on CT images with synthetic pathological priors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, a variety of Neural radiance fields methods have garneredremarkable success in high render speed. However, current accelerating methodsis specialized and not compatible for various implicit method, which prevent areal-time composition over different kinds of NeRF works. Since NeRF relies onsampling along rays, it's possible to provide a guidance generally. We proposea general implicit pipeline to rapidly compose NeRF objects. This new methodenables the casting of dynamic shadows within or between objects usinganalytical light sources while allowing multiple NeRF objects to be seamlesslyplaced and rendered together with any arbitrary rigid transformations. Mainly,our work introduces a new surface representation known as Neural Depth Fields(NeDF) that quickly determines the spatial relationship between objects byallowing direct intersection computation between rays and implicit surfaces. Itleverages an intersection neural network to query NeRF for acceleration insteadof depending on an explicit spatial structure.Our proposed method is the firstto enable both the progressive and interactive composition of NeRF objects.Additionally, it also serves as a previewing plugin for a range of existingNeRF works.", "output": "A General Implicit Framework for Fast NeRF Composition and Rendering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Partial differential equations (PDEs) underlie our understanding andprediction of natural phenomena across numerous fields, including physics,engineering, and finance. However, solving parametric PDEs is a complex taskthat necessitates efficient numerical methods. In this paper, we propose anovel approach for solving parametric PDEs using a Finite Element OperatorNetwork (FEONet). Our proposed method leverages the power of deep learning inconjunction with traditional numerical methods, specifically the finite elementmethod, to solve parametric PDEs in the absence of any paired input-outputtraining data. We demonstrate the effectiveness of our approach on severalbenchmark problems and show that it outperforms existing state-of-the-artmethods in terms of accuracy, generalization, and computational flexibility.Our FEONet framework shows potential for application in various fields wherePDEs play a crucial role in modeling complex domains with diverse boundaryconditions and singular behavior. Furthermore, we provide theoreticalconvergence analysis to support our approach, utilizing finite elementapproximation in numerical analysis.", "output": "Finite Element Operator Network for Solving Parametric PDEs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While artificial intelligence (AI) has made many successful applications invarious domains, its adoption in healthcare lags a little bit behind otherhigh-stakes settings. Several factors contribute to this slower uptake,including regulatory frameworks, patient privacy concerns, and dataheterogeneity. However, one significant challenge that impedes theimplementation of AI in healthcare, particularly in orthopedics, is the lack ofexplainability and interpretability around AI models. Addressing the challengeof explainable AI (XAI) in orthopedics requires developing AI models andalgorithms that prioritize transparency and interpretability, allowingclinicians, surgeons, and patients to understand the contributing factorsbehind any AI-powered predictive or descriptive models. The currentcontribution outlines several key challenges and opportunities that manifest inXAI in orthopedic practice. This work emphasizes the need for interdisciplinarycollaborations between AI practitioners, orthopedic specialists, and regulatoryentities to establish standards and guidelines for the adoption of XAI inorthopedics.", "output": "Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Corona VIrus Disease abbreviated as COVID-19 is a novel virus which isinitially identified in Wuhan of China in December of 2019 and now this deadlydisease has spread all over the world. According to World Health Organization(WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case,many methods, AI base techniques, and machine learning algorithms have beenresearched and are being used to save people from this pandemic. The SARS-CoVand the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differencesin the structure of cell proteins. Protein-protein interaction (PPI) is anessential process in our cells and plays a very important role in thedevelopment of medicines and gives ideas about the disease. In this study, weperformed clustering on PPI networks generated from 92 genes of the Covi-19dataset. We have used three graph-based clustering algorithms to give intuitionto the analysis of clusters.", "output": "An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning (ML)-based malware detection systems are becomingincreasingly important as malware threats increase and get more sophisticated.PDF files are often used as vectors for phishing attacks because they arewidely regarded as trustworthy data resources, and are accessible acrossdifferent platforms. Therefore, researchers have developed many different PDFmalware detection methods. Performance in detecting PDF malware is greatlyinfluenced by feature selection. In this research, we propose a small featuresset that don't require too much domain knowledge of the PDF file. We evaluateproposed features with six different machine learning models. We report thebest accuracy of 99.75% when using Random Forest model. Our proposed featureset, which consists of just 12 features, is one of the most conciseness in thefield of PDF malware detection. Despite its modest size, we obtain comparableresults to state-of-the-art that employ a much larger set of features.", "output": "A Feature Set of Small Size for the PDF Malware Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multimedia recommendation involves personalized ranking tasks, wheremultimedia content is usually represented using a generic encoder. However,these generic representations introduce spurious correlations that fail toreveal users' true preferences. Existing works attempt to alleviate thisproblem by learning invariant representations, but overlook the balance betweenindependent and identically distributed (IID) and out-of-distribution (OOD)generalization. In this paper, we propose a framework called Pareto InvariantRepresentation Learning (PaInvRL) to mitigate the impact of spuriouscorrelations from an IID-OOD multi-objective optimization perspective, bylearning invariant representations (intrinsic factors that attract userattention) and variant representations (other factors) simultaneously.Specifically, PaInvRL includes three iteratively executed modules: (i)heterogeneous identification module, which identifies the heterogeneousenvironments to reflect distributional shifts for user-item interactions; (ii)invariant mask generation module, which learns invariant masks based on thePareto-optimal solutions that minimize the adaptive weighted Invariant RiskMinimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, whichgenerates both variant representations and item-invariant representations fortraining a multi-modal recommendation model that mitigates spuriouscorrelations and balances the generalization performance within and cross theenvironmental distributions. We compare the proposed PaInvRL withstate-of-the-art recommendation models on three public multimediarecommendation datasets (Movielens, Tiktok, and Kwai), and the experimentalresults validate the effectiveness of PaInvRL for both within- andcross-environmental learning.", "output": "Pareto Invariant Representation Learning for Multimedia Recommendation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the task of probabilistic anomaly attribution in the black-boxregression setting, where the goal is to compute the probability distributionof the attribution score of each input variable, given an observed anomaly. Thetraining dataset is assumed to be unavailable. This task differs from thestandard XAI (explainable AI) scenario, since we wish to explain the anomalousdeviation from a black-box prediction rather than the black-box model itself.We begin by showing that mainstream model-agnostic explanation methods, suchas the Shapley values, are not suitable for this task because of their``deviation-agnostic property.'' We then propose a novel framework forprobabilistic anomaly attribution that allows us to not only computeattribution scores as the predictive mean but also quantify the uncertainty ofthose scores. This is done by considering a generative process forperturbations that counter-factually bring the observed anomalous observationback to normalcy. We introduce a variational Bayes algorithm for deriving thedistributions of per variable attribution scores. To the best of our knowledge,this is the first probabilistic anomaly attribution framework that is free frombeing deviation-agnostic.", "output": "Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advanced methods in Natural Language Understanding for Task-orientedDialogue (TOD) Systems (e.g., intent detection and slot filling) require alarge amount of annotated data to achieve competitive performance. In reality,token-level annotations (slot labels) are time-consuming and difficult toacquire. In this work, we study the Slot Induction (SI) task whose objective isto induce slot boundaries without explicit knowledge of token-level slotannotations. We propose leveraging Unsupervised Pre-trained Language Model(PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervisedsemantic knowledge extracted from PLM, and (2) additional sentence-level intentlabel signals available from TOD. Our approach is shown to be effective in SItask and capable of bridging the gaps with token-level supervised models on twoNLU benchmark datasets. When generalized to emerging intents, our SI objectivesalso provide enhanced slot label representations, leading to improvedperformance on the Slot Filling tasks.", "output": "Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Music generation has attracted growing interest with the advancement of deepgenerative models. However, generating music conditioned on textualdescriptions, known as text-to-music, remains challenging due to the complexityof musical structures and high sampling rate requirements. Despite the task'ssignificance, prevailing generative models exhibit limitations in musicquality, computational efficiency, and generalization. This paper introducesJEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is adiffusion model incorporating both autoregressive and non-autoregressivetraining. Through in-context learning, JEN-1 performs various generation tasksincluding text-guided music generation, music inpainting, and continuation.Evaluations demonstrate JEN-1's superior performance over state-of-the-artmethods in text-music alignment and music quality while maintainingcomputational efficiency. Our demos are available at<a href=\" http URL</a>", "output": "JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Physics-informed neural networks have been widely applied to partialdifferential equations with great success because the physics-informed lossessentially requires no observations or discretization. However, it isdifficult to optimize model parameters, and these parameters must be trainedfor each distinct initial condition. To overcome these challenges insecond-order reaction-diffusion type equations, a possible way is to usefive-point stencil convolutional neural networks (FCNNs). FCNNs are trainedusing two consecutive snapshots, where the time step corresponds to the stepsize of the given snapshots. Thus, the time evolution of FCNNs depends on thetime step, and the time step must satisfy its CFL condition to avoid blow-upsolutions. In this work, we propose deep FCNNs that have large receptive fieldsto predict time evolutions with a time step larger than the threshold of theCFL condition. To evaluate our models, we consider the heat, Fisher's, andAllen-Cahn equations with diverse initial conditions. We demonstrate that deepFCNNs retain certain accuracies, in contrast to FDMs that blow up.", "output": "Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "StorSeismic is a recently introduced model based on the Transformer to adaptto various seismic processing tasks through its pretraining and fine-tuningtraining strategy. In the original implementation, StorSeismic utilized asinusoidal positional encoding and a conventional self-attention mechanism,both borrowed from the natural language processing (NLP) applications. Forseismic processing they admitted good results, but also hinted to limitationsin efficiency and expressiveness. We propose modifications to these two keycomponents, by utilizing relative positional encoding and low-rank attentionmatrices as replacements to the vanilla ones. The proposed changes are testedon processing tasks applied to a realistic Marmousi and offshore field data asa sequential strategy, starting from denoising, direct arrival removal,multiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$)prediction for normal moveout (NMO) correction. We observe faster pretrainingand competitive results on the fine-tuning tasks and, additionally, fewerparameters to train compared to the vanilla model.", "output": "Optimizing a Transformer-based network for a deep learning seismic processing workflow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fuzzing has achieved tremendous success in discovering bugs andvulnerabilities in various software systems. Systems under test (SUTs) thattake in programming or formal language as inputs, e.g., compilers, runtimeengines, constraint solvers, and software libraries with accessible APIs, areespecially important as they are fundamental building blocks of softwaredevelopment. However, existing fuzzers for such systems often target a specificlanguage, and thus cannot be easily applied to other languages or even otherversions of the same language. Moreover, the inputs generated by existingfuzzers are often limited to specific features of the input language, and thuscan hardly reveal bugs related to other or new features. This paper presentsFuzz4All, the first fuzzer that is universal in the sense that it can targetmany different input languages and many different features of these languages.The key idea behind Fuzz4All is to leverage large language models (LLMs) as aninput generation and mutation engine, which enables the approach to producediverse and realistic inputs for any practically relevant language. To realizethis potential, we present a novel autoprompting technique, which creates LLMprompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop,which iteratively updates the prompt to create new fuzzing inputs. We evaluateFuzz4All on nine systems under test that take in six different languages (C,C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all sixlanguages, that universal fuzzing achieves higher coverage than existing,language-specific fuzzers. Furthermore, Fuzz4All has identified 76 bugs inwidely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskitquantum computing platform, with 47 bugs already confirmed by developers aspreviously unknown.", "output": "Universal Fuzzing via Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Consider a setting where multiple parties holding sensitive data aim tocollaboratively learn population level statistics, but pooling the sensitivedata sets is not possible. We propose a framework in which each party shares adifferentially private synthetic twin of their data. We study the feasibilityof combining such synthetic twin data sets for collaborative learning onreal-world health data from the UK Biobank. We discover that parties engagingin the collaborative learning via shared synthetic data obtain more accurateestimates of target statistics compared to using only their local data. Thisfinding extends to the difficult case of small heterogeneous data sets.Furthermore, the more parties participate, the larger and more consistent theimprovements become. Finally, we find that data sharing can especially helpparties whose data contain underrepresented groups to perform better-adjustedanalysis for said groups. Based on our results we conclude that sharing ofsynthetic twins is a viable method for enabling learning from sensitive datawithout violating privacy constraints even if individual data sets are small ordo not represent the overall population well. The setting of distributedsensitive data is often a bottleneck in biomedical research, which our studyshows can be alleviated with privacy-preserving collaborative learning methods.", "output": "Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL) has emerged as a privacy-preserving paradigm thattrains neural networks on edge devices without collecting data at a centralserver. However, FL encounters an inherent challenge in dealing withnon-independent and identically distributed (non-IID) data among devices. Toaddress this challenge, this paper proposes a hard feature matching datasynthesis (HFMDS) method to share auxiliary data besides local models.Specifically, synthetic data are generated by learning the essentialclass-relevant features of real samples and discarding the redundant features,which helps to effectively tackle the non-IID issue. For better privacypreservation, we propose a hard feature augmentation method to transfer realfeatures towards the decision boundary, with which the synthetic data not onlyimprove the model generalization but also erase the information of realfeatures. By integrating the proposed HFMDS method with FL, we present a novelFL framework with data augmentation to relieve data heterogeneity. Thetheoretical analysis highlights the effectiveness of our proposed datasynthesis method in solving the non-IID challenge. Simulation results furtherdemonstrate that our proposed HFMDS-FL algorithm outperforms the baselines interms of accuracy, privacy preservation, and computational cost on variousbenchmark datasets.", "output": "Feature Matching Data Synthesis for Non-IID Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In decentralized federated learning (DFL), substantial traffic from frequentinter-node communication and non-independent and identically distributed(non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL,a novel DFL method, which progressively refines a global model by transferringit sequentially amongst nodes, rather than by exchanging and aggregating localmodels. We also introduce a dynamic model routing algorithm for optimal routeselection, aimed at enhancing model precision with minimal forwarding. Ourexperiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FLwith the proposed routing delivers high model accuracy under non-IIDconditions, outperforming baselines while reducing communication costs.", "output": "Tram-FL: Routing-based Model Training for Decentralized Federated Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a new sparse unmixing technique using archetypalanalysis (SUnAA). First, we design a new model based on archetypal analysis. Weassume that the endmembers of interest are a convex combination of endmembersprovided by a spectral library and that the number of endmembers of interest isknown. Then, we propose a minimization problem. Unlike most conventional sparseunmixing methods, here the minimization problem is non-convex. We minimize theoptimization objective iteratively using an active set algorithm. Our method isrobust to the initialization and only requires the number of endmembers ofinterest. SUnAA is evaluated using two simulated datasets for which resultsconfirm its better performance over other conventional and advanced techniquesin terms of signal-to-reconstruction error. SUnAA is also applied to Cupritedataset and the results are compared visually with the available geological mapprovided for this dataset. The qualitative assessment demonstrates thesuccessful estimation of the minerals abundances and significantly improves thedetection of dominant minerals compared to the conventional regression-basedsparse unmixing methods. The Python implementation of SUnAA can be found at:", "output": "SUnAA: Sparse Unmixing using Archetypal Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, Transformer-based models have shown remarkable performance inlong-term time series forecasting (LTSF) tasks due to their ability to modellong-term dependencies. However, the validity of Transformers for LTSF tasksremains debatable, particularly since recent work has shown that simple linearmodels can outperform numerous Transformer-based approaches. This suggests thatthere are limitations to the application of Transformer in LTSF. Therefore,this paper investigates three key issues when applying Transformer to LTSF:temporal continuity, information density, and multi-channel relationships.Accordingly, we propose three innovative solutions, including PlaceholderEnhancement Technique (PET), Long Sub-sequence Division (LSD), andMulti-channel Separation and Interaction (MSI), which together form a novelmodel called PETformer. These three key designs introduce prior biases suitablefor LTSF tasks. Extensive experiments have demonstrated that PETformer achievesstate-of-the-art (SOTA) performance on eight commonly used public datasets forLTSF, outperforming all other models currently available. This demonstratesthat Transformer still possesses powerful capabilities in LTSF.", "output": "PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Spike trains data find a growing list of applications in computationalneuroscience, imaging, streaming data and finance. Machine learning strategiesfor spike trains are based on various neural network and probabilistic models.The probabilistic approach is relying on parametric or nonparametricspecifications of the underlying spike generation model. In this paper weconsider the two-class statistical classification problem for a class of spiketrain data characterized by nonparametrically specified intensity functions. Wederive the optimal Bayes rule and next form the plug-in nonparametric kernelclassifier. Asymptotical properties of the rules are established including thelimit with respect to the increasing recording time interval and the size of atraining set. In particular the convergence of the kernel classifier to theBayes rule is proved. The obtained results are supported by a finite samplesimulation studies.", "output": "Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Activation functions are essential components of neural networks. In thispaper, we introduce a new activation function called the Truncated and SignedSquare Root (TSSR) function. This function is distinctive because it is odd,nonlinear, monotone and differentiable. Its gradient is continuous and alwayspositive. Thanks to these properties, it has the potential to improve thenumerical stability of neural networks. Several experiments confirm that theproposed TSSR has better performance than other stat-of-the-art activationfunctions. The proposed function has significant implications for thedevelopment of neural network models and can be applied to a wide range ofapplications in fields such as computer vision, natural language processing,and speech recognition.", "output": "TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a new computing model for intrinsic rewards in reinforcementlearning that addresses the limitations of existing surprise-drivenexplorations. The reward is the novelty of the surprise rather than thesurprise norm. We estimate the surprise novelty as retrieval errors of a memorynetwork wherein the memory stores and reconstructs surprises. Our surprisememory (SM) augments the capability of surprise-based intrinsic motivators,maintaining the agent's interest in exciting exploration while reducingunwanted attraction to unpredictable or noisy observations. Our experimentsdemonstrate that the SM combined with various surprise predictors exhibitsefficient exploring behaviors and significantly boosts the final performance insparse reward environments, including Noisy-TV, navigation and challengingAtari games.", "output": "Intrinsic Motivation via Surprise Memory."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many multi-agent systems require inter-agent communication to properlyachieve their goal. By learning the communication protocol alongside the actionprotocol using multi-agent reinforcement learning techniques, the agents gainthe flexibility to determine which information should be shared. However, whenthe number of agents increases we need to create an encoding of the informationcontained in these messages. In this paper, we investigate the effect ofincreasing the amount of information that should be contained in a message andincreasing the number of agents. We evaluate these effects on two differentmessage encoding methods, the mean message encoder and the attention messageencoder. We perform our experiments on a matrix environment. Surprisingly, ourresults show that the mean message encoder consistently outperforms theattention message encoder. Therefore, we analyse the communication protocolused by the agents that use the mean message encoder and can conclude that theagents use a combination of an exponential and a logarithmic function in theircommunication policy to avoid the loss of important information after applyingthe mean message encoder.", "output": "Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose a novel way to improve the generalisation capacity of deeplearning models by reducing high correlations between neurons. For this, wepresent two regularisation terms computed from the weights of a minimumspanning tree of the clique whose vertices are the neurons of a given network(or a sample of those), where weights on edges are correlation dissimilarities.We provide an extensive set of experiments to validate the effectiveness of ourterms, showing that they outperform popular ones. Also, we demonstrate thatnaive minimisation of all correlations between neurons obtains lower accuraciesthan our regularisation terms, suggesting that redundancies play a significantrole in artificial neural networks, as evidenced by some studies inneuroscience for real networks. We include a proof of differentiability of ourregularisers, thus developing the first effective topological persistence-basedregularisation terms that consider the whole set of neurons and that can beapplied to a feedforward architecture in any deep learning task such asclassification, data generation, or regression.", "output": "Decorrelating neurons using persistence."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "On the modern web, trackers and advertisers frequently construct and monetizeusers' detailed behavioral profiles without consent. Despite various studies onweb tracking mechanisms and advertisements, there has been no rigorous studyfocusing on websites targeted at children. To address this gap, we present ameasurement of tracking and (targeted) advertising on websites directed atchildren. Motivated by lacking a comprehensive list of child-directed (i.e.,targeted at children) websites, we first build a multilingual classifier basedon web page titles and descriptions. Applying this classifier to over twomillion pages, we compile a list of two thousand child-directed websites.Crawling these sites from five vantage points, we measure the prevalence oftrackers, fingerprinting scripts, and advertisements. Our crawler detects adsdisplayed on child-directed websites and determines if ad targeting is enabledby scraping ad disclosure pages whenever available. Our results show thataround 90% of child-directed websites embed one or more trackers, and about 27%contain targeted advertisements--a practice that should require verifiableparental consent. Next, we identify improper ads on child-directed websites bydeveloping an ML pipeline that processes both images and text extracted fromads. The pipeline allows us to run semantic similarity queries for arbitrarysearch terms, revealing ads that promote services related to dating, weightloss, and mental health; as well as ads for sex toys and flirting chatservices. Some of these ads feature repulsive and sexually explicit imagery. Insummary, our findings indicate a trend of non-compliance with privacyregulations and troubling ad safety practices among many advertisers andchild-directed websites. To protect children and create a safer onlineenvironment, regulators and stakeholders must adopt and enforce more stringentmeasures.", "output": "Targeted and Troublesome: Tracking and Advertising on Children's Websites."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rapid growth of information in the field of Generative ArtificialIntelligence (AI), particularly in the subfields of Natural Language Processing(NLP) and Machine Learning (ML), presents a significant challenge forresearchers and practitioners to keep pace with the latest developments. Toaddress the problem of information overload, this report by the NaturalLanguage Learning Group at Bielefeld University focuses on identifying the mostpopular papers on arXiv, with a specific emphasis on NLP and ML. The objectiveis to offer a quick guide to the most relevant and widely discussed research,aiding both newcomers and established researchers in staying abreast of currenttrends. In particular, we compile a list of the 40 most popular papers based onnormalized citation counts from the first half of 2023. We observe thedominance of papers related to Large Language Models (LLMs) and specificallyChatGPT during the first half of 2023, with the latter showing signs ofdeclining popularity more recently, however. Further, NLP related papers arethe most influential (around 60% of top papers) even though there are twice asmany ML related papers in our data. Core issues investigated in the mostheavily cited papers are: LLM efficiency, evaluation techniques, ethicalconsiderations, embodied agents, and problem-solving with LLMs. Additionally,we examine the characteristics of top papers in comparison to others outsidethe top-40 list (noticing the top paper's focus on LLM related issues andhigher number of co-authors) and analyze the citation distributions in ourdataset, among others.", "output": "NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Data Science is a modern Data Intelligence practice, which is the core ofmany businesses and helps businesses build smart strategies around to deal withbusinesses challenges more efficiently. Data Science practice also helps inautomating business processes using the algorithm, and it has several otherbenefits, which also deliver in a non-profitable framework. In regards to datascience, three key components primarily influence the effective outcome of adata science project. Those are 1.Availability of Data 2.Algorithm 3.Processingpower or infrastructure", "output": "Why Data Science Projects Fail."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As we increasingly depend on software systems, the consequences of breachesin the software supply chain become more severe. High-profile cyber attackslike those on SolarWinds and ShadowHammer have resulted in significantfinancial and data losses, underlining the need for stronger cybersecurity. Oneway to prevent future breaches is by studying past failures. However,traditional methods of analyzing these failures require manually reading andsummarizing reports about them. Automated support could reduce costs and allowanalysis of more failures. Natural Language Processing (NLP) techniques such asLarge Language Models (LLMs) could be leveraged to assist the analysis offailures. In this study, we assessed the ability of Large Language Models(LLMs) to analyze historical software supply chain breaches. We used LLMs toreplicate the manual analysis of 69 software supply chain security failuresperformed by members of the Cloud Native Computing Foundation (CNCF). Wedeveloped prompts for LLMs to categorize these by four dimensions: type ofcompromise, intent, nature, and impact. GPT 3.5s categorizations had an averageaccuracy of 68% and Bard had an accuracy of 58% over these dimensions. Wereport that LLMs effectively characterize software supply chain failures whenthe source articles are detailed enough for consensus among manual analysts,but cannot yet replace human analysts. Future work can improve LLM performancein this context, and study a broader range of articles and failures.", "output": "An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Differential equation discovery, a machine learning subfield, is used todevelop interpretable models, particularly in nature-related applications. Byexpertly incorporating the general parametric form of the equation of motionand appropriate differential terms, algorithms can autonomously uncoverequations from data. This paper explores the prerequisites and tools forindependent equation discovery without expert input, eliminating the need forequation form assumptions. We focus on addressing the challenge of assessingthe adequacy of discovered equations when the correct equation is unknown, withthe aim of providing insights for reliable equation discovery without priorknowledge of the equation form.", "output": "Towards true discovery of the differential equations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Congestion Control (CC) plays a fundamental role in optimizing traffic inData Center Networks (DCN). Currently, DCNs mainly implement two main CCprotocols: DCTCP and DCQCN. Both protocols -- and their main variants -- arebased on Explicit Congestion Notification (ECN), where intermediate switchesmark packets when they detect congestion. The ECN configuration is thus acrucial aspect on the performance of CC protocols. Nowadays, network expertsset static ECN parameters carefully selected to optimize the average networkperformance. However, today's high-speed DCNs experience quick and abruptchanges that severely change the network state (e.g., dynamic trafficworkloads, incast events, failures). This leads to under-utilization andsub-optimal performance. This paper presents GraphCC, a novel MachineLearning-based framework for in-network CC optimization. Our distributedsolution relies on a novel combination of Multi-agent Reinforcement Learning(MARL) and Graph Neural Networks (GNN), and it is compatible with widelydeployed ECN-based CC protocols. GraphCC deploys distributed agents on switchesthat communicate with their neighbors to cooperate and optimize the global ECNconfiguration. In our evaluation, we test the performance of GraphCC under awide variety of scenarios, focusing on the capability of this solution to adaptto new scenarios unseen during training (e.g., new traffic workloads, failures,upgrades). We compare GraphCC with a state-of-the-art MARL-based solution forECN tuning -- ACC -- and observe that our proposed solution outperforms thestate-of-the-art baseline in all of the evaluation scenarios, showingimprovements up to $20%$ in Flow Completion Time as well as significantreductions in buffer occupancy ($38.0-85.7%$).", "output": "GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Functionally significant coronary artery disease (CAD) is caused by plaquebuildup in the coronary arteries, potentially leading to narrowing of thearterial lumen, i.e. coronary stenosis, that significantly obstructs blood flowto the myocardium. The current reference for establishing the presence of afunctionally significant stenosis is invasive fractional flow reserve (FFR)measurement. To avoid invasive measurements, non-invasive prediction of FFRfrom coronary CT angiography (CCTA) has emerged. For this, machine learningapproaches, characterized by fast inference, are increasingly developed.However, these methods predict a single FFR value per artery i.e. they don'tprovide information about the stenosis location or treatment strategy. Wepropose a deep learning-based method to predict the FFR along the artery fromCCTA scans. This study includes CCTA images of 110 patients who underwentinvasive FFR pullback measurement in 112 arteries. First, a multi planarreconstruction (MPR) of the artery is fed to a variational autoencoder tocharacterize the artery, i.e. through the lumen area and unsupervised arteryencodings. Thereafter, a convolutional neural network (CNN) predicts the FFRalong the artery. The CNN is supervised by multiple loss functions, notably aloss function inspired by the Earth Mover's Distance (EMD) to predict thecorrect location of FFR drops and a histogram-based loss to explicitlysupervise the slope of the FFR curve. To train and evaluate our model,eight-fold cross-validation was performed. The resulting FFR curves show goodagreement with the reference allowing the distinction between diffuse and focalCAD distributions in most cases. Quantitative evaluation yielded a meanabsolute difference in the area under the FFR pullback curve (AUPC) of 1.7. Themethod may pave the way towards fast, accurate, automatic prediction of FFRalong the artery from CCTA.", "output": "Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose JEDI, a multi-dataset semi-supervised learning method, whichefficiently combines knowledge from multiple experts, learned on differentdatasets, to train and improve the performance of individual, per dataset,student models. Our approach achieves this by addressing two important problemsin current machine learning research: generalization across datasets andlimitations of supervised training due to scarcity of labeled data. We startwith an arbitrary number of experts, pretrained on their own specific dataset,which form the initial set of student models. The teachers are immediatelyderived by concatenating the feature representations from the penultimatelayers of the students. We then train all models in a student-teachersemi-supervised learning scenario until convergence. In our efficient approach,student-teacher training is carried out jointly and end-to-end, showing thatboth students and teachers improve their generalization capacity duringtraining. We validate our approach on four video action recognition datasets.By simultaneously considering all datasets within a unified semi-supervisedsetting, we demonstrate significant improvements over the initial experts.", "output": "JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Communication is crucial in multi-agent reinforcement learning when agentsare not able to observe the full state of the environment. The most commonapproach to allow learned communication between agents is the use of adifferentiable communication channel that allows gradients to flow betweenagents as a form of feedback. However, this is challenging when we want to usediscrete messages to reduce the message size, since gradients cannot flowthrough a discrete communication channel. Previous work proposed methods todeal with this problem. However, these methods are tested in differentcommunication learning architectures and environments, making it hard tocompare them. In this paper, we compare several state-of-the-art discretizationmethods as well as a novel approach. We do this comparison in the context ofcommunication learning using gradients from other agents and perform tests onseveral environments. In addition, we present COMA-DIAL, a communicationlearning approach based on DIAL and COMA extended with learning rate scalingand adapted exploration. Using COMA-DIAL allows us to perform experiments onmore complex environments. Our results show that the novel ST-DRU method,proposed in this paper, achieves the best results out of all discretizationmethods across the different environments. It achieves the best or close to thebest performance in each of the experiments and is the only method that doesnot fail on any of the tested environments.", "output": "An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph Neural Networks (GNNs) with differential privacy have been proposed topreserve graph privacy when nodes represent personal and sensitive information.However, the existing methods ignore that nodes with different importance mayyield diverse privacy demands, which may lead to over-protect some nodes anddecrease model utility. In this paper, we study the problem ofimportance-grained privacy, where nodes contain personal data that need to bekept private but are critical for training a GNN. We propose NAP-GNN, anode-importance-grained privacy-preserving GNN algorithm with privacyguarantees based on adaptive differential privacy to safeguard nodeinformation. First, we propose a Topology-based Node Importance Estimation(TNIE) method to infer unknown node importance with neighborhood and centralityawareness. Second, an adaptive private aggregation method is proposed toperturb neighborhood aggregation from node-importance-grain. Third, we proposeto privately train a graph learning algorithm on perturbed aggregations inadaptive residual connection mode over multi-layers convolution for node-wisetasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees.Empirical experiments over real-world graph datasets show that NAP-GNN achievesa better trade-off between privacy and accuracy.", "output": "Differentially Private Graph Neural Network with Importance-Grained Noise Adaption."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Predicting stock prices presents a challenging research problem due to theinherent volatility and non-linear nature of the stock market. In recent years,knowledge-enhanced stock price prediction methods have shown groundbreakingresults by utilizing external knowledge to understand the stock market. Despitethe importance of these methods, there is a scarcity of scholarly works thatsystematically synthesize previous studies from the perspective of externalknowledge types. Specifically, the external knowledge can be modeled indifferent data structures, which we group into non-graph-based formats andgraph-based formats: 1) non-graph-based knowledge captures contextualinformation and multimedia descriptions specifically associated with anindividual stock; 2) graph-based knowledge captures interconnected andinterdependent information in the stock market. This survey paper aims toprovide a systematic and comprehensive description of methods for acquiringexternal knowledge from various unstructured data sources and thenincorporating it into stock price prediction models. We also explore fusionmethods for combining external knowledge with historical price features.Moreover, this paper includes a compilation of relevant datasets and delvesinto potential future research directions in this domain.", "output": "Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Fake news is fake material in a news media format but is not processedproperly by news agencies. The fake material can provoke or defame significantentities or individuals or potentially even for the personal interests of thecreators, causing problems for society. Distinguishing fake news and real newsis challenging due to limited of domain knowledge and time constraints.According to the survey, the top three areas most exposed to hoaxes andmisinformation by residents are in Banten, DKI Jakarta and West Java. The modelof transformers is referring to an approach in the field of artificialintelligence (AI) in natural language processing utilizing the deep learningarchitectures. Transformers exercise a powerful attention mechanism to processtext in parallel and produce rich and contextual word representations. Aprevious study indicates a superior performance of a transformer model known asBERT over and above non transformer approach. However, some studies suggest theperformance can be improved with the use of improved BERT models known asALBERT and RoBERTa. However, the modified BERT models are not well explored fordetecting fake news in Bahasa Indonesia. In this research, we explore thosetransformer models and found that ALBERT outperformed other models with 87.6%accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)respectively. Source code available at:", "output": "Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Advanced Air Mobility (AAM) introduces a new, efficient mode oftransportation with the use of vehicle autonomy and electrified aircraft toprovide increasingly autonomous transportation between previously underservedmarkets. Safe and efficient navigation of low altitude aircraft through highlydense environments requires the integration of a multitude of complexobservations, such as surveillance, knowledge of vehicle dynamics, and weather.The processing and reasoning on these observations pose challenges due to thevarious sources of uncertainty in the information while ensuring cooperationwith a variable number of aircraft in the airspace. These challenges coupledwith the requirement to make safety-critical decisions in real-time rule outthe use of conventional separation assurance techniques. We present adecentralized reinforcement learning framework to provide autonomousself-separation capabilities within AAM corridors with the use of speed andvertical maneuvers. The problem is formulated as a Markov Decision Process andsolved by developing a novel extension to the sample-efficient, off-policy softactor-critic (SAC) algorithm. We introduce the use of attention networks forvariable-length observation processing and a distributed computing architectureto achieve high training sample throughput as compared to existing approaches.A comprehensive numerical study shows that the proposed framework can ensuresafe and efficient separation of aircraft in high density, dynamic environmentswith various sources of uncertainty.", "output": "Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Privacy preservation has long been a concern in smart acoustic monitoringsystems, where speech can be passively recorded along with a target signal inthe system's operating environment. In this study, we propose the integrationof two commonly used approaches in privacy preservation: source separation andadversarial representation learning. The proposed system learns the latentrepresentation of audio recordings such that it prevents differentiatingbetween speech and non-speech recordings. Initially, the source separationnetwork filters out some of the privacy-sensitive data, and during theadversarial learning process, the system will learn privacy-preservingrepresentation on the filtered signal. We demonstrate the effectiveness of ourproposed method by comparing our method against systems without sourceseparation, without adversarial learning, and without both. Overall, ourresults suggest that the proposed system can significantly improve speechprivacy preservation compared to that of using source separation or adversariallearning solely while maintaining good performance in the acoustic monitoringtask.", "output": "Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing approaches for information cascade prediction fall into three maincategories: feature-driven methods, point process-based methods, and deeplearning-based methods. Among them, deep learning-based methods, characterizedby its superior learning and representation capabilities, mitigates theshortcomings inherent of the other methods. However, current deep learningmethods still face several persistent challenges. In particular, accuraterepresentation of user attributes remains problematic due to factors such asfake followers and complex network configurations. Previous algorithms thatfocus on the sequential order of user activations often neglect the richinsights offered by activation timing. Furthermore, these techniques often failto holistically integrate temporal and structural aspects, thus missing thenuanced propagation trends inherent in information cascades.To address theseissues, we propose the Cross-Domain Information Fusion Framework (CasCIFF),which is tailored for information cascade prediction. This framework exploitsmulti-hop neighborhood information to make user embeddings robust. Whenembedding cascades, the framework intentionally incorporates timestamps,endowing it with the ability to capture evolving patterns of informationdiffusion. In particular, the CasCIFF seamlessly integrates the tasks of userclassification and cascade prediction into a consolidated framework, therebyallowing the extraction of common features that prove useful for all tasks, astrategy anchored in the principles of multi-task learning.", "output": "CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "ModSecurity is widely recognized as the standard open-source Web ApplicationFirewall (WAF), maintained by the OWASP Foundation. It detects maliciousrequests by matching them against the Core Rule Set, identifying well-knownattack patterns. Each rule in the CRS is manually assigned a weight, based onthe severity of the corresponding attack, and a request is detected asmalicious if the sum of the weights of the firing rules exceeds a giventhreshold. In this work, we show that this simple strategy is largelyineffective for detecting SQL injection (SQLi) attacks, as it tends to blockmany legitimate requests, while also being vulnerable to adversarial SQLiattacks, i.e., attacks intentionally manipulated to evade detection. Toovercome these issues, we design a robust machine learning model, namedAdvModSec, which uses the CRS rules as input features, and it is trained todetect adversarial SQLi attacks. Our experiments show that AdvModSec, beingtrained on the traffic directed towards the protected web services, achieves abetter trade-off between detection and false positive rates, improving thedetection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover,our approach is able to improve its adversarial robustness against adversarialSQLi attacks by 42%, thereby taking a step forward towards building more robustand trustworthy WAFs.", "output": "Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Passive acoustic monitoring offers a scalable, non-invasive method fortracking global biodiversity and anthropogenic impacts on species. Althoughdeep learning has become a vital tool for processing this data, current modelsare inflexible, typically cover only a handful of species, and are limited bydata scarcity. In this work, we propose BioLingual, a new model forbioacoustics based on contrastive language-audio pretraining. We firstaggregate bioacoustic archives into a language-audio dataset, calledAnimalSpeak, with over a million audio-caption pairs holding information onspecies, vocalization context, and animal behavior. After training on thisdataset to connect language and audio representations, our model can identifyover a thousand species' calls across taxa, complete bioacoustic taskszero-shot, and retrieve animal vocalization recordings from natural textqueries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasksin the Benchmark of Animal Sounds. Given its broad taxa coverage and ability tobe flexibly queried in human language, we believe this model opens newparadigms in ecological monitoring and research, including free-text search onthe world's acoustic monitoring archives. We open-source our models, dataset,and code.", "output": "Transferable Models for Bioacoustics with Human Language Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the increasing volume of astronomical data generated by modern surveytelescopes, automated pipelines and machine learning techniques have becomecrucial for analyzing and extracting knowledge from these datasets. Anomalydetection, i.e. the task of identifying irregular or unexpected patterns in thedata, is a complex challenge in astronomy. In this paper, we proposeMulti-Class Deep Support Vector Data Description (MCDSVDD), an extension of thestate-of-the-art anomaly detection algorithm One-Class Deep SVDD, specificallydesigned to handle different inlier categories with distinct datadistributions. MCDSVDD uses a neural network to map the data into hyperspheres,where each hypersphere represents a specific inlier category. The distance ofeach sample from the centers of these hyperspheres determines the anomalyscore. We evaluate the effectiveness of MCDSVDD by comparing its performancewith several anomaly detection algorithms on a large dataset of astronomicallight-curves obtained from the Zwicky Transient Facility. Our resultsdemonstrate the efficacy of MCDSVDD in detecting anomalous sources whileleveraging the presence of different inlier categories. The code and the dataneeded to reproduce our results are publicly available at", "output": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Federated learning (FL), as a decentralized machine learning solution to theprotection of users' private data, has become an important learning paradigm inrecent years, especially since the enforcement of stricter laws and regulationsin most countries. Therefore, a variety of FL frameworks are released tofacilitate the development and application of federated learning. Despite theconsiderable amount of research on the security and privacy of FL models andsystems, the security issues in FL frameworks have not been systematicallystudied yet. In this paper, we conduct the first empirical study on 1,112 FLframework bugs to investigate their characteristics. These bugs are manuallycollected, classified, and labeled from 12 open-source FL frameworks on GitHub.In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fixpatterns of these bugs and investigate their correlations and distributions on23 logical components and two main application scenarios. From the results ofour study, we present nine findings, discuss their implications, and propoundseveral suggestions to FL framework developers and security researchers on theFL frameworks.", "output": "An Empirical Study of Bugs in Open-Source Federated Learning Framework."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeledset by leveraging prior knowledge from a labeled set with known classes.Despite its importance, there is a lack of theoretical foundations for NCD.This paper bridges the gap by providing an analytical framework to formalizeand investigate when and how known classes can help discover novel classes.Tailored to the NCD problem, we introduce a graph-theoretic representation thatcan be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing thisobjective is equivalent to factorizing the graph's adjacency matrix, whichallows us to derive a provable error bound and provide the sufficient andnecessary condition for NCD. Empirically, NSCL can match or outperform severalstrong baselines on common benchmark datasets, which is appealing for practicalusage while enjoying theoretical guarantees.", "output": "When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While diffusion models have achieved promising performances in datasynthesis, they might suffer error propagation because of their cascadestructure, where the distributional mismatch spreads and magnifies through thechain of denoising modules. However, a strict analysis is expected since manysequential models such as Conditional Random Field (CRF) are free from errorpropagation. In this paper, we empirically and theoretically verify thatdiffusion models are indeed affected by error propagation and we then propose aregularization to address this problem. Our theoretical analysis reveals thatthe question can be reduced to whether every denoising module of the diffusionmodel is fault-tolerant. We derive insightful transition equations, indicatingthat the module can't recover from input errors and even propagates additionalerrors to the next module. Our analysis directly leads to a consistencyregularization scheme for diffusion models, which explicitly reduces thedistribution gap between forward and backward processes. We further introduce abootstrapping algorithm to reduce the computation cost of the regularizer. Ourexperimental results on multiple image datasets show that our regularizationeffectively handles error propagation and significantly improves theperformance of vanilla diffusion models.", "output": "Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce AbDiffuser, an equivariant and physics-informed diffusion modelfor the joint generation of antibody 3D structures and sequences. AbDiffuser isbuilt on top of a new representation of protein structure, relies on a novelarchitecture for aligned proteins, and utilizes strong diffusion priors toimprove the denoising process. Our approach improves protein diffusion bytaking advantage of domain knowledge and physics-based constraints; handlessequence-length changes; and reduces memory complexity by an order of magnitudeenabling backbone and side chain generation. We validate AbDiffuser in silicoand in vitro. Numerical experiments showcase the ability of AbDiffuser togenerate antibodies that closely track the sequence and structural propertiesof a reference set. Laboratory experiments confirm that all 16 HER2 antibodiesdiscovered were expressed at high levels and that 57.1% of selected designswere tight binders.", "output": "AbDiffuser: Full-Atom Generation of In-Vitro Functioning Antibodies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One of the important bottlenecks in training modern object detectors is theneed for labeled images where bounding box annotations have to be produced foreach object present in the image. This bottleneck is further exacerbated inaerial images where the annotators have to label small objects oftendistributed in clusters on high-resolution images. In recent days, themean-teacher approach trained with pseudo-labels and weak-strong augmentationconsistency is gaining popularity for semi-supervised object detection.However, a direct adaptation of such semi-supervised detectors for aerialimages where small clustered objects are often present, might not lead tooptimal results. In this paper, we propose a density crop-guidedsemi-supervised detector that identifies the cluster of small objects duringtraining and also exploits them to improve performance at inference. Duringtraining, image crops of clusters identified from labeled and unlabeled imagesare used to augment the training set, which in turn increases the chance ofdetecting small objects and creating good pseudo-labels for small objects onthe unlabeled images. During inference, the detector is not only able to detectthe objects of interest but also regions with a high density of small objects(density crops) so that detections from the input image and detections fromimage crops are combined, resulting in an overall more accurate objectprediction, especially for small objects. Empirical studies on the popularbenchmarks of VisDrone and DOTA datasets show the effectiveness of our densitycrop-guided semi-supervised detector with an average improvement of more than2% over the basic mean-teacher method in COCO style AP. Our code is availableat: ", "output": "Density Crop-guided Semi-supervised Object Detection in Aerial Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Provenance graphs are structured audit logs that describe the history of asystem's execution. Recent studies have explored a variety of techniques toanalyze provenance graphs for automated host intrusion detection, focusingparticularly on advanced persistent threats. Sifting through their designdocuments, we identify four common dimensions that drive the development ofprovenance-based intrusion detection systems (PIDSes): scope (can PIDSes detectmodern attacks that infiltrate across application boundaries?), attackagnosticity (can PIDSes detect novel attacks without a priori knowledge ofattack characteristics?), timeliness (can PIDSes efficiently monitor hostsystems as they run?), and attack reconstruction (can PIDSes distill attackactivity from large provenance graphs so that sysadmins can easily understandand quickly respond to system intrusion?). We present KAIROS, the first PIDSthat simultaneously satisfies the desiderata in all four dimensions, whereasexisting approaches sacrifice at least one and struggle to achieve comparabledetection performance.Kairos leverages a novel graph neural network-based encoder-decoderarchitecture that learns the temporal evolution of a provenance graph'sstructural changes to quantify the degree of anomalousness for each systemevent. Then, based on this fine-grained information, Kairos reconstructs attackfootprints, generating compact summary graphs that accurately describemalicious activity over a stream of system audit logs. Using state-of-the-artbenchmark datasets, we demonstrate that Kairos outperforms previous approaches.", "output": "Kairos: : Practical Intrusion Detection and Investigation using Whole-system Provenance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we propose a data-driven framework for collaborative widebandspectrum sensing and scheduling for networked unmanned aerial vehicles (UAVs),which act as the secondary users to opportunistically utilize detected spectrumholes. To this end, we propose a multi-class classification problem forwideband spectrum sensing to detect vacant spectrum spots based on collectedI/Q samples. To enhance the accuracy of the spectrum sensing module, theoutputs from the multi-class classification by each individual UAV are fused ata server in the unmanned aircraft system traffic management (UTM) ecosystem. Inthe spectrum scheduling phase, we leverage reinforcement learning (RL)solutions to dynamically allocate the detected spectrum holes to the secondaryusers (i.e., UAVs). To evaluate the proposed methods, we establish acomprehensive simulation framework that generates a near-realistic syntheticdataset using MATLAB LTE toolbox by incorporating base-station~(BS) locationsin a chosen area of interest, performing ray-tracing, and emulating the primaryusers channel usage in terms of I/Q samples. This evaluation methodologyprovides a flexible framework to generate large spectrum datasets that could beused for developing ML/AI-based spectrum management solutions for aerialdevices.", "output": "Collaborative Wideband Spectrum Sensing and Scheduling for Networked UAVs in UTM Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present RadGraph2, a novel dataset for extracting information fromradiology reports that focuses on capturing changes in disease state and deviceplacement over time. We introduce a hierarchical schema that organizes entitiesbased on their relationships and show that using this hierarchy during trainingimproves the performance of an information extraction model. Specifically, wepropose a modification to the DyGIE++ framework, resulting in our model HGIE,which outperforms previous models in entity and relation extraction tasks. Wedemonstrate that RadGraph2 enables models to capture a wider variety offindings and perform better at relation extraction compared to those trained onthe original RadGraph dataset. Our work provides the foundation for developingautomated systems that can track disease progression over time and developinformation extraction models that leverage the natural hierarchy of labels inthe medical domain.", "output": "RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning has revolutionized industries like computer vision, naturallanguage processing, and speech recognition. However, back propagation, themain method for training deep neural networks, faces challenges likecomputational overhead and vanishing gradients. In this paper, we propose anovel instant parameter update methodology that eliminates the need forcomputing gradients at each layer. Our approach accelerates learning, avoidsthe vanishing gradient problem, and outperforms state-of-the-art methods onbenchmark data sets. This research presents a promising direction for efficientand effective deep neural network training.", "output": "A Novel Method for improving accuracy in neural network by reinstating traditional back propagation technique."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In the growing domain of scientific machine learning, in-context operatorlearning has demonstrated notable potential in learning operators from prompteddata during inference stage without weight updates. However, the currentmodel's overdependence on sensor data, may inadvertently overlook theinvaluable human insight into the operator. To address this, we present atransformation of in-context operator learning into a multi-modal paradigm. Wepropose the use of \"captions\" to integrate human knowledge about the operator,expressed through natural language descriptions and equations. We illustratehow this method not only broadens the flexibility and generality ofphysics-informed learning, but also significantly boosts learning performanceand reduces data needs. Furthermore, we introduce a more efficient neuralnetwork architecture for multi-modal in-context operator learning, referred toas \"ICON-LM\", based on a language-model-like architecture. We demonstrate theviability of \"ICON-LM\" for scientific machine learning tasks, which creates anew path for the application of language models.", "output": "Prompting In-Context Operator Learning with Sensor Data, Equations, and Natural Language."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Offline Reinforcement learning is commonly used for sequentialdecision-making in domains such as healthcare and education, where the rewardsare known and the transition dynamics $T$ must be estimated on the basis ofbatch data. A key challenge for all tasks is how to learn a reliable estimateof the transition dynamics $T$ that produce near-optimal policies that are safeenough so that they never take actions that are far away from the best actionwith respect to their value functions and informative enough so that theycommunicate the uncertainties they have. Using data from an expert, we proposea new constraint-based approach that captures our desiderata for reliablylearning a posterior distribution of the transition dynamics $T$ that is freefrom gradients. Our results demonstrate that by using our constraints, we learna high-performing policy, while considerably reducing the policy's varianceover different datasets. We also explain how combining uncertainty estimationwith these constraints can help us infer a partial ranking of actions thatproduce higher returns, and helps us infer safer and more informative policiesfor planning.", "output": "Bayesian Inverse Transition Learning for Offline Settings."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The purpose of the research is to determine if currently availableself-supervised learning techniques can accomplish human level comprehension ofvisual images using the same degree and amount of sensory input that peopleacquire from. Initial research on this topic solely considered data volumescaling. Here, we scale both the volume of data and the quality of the image.This scaling experiment is a self-supervised learning method that may be donewithout any outside financing. We find that scaling up data volume and pictureresolution at the same time enables human-level item detection performance atsub-human sizes.We run a scaling experiment with vision transformers trained onup to 200000 images up to 256 ppi.", "output": "A degree of image identification at sub-human scales could be possible with more advanced clusters."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The enormous demand for annotated data brought forth by deep learningtechniques has been accompanied by the problem of annotation noise. Althoughthis issue has been widely discussed in machine learning literature, it hasbeen relatively unexplored in the context of \"multi-label classification\" (MLC)tasks which feature more complicated kinds of noise. Additionally, when thedomain in question has certain logical constraints, noisy annotations oftenexacerbate their violations, making such a system unacceptable to an expert.This paper studies the effect of label noise on domain rule violation incidentsin the MLC task, and incorporates domain rules into our learning algorithm tomitigate the effect of noise. We propose the Domain Obedient Self-supervisedTraining (DOST) paradigm which not only makes deep learning models more alignedto domain rules, but also improves learning performance in key metrics andminimizes the effect of annotation noise. This novel approach uses domainguidance to detect offending annotations and deter rule-violating predictionsin a self-supervised manner, thus making it more \"data efficient\" and domaincompliant. Empirical studies, performed over two large scale multi-labelclassification datasets, demonstrate that our method results in improvementacross the board, and often entirely counteracts the effect of noise.", "output": "DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diffusion MRI is commonly performed using echo-planar imaging (EPI) due toits rapid acquisition time. However, the resolution of diffusion-weightedimages is often limited by magnetic field inhomogeneity-related artifacts andblurring induced by T2- and T2*-relaxation effects. To address theselimitations, multi-shot EPI (msEPI) combined with parallel imaging techniquesis frequently employed. Nevertheless, reconstructing msEPI can be challengingdue to phase variation between multiple shots. In this study, we introduce anovel msEPI reconstruction approach called zero-MIRID (zero-shotself-supervised learning of Multi-shot Image Reconstruction for ImprovedDiffusion MRI). This method jointly reconstructs msEPI data by incorporatingdeep learning-based image regularization techniques. The network incorporatesCNN denoisers in both k- and image-spaces, while leveraging virtual coils toenhance image reconstruction conditioning. By employing a self-supervisedlearning technique and dividing sampled data into three groups, the proposedapproach achieves superior results compared to the state-of-the-art parallelimaging method, as demonstrated in an in-vivo experiment.", "output": "Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot Self-Supervised Learning Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, tensor data (or multidimensional array) have been generated in manymodern applications, such as functional magnetic resonance imaging (fMRI) inneuroscience and videos in video analysis. Many efforts are made in recentyears to predict the relationship between tensor features and univariateresponses. However, previously proposed methods either lose structuralinformation within tensor data or have prohibitively expensive time costs,especially for large-scale data with high-order structures. To address suchproblems, we propose the Sparse and Low-rank Tensor Regression (SLTR) model.Our model enforces sparsity and low-rankness of the tensor coefficient bydirectly applying $ell_1$ norm and tensor nuclear norm, such that it preservesstructural information of the tensor. To make the solving procedure scalableand efficient, SLTR makes use of the proximal gradient method, which can beeasily implemented parallelly. We evaluate SLTR on several simulated datasetsand one video action recognition dataset. Experiment results show that,compared with previous models, SLTR can obtain a better solution with muchfewer time costs. Moreover, our model's predictions exhibit meaningfulinterpretations on the video dataset.", "output": "Sparse and Low-Rank High-Order Tensor Regression via Parallel Proximal Method."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Model-based reinforcement learning (RL), which finds an optimal policy usingan empirical model, has long been recognized as one of the corner stones of RL.It is especially suitable for multi-agent RL (MARL), as it naturally decouplesthe learning and the planning phases, and avoids the non-stationarity problemwhen all agents are improving their policies simultaneously using samples.Though intuitive and widely-used, the sample complexity of model-based MARLalgorithms has not been fully investigated. In this paper, our goal is toaddress the fundamental question about its sample complexity. We study arguablythe most basic MARL setting: two-player discounted zero-sum Markov games, givenonly access to a generative model. We show that model-based MARL achieves asample complexity of $tilde O(|S||A||B|(1-gamma)^{-3}epsilon^{-2})$ forfinding the Nash equilibrium (NE) value up to some $epsilon$ error, and the$epsilon$-NE policies with a smooth planning oracle, where $gamma$ is thediscount factor, and $S,A,B$ denote the state space, and the action spaces forthe two agents. We further show that such a sample bound is minimax-optimal (upto logarithmic factors) if the algorithm is reward-agnostic, where thealgorithm queries state transition samples without reward knowledge, byestablishing a matching lower bound. This is in contrast to the usualreward-aware setting, with a$tildeOmega(|S|(|A|+|B|)(1-gamma)^{-3}epsilon^{-2})$ lower bound, wherethis model-based approach is near-optimal with only a gap on the $|A|,|B|$dependence. Our results not only demonstrate the sample-efficiency of thisbasic model-based approach in MARL, but also elaborate on the fundamentaltradeoff between its power (easily handling the more challengingreward-agnostic case) and limitation (less adaptive and suboptimal in$|A|,|B|$), particularly arises in the multi-agent context.", "output": "Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The application of Transformer neural networks to Electronic Health Records(EHR) is challenging due to the distinct, multidimensional sequential structureof EHR data, often leading to underperformance when compared to simpler linearmodels. Thus, the advantages of Transformers, such as efficient transferlearning and improved scalability are not fully exploited in EHR applications.To overcome these challenges, we introduce SANSformer, a novel attention-freesequential model designed specifically with inductive biases to cater for theunique characteristics of EHR data.Our main application area is predicting future healthcare utilization, acrucial task for effectively allocating healthcare resources. This task becomesparticularly difficult when dealing with divergent patient subgroups. Thesesubgroups, characterized by unique health trajectories and often small in size,such as patients with rare diseases, require specialized modeling approaches.To address this, we adopt a self-supervised pretraining strategy, which we termGenerative Summary Pretraining (GSP). GSP predicts summary statistics of afuture window in the patient's history based on their past health records, thusdemonstrating potential to deal with the noisy and complex nature of EHR data.We pretrain our models on a comprehensive health registry encompassing close toone million patients, before fine-tuning them for specific subgroup predictiontasks.In our evaluations, SANSformer consistently outshines strong EHR baselines.Importantly, our GSP pretraining method greatly enhances model performance,especially for smaller patient subgroups. Our findings underscore thesubstantial potential of bespoke attention-free models and self-supervisedpretraining for enhancing healthcare utilization predictions across a broadrange of patient groups.", "output": "SANSformers: Self-Supervised Forecasting in Electronic Health Records with Attention-Free Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Model-based reinforcement learning is a promising learning strategy forpractical robotic applications due to its improved data-efficiency versusmodel-free counterparts. However, current state-of-the-art model-based methodsrely on shaped reward signals, which can be difficult to design and implement.To remedy this, we propose a simple model-based method tailored forsparse-reward multi-goal tasks that foregoes the need for complicated rewardengineering. This approach, termed Imaginary Hindsight Experience Replay,minimises real-world interactions by incorporating imaginary data into policyupdates. To improve exploration in the sparse-reward setting, the policy istrained with standard Hindsight Experience Replay and endowed withcuriosity-based intrinsic rewards. Upon evaluation, this approach provides anorder of magnitude increase in data-efficiency on average versus thestate-of-the-art model-free method in the benchmark OpenAI Gym Fetch Roboticstasks.", "output": "Imaginary Hindsight Experience Replay: Curious Model-based Learning for Sparse Reward Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we propose a parameter identification methodology of the SIRDmodel, an extension of the classical SIR model, that considers the deceased asa separate category. In addition, our model includes one parameter which is theratio between the real total number of infected and the number of infected thatwere documented in the official statistics.Due to many factors, like governmental decisions, several variantscirculating, opening and closing of schools, the typical assumption that theparameters of the model stay constant for long periods of time is notrealistic. Thus our objective is to create a method which works for shortperiods of time. In this scope, we approach the estimation relying on theprevious 7 days of data and then use the identified parameters to makepredictions.To perform the estimation of the parameters we propose the average of anensemble of neural networks. Each neural network is constructed based on adatabase built by solving the SIRD for 7 days, with random parameters. In thisway, the networks learn the parameters from the solution of the SIRD model.Lastly we use the ensemble to get estimates of the parameters from the realdata of Covid19 in Romania and then we illustrate the predictions for differentperiods of time, from 10 up to 45 days, for the number of deaths. The main goalwas to apply this approach on the analysis of COVID-19 evolution in Romania,but this was also exemplified on other countries like Hungary, Czech Republicand Poland with similar results.The results are backed by a theorem which guarantees that we can recover theparameters of the model from the reported data. We believe this methodology canbe used as a general tool for dealing with short term predictions of infectiousdiseases or in other compartmental models.", "output": "Inverse problem for parameters identification in a modified SIRD epidemic model using ensemble neural networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning methods have shown outstanding classification accuracy inmedical imaging problems, which is largely attributed to the availability oflarge-scale datasets manually annotated with clean labels. However, given thehigh cost of such manual annotation, new medical imaging classificationproblems may need to rely on machine-generated noisy labels extracted fromradiology reports. Indeed, many Chest X-ray (CXR) classifiers have already beenmodelled from datasets with noisy labels, but their training procedure is ingeneral not robust to noisy-label samples, leading to sub-optimal models.Furthermore, CXR datasets are mostly multi-label, so current noisy-labellearning methods designed for multi-class problems cannot be easily adapted. Inthis paper, we propose a new method designed for the noisy multi-label CXRlearning, which detects and smoothly re-labels samples from the dataset, whichis then used to train common multi-label classifiers. The proposed methodoptimises a bag of multi-label descriptors (BoMD) to promote their similaritywith the semantic descriptors produced by BERT models from the multi-labelimage annotation. Our experiments on diverse noisy multi-label training setsand clean testing sets show that our model has state-of-the-art accuracy androbustness in many CXR multi-label classification benchmarks.", "output": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph Representation Learning (GRL) has become central for characterizingstructures of complex networks and performing tasks such as link prediction,node classification, network reconstruction, and community detection. Whereasnumerous generative GRL models have been proposed, many approaches haveprohibitive computational requirements hampering large-scale network analysis,fewer are able to explicitly account for structure emerging at multiple scales,and only a few explicitly respect important network properties such ashomophily and transitivity. This paper proposes a novel scalable graphrepresentation learning method named the Hierarchical Block Distance Model(HBDM). The HBDM imposes a multiscale block structure akin to stochastic blockmodeling (SBM) and accounts for homophily and transitivity by accuratelyapproximating the latent distance model (LDM) throughout the inferredhierarchy. The HBDM naturally accommodates unipartite, directed, and bipartitenetworks whereas the hierarchy is designed to ensure linearithmic time andspace complexity enabling the analysis of very large-scale networks. Weevaluate the performance of the HBDM on massive networks consisting of millionsof nodes. Importantly, we find that the proposed HBDM framework significantlyoutperforms recent scalable approaches in all considered downstream tasks.Surprisingly, we observe superior performance even imposing ultra-lowtwo-dimensional embeddings facilitating accurate direct and hierarchical-awarenetwork visualization and interpretation.", "output": "A Hierarchical Block Distance Model for Ultra Low-Dimensional Graph Representations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generative models have emerged as an essential building block for many imagesynthesis and editing tasks. Recent advances in this field have also enabledhigh-quality 3D or video content to be generated that exhibits eithermulti-view or temporal consistency. With our work, we explore 4D generativeadversarial networks (GANs) that learn unconditional generation of 3D-awarevideos. By combining neural implicit representations with time-awarediscriminator, we develop a GAN framework that synthesizes 3D video supervisedonly with monocular videos. We show that our method learns a rich embedding ofdecomposable 3D structures and motions that enables new visual effects ofspatio-temporal renderings while producing imagery with quality comparable tothat of existing 3D or video GANs.", "output": "3D-Aware Video Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a novel form of Fourier analysis, and associated signal processingconcepts, for signals (or data) indexed by edge-weighted directed acyclicgraphs (DAGs). This means that our Fourier basis yields an eigendecompositionof a suitable notion of shift and convolution operators that we define. DAGsare the common model to capture causal relationships between data values and inthis case our proposed Fourier analysis relates data with its causes under alinearity assumption that we define. The definition of the Fourier transformrequires the transitive closure of the weighted DAG for which several forms arepossible depending on the interpretation of the edge weights. Examples includelevel of influence, distance, or pollution distribution. Our framework isdifferent from prior GSP: it is specific to DAGs and leverages, and extends,the classical theory of Moebius inversion from combinatorics. For aprototypical application we consider DAGs modeling dynamic networks in whichedges change over time. Specifically, we model the spread of an infection onsuch a DAG obtained from real-world contact tracing data and learn theinfection signal from samples assuming sparsity in the Fourier domain.", "output": "Causal Fourier Analysis on Directed Acyclic Graphs and Posets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks have revolutionized the field of machine learning withincreased predictive capability. In addition to improving the predictions ofneural networks, there is a simultaneous demand for reliable uncertaintyquantification on estimates made by machine learning methods such as neuralnetworks. Bayesian neural networks (BNNs) are an important type of neuralnetwork with built-in capability for quantifying uncertainty. This paperdiscusses aleatoric and epistemic uncertainty in BNNs and how they can becalculated. With an example dataset of images where the goal is to identify theamplitude of an event in the image, it is shown that epistemic uncertaintytends to be lower in images which are well-represented in the training datasetand tends to be high in images which are not well-represented. An algorithm forout-of-distribution (OoD) detection with BNN epistemic uncertainty isintroduced along with various experiments demonstrating factors influencing theOoD detection capability in a BNN. The OoD detection capability with epistemicuncertainty is shown to be comparable to the OoD detection in the discriminatornetwork of a generative adversarial network (GAN) with comparable networkarchitecture.", "output": "An out-of-distribution discriminator based on Bayesian neural network epistemic uncertainty."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a unified and compact scene representation for robotics, whereeach object in the scene is depicted by a latent code capturing geometry andappearance. This representation can be decoded for various tasks such as novelview rendering, 3D reconstruction (e.g. recovering depth, point clouds, orvoxel maps), collision checking, and stable grasp prediction. We build ourrepresentation from a single RGB input image at test time by leveraging recentadvances in Neural Radiance Fields (NeRF) that learn category-level priors onlarge multiview datasets, then fine-tune on novel objects from one or fewviews. We expand the NeRF model for additional grasp outputs and explore waysto leverage this representation for robotics. At test-time, we build therepresentation from a single RGB input image observing the scene from only oneviewpoint. We find that the recovered representation allows rendering fromnovel views, including of occluded object parts, and also for predictingsuccessful stable grasps. Grasp poses can be directly decoded from our latentrepresentation with an implicit grasp decoder. We experimented in bothsimulation and real world and demonstrated the capability for robust roboticgrasping using such compact representation. Website:", "output": "One-Shot Neural Fields for 3D Object Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While text-to-image synthesis currently enjoys great popularity amongresearchers and the general public, the security of these models has beenneglected so far. Many text-guided image generation models rely on pre-trainedtext encoders from external sources, and their users trust that the retrievedmodels will behave as promised. Unfortunately, this might not be the case. Weintroduce backdoor attacks against text-guided generative models anddemonstrate that their text encoders pose a major tampering risk. Our attacksonly slightly alter an encoder so that no suspicious model behavior is apparentfor image generations with clean prompts. By then inserting a single charactertrigger into the prompt, e.g., a non-Latin character or emoji, the adversarycan trigger the model to either generate images with pre-defined attributes orimages following a hidden, potentially malicious description. We empiricallydemonstrate the high effectiveness of our attacks on Stable Diffusion andhighlight that the injection process of a single backdoor takes less than twominutes. Besides phrasing our approach solely as an attack, it can also forcean encoder to forget phrases related to certain concepts, such as nudity orviolence, and help to make image generation safer.", "output": "Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In autonomous driving systems, LiDAR and radar play important roles in theperception of the surrounding environment. LiDAR provides accurate 3D spatialsensing information but cannot work in adverse weather like fog. On the otherhand, the radar signal can be diffracted when encountering raindrops or mistparticles thanks to its wavelength, but it suffers from large noise. Recentstate-of-the-art works reveal that fusion of radar and LiDAR can lead to robustdetection in adverse weather. The existing works adopt convolutional neuralnetwork architecture to extract features from each sensor data stream, thenalign and aggregate the two branch features to predict object detectionresults. However, these methods have low accuracy of bounding box estimationsdue to a simple design of label assignment and fusion strategies. In thispaper, we propose a bird's-eye view fusion learning-based anchor box-freeobject detection system, which fuses the feature derived from the radarrange-azimuth heatmap and the LiDAR point cloud to estimate the possibleobjects. Different label assignment strategies have been designed to facilitatethe consistency between the classification of foreground or background anchorpoints and the corresponding bounding box regressions. In addition, theperformance of the proposed object detector is further enhanced by employing anovel interactive transformer module. The superior performance of the methodsproposed in this paper has been demonstrated using the recently publishedOxford Radar RobotCar dataset. Our system's average precision significantlyoutperforms the best state-of-the-art method by 13.1% and 19.0% at IoU of 0.8under 'Clear+Foggy' training conditions for 'Clear' and 'Foggy' testing,respectively.", "output": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A growing ecosystem of large, open-source foundation models has reduced thelabeled data and technical expertise necessary to apply machine learning tomany new problems. Yet foundation models pose a clear dual-use risk,indiscriminately reducing the costs of building both harmful and beneficialmachine learning systems. Policy tools such as restricted model access andexport controls are the primary methods currently used to mitigate suchdual-use risks. In this work, we review potential safe-release strategies andargue that both policymakers and AI researchers would benefit fromfundamentally new technologies enabling more precise control over thedownstream usage of open-source foundation models. We propose one suchapproach: the task blocking paradigm, in which foundation models are trainedwith an additional mechanism to impede adaptation to harmful tasks withoutsacrificing performance on desirable tasks. We call the resulting modelsself-destructing models, inspired by mechanisms that prevent adversaries fromusing tools for harmful purposes. We present an algorithm for trainingself-destructing models leveraging techniques from meta-learning andadversarial learning, which we call meta-learned adversarial censoring (MLAC).In a small-scale experiment, we show MLAC can largely prevent a BERT-stylemodel from being re-purposed to perform gender identification without harmingthe model's ability to perform profession classification.", "output": "Self-Destructing Models: Increasing the Costs of Harmful Dual Uses of Foundation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Foundation models are redefining how AI systems are built. Practitioners nowfollow a standard procedure to build their machine learning solutions: from apre-trained foundation model, they fine-tune the weights on the target task ofinterest. So, the Internet is swarmed by a handful of foundation modelsfine-tuned on many diverse tasks: these individual fine-tunings exist inisolation without benefiting from each other. In our opinion, this is a missedopportunity, as these specialized models contain rich and diverse features. Inthis paper, we thus propose model ratatouille, a new strategy to recycle themultiple fine-tunings of the same foundation model on diverse auxiliary tasks.Specifically, we repurpose these auxiliary weights as initializations formultiple parallel fine-tunings on the target task; then, we average allfine-tuned weights to obtain the final model. This recycling strategy aims atmaximizing the diversity in weights by leveraging the diversity in auxiliarytasks. Empirically, it improves the state of the art on the reference DomainBedbenchmark for out-of-distribution generalization. Looking forward, this workcontributes to the emerging paradigm of updatable machine learning where, akinto open-source software development, the community collaborates to reliablyupdate machine learning models. Our code is released:", "output": "Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Within the framework of deep learning we demonstrate the emergence of thesingular value decomposition (SVD) of the weight matrix as a tool forinterpretation of neural networks (NN) when combined with the descramblingtransformation--a recently-developed technique for addressing interpretabilityin noisy parameter estimation neural networks cite{amey2021neural}. Byconsidering the averaging effect of the data passed to the descramblingminimization problem, we show that descrambling transformations--in the largedata limit--can be expressed in terms of the SVD of the NN weights and theinput autocorrelation matrix. Using this fact, we show that within the class ofnoisy parameter estimation problems the SVD may be the structure through whichtrained networks encode a signal model. We substantiate our theoreticalfindings with empirical evidence from both linear and non-linear signal models.Our results also illuminate the connections between a mathematical theory ofsemantic development cite{saxe2019mathematical} and neural networkinterpretability.", "output": "Emergence of the SVD as an interpretable factorization in deep learning for inverse problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The past decade has witnessed remarkable advancements in deep learning, owingto the emergence of various architectures, layers, objectives, and optimizationtechniques. These consist of a multitude of variations of attention,normalization, skip connections, transformer, and self-supervised learningmethods, among others. Our goal is to furnish a comprehensive survey ofsignificant recent contributions in these domains to individuals with afundamental grasp of deep learning. Our aspiration is that an integrated andcomprehensive approach of influential recent works will facilitate theformation of new connections between different areas of deep learning. In ourdiscussion, we discuss multiple patterns that summarize the key strategies formany of the successful innovations over the last decade. We also include adiscussion on recent commercially built, closed-source models such as OpenAI'sGPT-4 and Google's PaLM 2.", "output": "A Survey of Deep Learning: From Activations to Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph neural networks (GNNs) have been applied to a large variety ofapplications in materials science and chemistry. Here, we recapitulate thegraph construction for crystalline (periodic) materials and investigate itsimpact on the GNNs model performance. We suggest the asymmetric unit cell as arepresentation to reduce the number of atoms by using all symmetries of thesystem. This substantially reduced the computational cost and thus time neededto train large graph neural networks without any loss in accuracy. Furthermore,with a simple but systematically built GNN architecture based on messagepassing and line graph templates, we introduce a general architecture (NestedGraph Network, NGN) that is applicable to a wide range of tasks. We show thatour suggested models systematically improve state-of-the-art results across alltasks within the MatBench benchmark. Further analysis shows that optimizedconnectivity and deeper message functions are responsible for the improvement.Asymmetric unit cells and connectivity optimization can be generally applied to(crystal) graph networks, while our suggested nested graph framework will opennew ways of systematic comparison of GNN architectures.", "output": "Connectivity Optimized Nested Graph Networks for Crystal Structures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Developing extended hydrodynamics equations valid for both dense and rarefiedgases remains a great challenge. A systematical solution for this challenge isthe moment method describing both dense and rarefied gas behaviors with momentsof gas molecule velocity distributions. Among moment methods, the maximalentropy moment method (MEM) stands out for its well-posedness and stability,which utilizes velocity distributions with maximized entropy. However, findingsuch distributions requires solving an ill-conditioned andcomputation-demanding optimization problem. This problem causes numericaloverflow and breakdown when the numerical precision is insufficient, especiallyfor flows like high-speed shock waves. It also prevents modern GPUs fromaccelerating optimization with their enormous single floating-point precisioncomputation power. This paper aims to stabilize MEM, making it practical forsimulating very strong normal shock waves on modern GPUs at single precision.We propose the gauge transformations for MEM, making the optimization lessill-conditioned. We also tackle numerical overflow and breakdown by adoptingthe canonical form of distribution and Newton's modified optimization method.With these techniques, we achieved a single-precision GPU simulation of a Mach10 shock wave with 35 moments MEM, surpassing the previous double-precisionresults of Mach 4. Moreover, we argued that over-refined spatial mesh degradesboth the accuracy and stability of MEM. Overall, this paper makes the maximalentropy moment method practical for simulating very strong normal shock waveson modern GPUs at single-precision, with significant stability improvementcompared to previous methods.", "output": "Stabilizing the Maximal Entropy Moment Method for Rarefied Gas Dynamics at Single-Precision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large Language Models (LLMs) have sparked significant interest in theirgenerative capabilities, leading to the development of various commercialapplications. The high cost of using the models drives application builders tomaximize the value of generation under a limited inference budget. This paperpresents a study of optimizing inference hyperparameters such as the number ofresponses, temperature and max tokens, which significantly affects theutility/cost of text generation. We design a framework named EcoOptiGen whichleverages economical hyperparameter optimization and cost-based pruning.Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify itseffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAMLlibrary: url{", "output": "Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The warming of the Arctic, also known as Arctic amplification, is led byseveral atmospheric and oceanic drivers. However, the details of its underlyingthermodynamic causes are still unknown. Inferring the causal effects ofatmospheric processes on sea ice melt using fixed treatment effect strategiesleads to unrealistic counterfactual estimations. Such models are also prone tobias due to time-varying confoundedness. Further, the complex non-linearity inEarth science data makes it infeasible to perform causal inference usingexisting marginal structural techniques. In order to tackle these challenges,we propose TCINet - time-series causal inference model to infer causation undercontinuous treatment using recurrent neural networks and a novel probabilisticbalancing technique. Through experiments on synthetic and observational data,we show how our research can substantially improve the ability to quantifyleading causes of Arctic sea ice melt, further paving paths for causalinference in observational Earth science.", "output": "Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The development of language models have moved from encoder-decoder todecoder-only designs. In addition, we observe that the two most popularmultimodal tasks, the generative and contrastive tasks, are nontrivial toaccommodate in one architecture, and further need adaptations for downstreamtasks. We propose a novel paradigm of training with a decoder-only model formultimodal tasks, which is surprisingly effective in jointly learning of thesedisparate vision-language tasks. This is done with a simple model, calledMaMMUT. It consists of a single vision encoder and a text decoder, and is ableto accommodate contrastive and generative learning by a novel two-pass approachon the text decoder. We demonstrate that joint learning of these diverseobjectives is simple, effective, and maximizes the weight-sharing of the modelacross these tasks. Furthermore, the same architecture enables straightforwardextensions to open-vocabulary object detection and video-language tasks. Themodel tackles a diverse range of tasks, while being modest in capacity. Ourmodel achieves the state of the art on image-text and text-image retrieval,video question answering and open-vocabulary detection tasks, outperformingmuch larger and more extensively trained foundational models. It shows verycompetitive results on VQA and Video Captioning, especially considering itscapacity. Ablations confirm the flexibility and advantages of our approach.", "output": "MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine Learning (ML) models are widely employed to drive many modern datasystems. While they are undeniably powerful tools, ML models often demonstrateimbalanced performance and unfair behaviors. The root of this problem oftenlies in the fact that different subpopulations commonly display divergenttrends: as a learning algorithm tries to identify trends in the data, itnaturally favors the trends of the majority groups, leading to a model thatperforms poorly and unfairly for minority populations. Our goal is to improvethe fairness and trustworthiness of ML models by applying only non-invasiveinterventions, i.e., without altering the data or the learning algorithm. Weuse a simple but key insight: the divergence of trends between differentpopulations, and, consecutively, between a learned model and minoritypopulations, is analogous to data drift, which indicates the poor conformancebetween parts of the data and the trained model. We explore two strategies(model-splitting and reweighing) to resolve this drift, aiming to improve theoverall conformance of models to the underlying data. Both our methodsintroduce novel ways to employ the recently-proposed data profiling primitiveof Conformance Constraints. Our experimental evaluation over 7 real-worlddatasets shows that both DifFair and ConFair improve the fairness of ML models.We demonstrate scenarios where DifFair has an edge, though ConFair has thegreatest practical impact and outperforms other baselines. Moreover, as amodel-agnostic technique, ConFair stays robust when used against differentmodels than the ones on which the weights have been learned, which is not thecase for other state of the art.", "output": "Non-Invasive Fairness in Learning through the Lens of Data Drift."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In supervised learning, the regularization path is sometimes used as aconvenient theoretical proxy for the optimization path of gradient descentinitialized from zero. In this paper, we study a modification of theregularization path for infinite-width 2-layer ReLU neural networks withnonzero initial distribution of the weights at different scales. By exploitinga link with unbalanced optimal-transport theory, we show that, despite thenon-convexity of the 2-layer network training, this problem admits aninfinite-dimensional convex counterpart. We formulate the correspondingfunctional-optimization problem and investigate its main properties. Inparticular, we show that, as the scale of the initialization ranges between $0$and $+infty$, the associated path interpolates continuously between theso-called kernel and rich regimes. Numerical experiments confirm that, in oursetting, the scaling path and the final states of the optimization path behavesimilarly, even beyond these extreme points.", "output": "On the Effect of Initialization: The Scaling Path of 2-Layer Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose and release a new vulnerable source code dataset. We curate thedataset by crawling security issue websites, extracting vulnerability-fixingcommits and source codes from the corresponding projects. Our new datasetcontains 18,945 vulnerable functions spanning 150 CWEs and 330,492non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295more projects than all previous datasets combined.Combining our new dataset with previous datasets, we present an analysis ofthe challenges and promising research directions of using deep learning fordetecting software vulnerabilities. We study 11 model architectures belongingto 4 families. Our results show that deep learning is still not ready forvulnerability detection, due to high false positive rate, low F1 score, anddifficulty of detecting hard CWEs. In particular, we demonstrate an importantgeneralization challenge for the deployment of deep learning-based models. Weshow that increasing the volume of training data may not further improve theperformance of deep learning models for vulnerability detection, but might beuseful to improve the generalization ability to unseen projects.We also identify hopeful future research directions. We demonstrate thatlarge language models (LLMs) are a promising research direction for ML-basedvulnerability detection, outperforming Graph Neural Networks (GNNs) withcode-structure features in our experiments. Moreover, developing source codespecific pre-training objectives is a promising research direction to improvethe vulnerability detection performance.", "output": "DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent work has shown that simple linear models can outperform severalTransformer based approaches in long term time-series forecasting. Motivated bythis, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model,Time-series Dense Encoder (TiDE), for long-term time-series forecasting thatenjoys the simplicity and speed of linear models while also being able tohandle covariates and non-linear dependencies. Theoretically, we prove that thesimplest linear analogue of our model can achieve near optimal error rate forlinear dynamical systems (LDS) under some assumptions. Empirically, we showthat our method can match or outperform prior approaches on popular long-termtime-series forecasting benchmarks while being 5-10x faster than the bestTransformer based model.", "output": "Long-term Forecasting with TiDE: Time-series Dense Encoder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement learning is a growing field in AI with a lot of potential.Intelligent behavior is learned automatically through trial and error ininteraction with the environment. However, this learning process is oftencostly. Using variational quantum circuits as function approximatorspotentially can reduce this cost. In order to implement this, we propose thequantum natural policy gradient (QNPG) algorithm -- a second-ordergradient-based routine that takes advantage of an efficient approximation ofthe quantum Fisher information matrix. We experimentally demonstrate that QNPGoutperforms first-order based training on Contextual Bandits environmentsregarding convergence speed and stability and moreover reduces the samplecomplexity. Furthermore, we provide evidence for the practical feasibility ofour approach by training on a 12-qubit hardware device.", "output": "Quantum Natural Policy Gradients: Towards Sample-Efficient Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This work puts forth low-complexity Riemannian subspace descent algorithmsfor the minimization of functions over the symmetric positive definite (SPD)manifold. Different from the existing Riemannian gradient descent variants, theproposed approach utilizes carefully chosen subspaces that allow the update tobe written as a product of the Cholesky factor of the iterate and a sparsematrix. The resulting updates avoid the costly matrix operations like matrixexponentiation and dense matrix multiplication, which are generally required inalmost all other Riemannian optimization algorithms on SPD manifold. We furtheridentify a broad class of functions, arising in diverse applications, such askernel matrix learning, covariance estimation of Gaussian distributions,maximum likelihood parameter estimation of elliptically contoureddistributions, and parameter estimation in Gaussian mixture model problems,over which the Riemannian gradients can be calculated efficiently. The proposeduni-directional and multi-directional Riemannian subspace descent variantsincur per-iteration complexities of $mathcal{O}(n)$ and $mathcal{O}(n^2)$respectively, as compared to the $mathcal{O}(n^3)$ or higher complexityincurred by all existing Riemannian gradient descent variants. The superiorruntime and low per-iteration complexity of the proposed algorithms is alsodemonstrated via numerical tests on large-scale covariance estimation problems.", "output": "Low-complexity subspace-descent over symmetric positive definite manifold."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the increasing number and sophistication of malware attacks, malwaredetection systems based on machine learning (ML) grow in importance. At thesame time, many popular ML models used in malware classification are supervisedsolutions. These supervised classifiers often do not generalize well to novelmalware. Therefore, they need to be re-trained frequently to detect new malwarespecimens, which can be time-consuming. Our work addresses this problem in ahybrid framework of theoretical Quantum ML, combined with feature selectionstrategies to reduce the data size and malware classifier training time. Thepreliminary results show that VQC with XGBoost selected features can get a78.91% test accuracy on the simulator. The average accuracy for the modeltrained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM5 qubits machines.", "output": "Can Feature Engineering Help Quantum Machine Learning for Malware Detection?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer models are revolutionizing machine learning, but their innerworkings remain mysterious. In this work, we present a new visualizationtechnique designed to help researchers understand the self-attention mechanismin transformers that allows these models to learn rich, contextualrelationships between elements of a sequence. The main idea behind our methodis to visualize a joint embedding of the query and key vectors used bytransformer models to compute attention. Unlike previous attentionvisualization techniques, our approach enables the analysis of global patternsacross multiple input sequences. We create an interactive visualization tool,AttentionViz (demo: <a href=\" http URL</a>), based on these joint query-keyembeddings, and use it to study attention mechanisms in both language andvision transformers. We demonstrate the utility of our approach in improvingmodel understanding and offering new insights about query-key interactionsthrough several application scenarios and expert feedback.", "output": "AttentionViz: A Global View of Transformer Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern advances in machine learning (ML) and wearable medical sensors (WMSs)in edge devices have enabled ML-driven disease detection for smart healthcare.Conventional ML-driven disease detection methods rely on customizing individualmodels for each disease and its corresponding WMS data. However, such methodslack adaptability to distribution shifts and new task classification classes.Moreover, they need to be rearchitected and retrained from scratch for each newdisease. To address these challenges, we propose DOCTOR, a multi-diseasedetection continual learning (CL) framework based on WMSs. It employs amulti-headed deep neural network (DNN) and an exemplar-replay-style CLalgorithm. The CL algorithm enables the framework to continually learn newmissions where different data distributions, classification classes, anddisease detection tasks are introduced sequentially. It counteractscatastrophic forgetting with a data preservation method and a synthetic datageneration (SDG) module. The data preservation method efficiently preserves themost informative subset of training data from previous missions for replay. TheSDG module models the probability distribution of the real training data andgenerates synthetic data for replays while retaining data privacy. Themulti-headed DNN enables DOCTOR to detect multiple diseases simultaneouslybased on user WMS data. In various CL experiments, we demonstrate DOCTOR'sefficacy in maintaining high disease classification accuracy with a single DNNmodel. DOCTOR achieves 1.43 times better average test accuracy, 1.25 timesbetter F1-score, and 0.41 higher backward transfer than the naive fine-tuningframework, with a small model size and in complex CL scenarios.", "output": "DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A myriad of algorithms for the automatic analysis of brain MR images isavailable to support clinicians in their decision-making. For brain tumorpatients, the image acquisition time series typically starts with a scan thatis already pathological. This poses problems, as many algorithms are designedto analyze healthy brains and provide no guarantees for images featuringlesions. Examples include but are not limited to algorithms for brain anatomyparcellation, tissue segmentation, and brain extraction. To solve this dilemma,we introduce the BraTS 2023 inpainting challenge. Here, the participants' taskis to explore inpainting techniques to synthesize healthy brain scans fromlesioned ones. The following manuscript contains the task formulation, dataset,and submission procedure. Later it will be updated to summarize the findings ofthe challenge. The challenge is organized as part of the BraTS 2023 challengehosted at the MICCAI 2023 conference in Vancouver, Canada.", "output": "The Brain Tumor Segmentation (BraTS) Challenge 2023: Local Synthesis of Healthy Brain Tissue via Inpainting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodeswithin graphs, finding applications in network security, fraud detection,social media spam detection, and various other domains. A common method for GADis Graph Auto-Encoders (GAEs), which encode graph data into noderepresentations and identify anomalies by assessing the reconstruction qualityof the graphs based on these representations. However, existing GAE models areprimarily optimized for direct link reconstruction, resulting in nodesconnected in the graph being clustered in the latent space. As a result, theyexcel at detecting cluster-type structural anomalies but struggle with morecomplex structural anomalies that do not conform to clusters. To address thislimitation, we propose a novel solution called GAD-NR, a new variant of GAEthat incorporates neighborhood reconstruction for graph anomaly detection.GAD-NR aims to reconstruct the entire neighborhood of a node, encompassing thelocal structure, self-attributes, and neighbor attributes, based on thecorresponding node representation. By comparing the neighborhood reconstructionloss between anomalous nodes and normal nodes, GAD-NR can effectively detectany anomalies. Extensive experimentation conducted on six real-world datasetsvalidates the effectiveness of GAD-NR, showcasing significant improvements (byup to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NRis openly available. Importantly, the comparative analysis reveals that theexisting methods perform well only in detecting one or two types of anomaliesout of the three types studied. In contrast, GAD-NR excels at detecting allthree types of anomalies across the datasets, demonstrating its comprehensiveanomaly detection capabilities.", "output": "GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With read-aloud speech synthesis achieving high naturalness scores, there isa growing research interest in synthesising spontaneous speech. However, humanspontaneous face-to-face conversation has both spoken and non-verbal aspects(here, co-speech gestures). Only recently has research begun to explore thebenefits of jointly synthesising these two modalities in a single system. Theprevious state of the art used non-probabilistic methods, which fail to capturethe variability of human speech and motion, and risk producing oversmoothingartefacts and sub-optimal synthesis quality. We present the firstdiffusion-based probabilistic model, called Diff-TTSG, that jointly learns tosynthesise speech and gestures together. Our method can be trained on smalldatasets from scratch. Furthermore, we describe a set of careful uni- andmulti-modal subjective tests for evaluating integrated speech and gesturesynthesis systems, and use them to validate our proposed approach. Please see for video examples, data, and code.", "output": "Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement learning (RL) for physical design of silicon chips in a Google2021 Nature paper stirred controversy due to poorly documented claims thatraised eyebrows and attracted critical media coverage. The Nature paperwithheld most inputs needed to produce reported results and some critical stepsin the methodology. But two separate evaluations filled in the gaps anddemonstrated that Google RL lags behind human designers, behind a well-knownalgorithm (Simulated Annealing), and also behind generally-available commercialsoftware, while taking longer to run. Crosschecked data show that the integrityof the Nature paper is substantially undermined owing to errors in conduct,analysis and reporting. Before publishing, Google rebuffed internal allegationsof fraud.", "output": "The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "High-dimensional metastable molecular system can often be characterised by afew features of the system, i.e. collective variables (CVs). Thanks to therapid advance in the area of machine learning and deep learning, various deeplearning-based CV identification techniques have been developed in recentyears, allowing accurate modelling and efficient simulation of complexmolecular systems. In this paper, we look at two different categories of deeplearning-based approaches for finding CVs, either by computing leadingeigenfunctions of infinitesimal generator or transfer operator associated tothe underlying dynamics, or by learning an autoencoder via minimisation ofreconstruction error. We present a concise overview of the mathematics behindthese two approaches and conduct a comparative numerical study of these twoapproaches on illustrative examples.", "output": "Understanding recent deep-learning techniques for identifying collective variables of molecular dynamics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This work introduces a novel approach to pruning deep learning models byusing distilled data. Unlike conventional strategies which primarily focus onarchitectural or algorithmic optimization, our method reconsiders the role ofdata in these scenarios. Distilled datasets capture essential patterns fromlarger datasets, and we demonstrate how to leverage this capability to enable acomputationally efficient pruning process. Our approach can find sparse,trainable subnetworks (a.k.a. Lottery Tickets) up to 5x faster than IterativeMagnitude Pruning at comparable sparsity on CIFAR-10. The experimental resultshighlight the potential of using distilled data for resource-efficient neuralnetwork pruning, model compression, and neural architecture search.", "output": "Distilled Pruning: Using Synthetic Data to Win the Lottery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time series are the primary data type used to record dynamic systemmeasurements and generated in great volume by both physical sensors and onlineprocesses (virtual sensors). Time series analytics is therefore crucial tounlocking the wealth of information implicit in available data. With the recentadvancements in graph neural networks (GNNs), there has been a surge inGNN-based approaches for time series analysis. These approaches can explicitlymodel inter-temporal and inter-variable relationships, which traditional andother deep neural network-based methods struggle to do. In this survey, weprovide a comprehensive review of graph neural networks for time seriesanalysis (GNN4TS), encompassing four fundamental dimensions: forecasting,classification, anomaly detection, and imputation. Our aim is to guidedesigners and practitioners to understand, build applications, and advanceresearch of GNN4TS. At first, we provide a comprehensive task-oriented taxonomyof GNN4TS. Then, we present and discuss representative research works andintroduce mainstream applications of GNN4TS. A comprehensive discussion ofpotential future research directions completes the survey. This survey, for thefirst time, brings together a vast array of knowledge on GNN-based time seriesresearch, highlighting foundations, practical applications, and opportunitiesof graph neural networks for time series analysis.", "output": "A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A wide variety of natural language tasks are currently being addressed withlarge-scale language models (LLMs). These models are usually trained with avery large amount of unsupervised text data and adapted to perform a downstreamnatural language task using methods like fine-tuning, calibration or in-contextlearning. In this work, we propose an approach to adapt the prior classdistribution to perform text classification tasks without the need for labelledsamples and only few in-domain sample queries. The proposed approach treats theLLM as a black box, adding a stage where the model posteriors are calibrated tothe task. Results show that these methods outperform the un-adapted model fordifferent number of training shots in the prompt and a previous approach werecalibration is performed without using any adaptation data.", "output": "Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Over the last decade, there has been a vast increase in eating disorderdiagnoses and eating disorder-attributed deaths, reaching their zenith duringthe Covid-19 pandemic. This immense growth derived in part from the stressorsof the pandemic but also from increased exposure to social media, which is rifewith content that promotes eating disorders. This study aimed to create amultimodal deep learning model that can determine if a given social media postpromotes eating disorders based on a combination of visual and textual data. Alabeled dataset of Tweets was collected from Twitter, upon which twelve deeplearning models were trained and tested. Based on model performance, the mosteffective deep learning model was the multimodal fusion of the RoBERTa naturallanguage processing model and the MaxViT image classification model, attainingaccuracy and F1 scores of 95.9% and 0.959, respectively. The RoBERTa and MaxViTfusion model, deployed to classify an unlabeled dataset of posts from thesocial media sites Tumblr and Reddit, generated results akin to those ofprevious research studies that did not employ artificial intelligence-basedtechniques, indicating that deep learning models can develop insights congruentto those of researchers. Additionally, the model was used to conduct atimeseries analysis of yet unseen Tweets from eight Twitter hashtags,uncovering that, since 2014, the relative abundance of content that promoteseating disorders has decreased drastically within those communities. Despitethis reduction, by 2018, content that promotes eating disorders had eitherstopped declining or increased in ampleness anew on these hashtags.", "output": "A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Leveraging network information for predictive modeling has become widespreadin many domains. Within the realm of referral and targeted marketing,influencer detection stands out as an area that could greatly benefit from theincorporation of dynamic network representation due to the ongoing developmentof customer-brand relationships. To elaborate this idea, we introduceINFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic GraphNeural Networks that combines Graph Neural Networks (GNN) and Recurrent NeuralNetworks (RNN) with weighted loss functions, the Synthetic MinorityOversampling TEchnique (SMOTE) adapted for graph data, and a carefully craftedrolling-window strategy. To evaluate predictive performance, we utilize aunique corporate data set with networks of three cities and derive aprofit-driven evaluation methodology for influencer prediction. Our resultsshow how using RNN to encode temporal attributes alongside GNNs significantlyimproves predictive performance. We compare the results of various models todemonstrate the importance of capturing graph representation, temporaldependencies, and using a profit-driven methodology for evaluation.", "output": "INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we propose Retentive Network (RetNet) as a foundationarchitecture for large language models, simultaneously achieving trainingparallelism, low-cost inference, and good performance. We theoretically derivethe connection between recurrence and attention. Then we propose the retentionmechanism for sequence modeling, which supports three computation paradigms,i.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallelrepresentation allows for training parallelism. The recurrent representationenables low-cost $O(1)$ inference, which improves decoding throughput, latency,and GPU memory without sacrificing performance. The chunkwise recurrentrepresentation facilitates efficient long-sequence modeling with linearcomplexity, where each chunk is encoded parallelly while recurrentlysummarizing the chunks. Experimental results on language modeling show thatRetNet achieves favorable scaling results, parallel training, low-costdeployment, and efficient inference. The intriguing properties make RetNet astrong successor to Transformer for large language models. Code will beavailable at ", "output": "Retentive Network: A Successor to Transformer for Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Restricting the variance of a policy's return is a popular choice inrisk-averse Reinforcement Learning (RL) due to its clear mathematicaldefinition and easy interpretability. Traditional methods directly restrict thetotal return variance. Recent methods restrict the per-step reward variance asa proxy. We thoroughly examine the limitations of these variance-based methods,such as sensitivity to numerical scale and hindering of policy learning, andpropose to use an alternative risk measure, Gini deviation, as a substitute. Westudy various properties of this new risk measure and derive a policy gradientalgorithm to minimize it. Empirical evaluation in domains where risk-aversioncan be clearly defined, shows that our algorithm can mitigate the limitationsof variance-based risk measures and achieves high return with low risk in termsof variance and Gini deviation when others fail to learn a reasonable policy.", "output": "An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing action recognition methods are typically actor-specific due to theintrinsic topological and apparent differences among the actors. This requiresactor-specific pose estimation (e.g., humans vs. animals), leading tocumbersome model design complexity and high maintenance costs. Moreover, theyoften focus on learning the visual modality alone and single-labelclassification whilst neglecting other available information sources (e.g.,class name text) and the concurrent occurrence of multiple actions. To overcomethese limitations, we propose a new approach called 'actor-agnostic multi-modalmulti-label action recognition,' which offers a unified solution for varioustypes of actors, including humans and animals. We further formulate a novelMulti-modal Semantic Query Network (MSQNet) model in a transformer-based objectdetection framework (e.g., DETR), characterized by leveraging visual andtextual modalities to represent the action classes better. The elimination ofactor-specific model designs is a key advantage, as it removes the need foractor pose estimation altogether. Extensive experiments on five publiclyavailable benchmarks show that our MSQNet consistently outperforms the priorarts of actor-specific alternatives on human and animal single- and multi-labelaction recognition tasks by up to 50%. Code will be released at", "output": "Actor-agnostic Multi-label Action Recognition with Multi-modal Query."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The curse-of-dimensionality (CoD) taxes computational resources heavily withexponentially increasing computational cost as the dimension increases. Thisposes great challenges in solving high-dimensional PDEs as Richard Bellmanfirst pointed out over 60 years ago. While there has been some recent successin solving numerically partial differential equations (PDEs) in highdimensions, such computations are prohibitively expensive, and true scaling ofgeneral nonlinear PDEs to high dimensions has never been achieved. In thispaper, we develop a new method of scaling up physics-informed neural networks(PINNs) to solve arbitrary high-dimensional PDEs. The new method, calledStochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEsinto pieces corresponding to different dimensions and samples randomly a subsetof these dimensional pieces in each iteration of training PINNs. Wetheoretically prove the convergence guarantee and other desired properties ofthe proposed method. We experimentally demonstrate that the proposed methodallows us to solve many notoriously hard high-dimensional PDEs, including theHamilton-Jacobi-Bellman (HJB) and the Schr\"{o}dinger equations in thousands ofdimensions very fast on a single GPU using the PINNs mesh-free approach. Forinstance, we solve nontrivial nonlinear PDEs (one HJB equation and oneBlack-Scholes equation) in 100,000 dimensions in 6 hours on a single GPU usingSDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGDcan be applied to any current and future variants of PINNs to scale them up forarbitrary high-dimensional PDEs.", "output": "Tackling the Curse of Dimensionality with Physics-Informed Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The exponential run time of quantum simulators on classical machines and longqueue depths and high costs of real quantum devices present significantchallenges in the effective training of Variational Quantum Algorithms (VQAs)like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) andQuantum Approximate Optimization Algorithm (QAOA). To address theselimitations, we propose a new approach, WEPRO (Weight Prediction), whichaccelerates the convergence of VQAs by exploiting regular trends in theparameter weights. We introduce two techniques for optimal predictionperformance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP).Through extensive experimentation and training of multiple QNN models onvarious datasets, we demonstrate that WEPRO offers a speedup of approximately$2.25times$ compared to standard training methods, while also providingimproved accuracy (up to $2.3%$ higher) and loss (up to $6.1%$ lower) withlow storage and computational overheads. We also evaluate WEPRO's effectivenessin VQE for molecular ground-state energy estimation and in QAOA for graphMaxCut. Our results show that WEPRO leads to speed improvements of up to$3.1times$ for VQE and $2.91times$ for QAOA, compared to traditionaloptimization techniques, while using up to $3.3times$ less number of shots(i.e., repeated circuit executions) per training iteration.", "output": "WEPRO: Weight Prediction for Efficient Optimization of Hybrid Quantum-Classical Algorithms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Semi-definite programs represent a frontier of efficient computation. Whilethere has been much progress on semi-definite optimization, with moderate-sizedinstances currently solvable in practice by the interior-point method, thebasic problem of sampling semi-definite solutions remains a formidablechallenge. The direct application of known polynomial-time algorithms forsampling general convex bodies to semi-definite sampling leads to aprohibitively high running time. In addition, known general methods require anexpensive rounding phase as pre-processing. Here we analyze the Dikin walk, byfirst adapting it to general metrics, then devising suitable metrics for thePSD cone with affine constraints. The resulting mixing time and per-stepcomplexity are considerably smaller, and by an appropriate choice of themetric, the dependence on the number of constraints can be madepolylogarithmic. We introduce a refined notion of self-concordant matrixfunctions and give rules for combining different metrics. Along the way, wefurther develop the theory of interior-point methods for sampling.", "output": "Efficiently Sampling the PSD Cone with the Metric Dikin Walk."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Relational tables, where each row corresponds to an entity and each columncorresponds to an attribute, have been the standard for tables in relationaldatabases. However, such a standard cannot be taken for granted when dealingwith tables \"in the wild\". Our survey of real spreadsheet-tables and web-tablesshows that over 30% of such tables do not conform to the relational standard,for which complex table-restructuring transformations are needed before thesetables can be queried easily using SQL-based analytics tools. Unfortunately,the required transformations are non-trivial to program, which has become asubstantial pain point for technical and non-technical users alike, asevidenced by large numbers of forum questions in places like StackOverflow andExcel/Power-BI/Tableau forums.We develop an Auto-Tables system that can automatically synthesize pipelineswith multi-step transformations (in Python or other languages), to transformnon-relational tables into standard relational forms for downstream analytics,obviating the need for users to manually program transformations. We compile anextensive benchmark for this new task, by collecting 244 real test cases fromuser spreadsheets and online forums. Our evaluation suggests that Auto-Tablescan successfully synthesize transformations for over 70% of test cases atinteractive speeds, without requiring any input from users, making this aneffective tool for both technical and non-technical users to prepare data foranalytics.", "output": "Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-agent reinforcement learning (MARL) has achieved promising results inrecent years. However, most existing reinforcement learning methods require alarge amount of data for model training. In addition, data-efficientreinforcement learning requires the construction of strong inductive biases,which are ignored in the current MARL approaches. Inspired by the symmetryphenomenon in multi-agent systems, this paper proposes a framework forexploiting prior knowledge by integrating data augmentation and a well-designedconsistency loss into the existing MARL methods. In addition, the proposedframework is model-agnostic and can be applied to most of the current MARLalgorithms. Experimental tests on multiple challenging tasks demonstrate theeffectiveness of the proposed framework. Moreover, the proposed framework isapplied to a physical multi-robot testbed to show its superiority.", "output": "ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We explore the equivalence between neural networks and kernel methods byderiving the first exact representation of any finite-size parametricclassification model trained with gradient descent as a kernel machine. Wecompare our exact representation to the well-known Neural Tangent Kernel (NTK)and discuss approximation error relative to the NTK and other non-exact pathkernel formulations. We experimentally demonstrate that the kernel can becomputed for realistic networks up to machine precision. We use this exactkernel to show that our theoretical contribution can provide useful insightsinto the predictions made by neural networks, particularly the way in whichthey generalize.", "output": "An Exact Kernel Equivalence for Finite Classification Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time series analysis is a fundamental task in various application domains,and deep learning approaches have demonstrated remarkable performance in thisarea. However, many real-world time series data exhibit significant periodic orquasi-periodic dynamics that are often not adequately captured by existing deeplearning-based solutions. This results in an incomplete representation of theunderlying dynamic behaviors of interest. To address this gap, we propose anunsupervised method called Floss that automatically regularizes learnedrepresentations in the frequency domain. The Floss method first automaticallydetects major periodicities from the time series. It then employs periodicshift and spectral density similarity measures to learn meaningfulrepresentations with periodic consistency. In addition, Floss can be easilyincorporated into both supervised, semi-supervised, and unsupervised learningframeworks. We conduct extensive experiments on common time seriesclassification, forecasting, and anomaly detection tasks to demonstrate theeffectiveness of Floss. We incorporate Floss into several representative deeplearning solutions to justify our design choices and demonstrate that it iscapable of automatically discovering periodic dynamics and improvingstate-of-the-art deep learning models.", "output": "Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human motion prediction (HMP) has emerged as a popular research topic due toits diverse applications, but it remains a challenging task due to thestochastic and aperiodic nature of future poses. Traditional methods rely onhand-crafted features and machine learning techniques, which often struggle tomodel the complex dynamics of human motion. Recent deep learning-based methodshave achieved success by learning spatio-temporal representations of motion,but these models often overlook the reliability of motion data. Additionally,the temporal and spatial dependencies of skeleton nodes are distinct. Thetemporal relationship captures motion information over time, while the spatialrelationship describes body structure and the relationships between differentnodes. In this paper, we propose a novel spatio-temporal branching networkusing incremental information for HMP, which decouples the learning oftemporal-domain and spatial-domain features, extracts more motion information,and achieves complementary cross-domain knowledge learning through knowledgedistillation. Our approach effectively reduces noise interference and providesmore expressive information for characterizing motion by separately extractingtemporal and spatial features. We evaluate our approach on standard HMPbenchmarks and outperform state-of-the-art methods in terms of predictionaccuracy.", "output": "Spatio-Temporal Branching for Motion Prediction using Motion Increments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a new Convolutional Neural Network (ConvNet)architecture inspired by a class of partial differential equations (PDEs)called quasi-linear hyperbolic systems. With comparable performance on theimage classification task, it allows for the modification of the weights via acontinuous group of symmetry. This is a significant shift from traditionalmodels where the architecture and weights are essentially fixed. We wish topromote the (internal) symmetry as a new desirable property for a neuralnetwork, and to draw attention to the PDE perspective in analyzing andinterpreting ConvNets in the broader Deep Learning community.", "output": "A Novel Convolutional Neural Network Architecture with a Continuous Symmetry."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning (DL) has been successfully applied to encrypted network trafficclassification in experimental settings. However, in production use, it hasbeen shown that a DL classifier's performance inevitably decays over time.Re-training the model on newer datasets has been shown to only partiallyimprove its performance. Manually re-tuning the model architecture to meet theperformance expectations on newer datasets is time-consuming and requiresdomain expertise. We propose AutoML4ETC, a novel tool to automatically designefficient and high-performing neural architectures for encrypted trafficclassification. We define a novel, powerful search space tailored specificallyfor the near real-time classification of encrypted traffic using packet headerbytes. We show that with different search strategies over our search space,AutoML4ETC generates neural architectures that outperform the state-of-the-artencrypted traffic classifiers on several datasets, including public benchmarkdatasets and real-world TLS and QUIC traffic collected from the Orange mobilenetwork. In addition to being more accurate, AutoML4ETC's architectures aresignificantly more efficient and lighter in terms of the number of parameters.Finally, we make AutoML4ETC publicly available for future research.", "output": "AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Cross-domain and cross-compositional generalization of Text-to-SQL semanticparsing is a challenging task. Existing Large Language Model (LLM) basedsolutions rely on inference-time retrieval of few-shot exemplars from thetraining set to synthesize a run-time prompt for each Natural Language (NL)test query. In contrast, we devise an algorithm which performs offline samplingof a minimal set-of few-shots from the training data, with complete coverage ofSQL clauses, operators and functions, and maximal domain coverage within theallowed token length. This allows for synthesis of a fixed Generic Prompt (GP),with a diverse set-of exemplars common across NL test queries, avoidingexpensive test time exemplar retrieval. We further auto-adapt the GP to thetarget database domain (DA-GP), to better handle cross-domain generalization;followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handlecross-compositional generalization. The synthesis of LTMP-DA-GP is an offlinetask, to be performed one-time per new database with minimal humanintervention. Our approach demonstrates superior performance on the KaggleDBQAdataset, designed to evaluate generalizability for the Text-to-SQL task. Wefurther showcase consistent performance improvement of LTMP-DA-GP over GP,across LLMs and databases of KaggleDBQA, highlighting the efficacy and modelagnostic benefits of our prompt based adapt and decompose approach.", "output": "Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Irregularly sampled multivariate time series are ubiquitous in severalapplication domains, leading to sparse, not fully-observed and non-alignedobservations across different variables. Standard sequential neural networkarchitectures, such as recurrent neural networks (RNNs) and convolutionalneural networks (CNNs), consider regular spacing between observation times,posing significant challenges to irregular time series modeling. While most ofthe proposed architectures incorporate RNN variants to handle irregular timeintervals, convolutional neural networks have not been adequately studied inthe irregular sampling setting. In this paper, we parameterize convolutionallayers by employing time-explicitly initialized kernels. Such general functionsof time enhance the learning process of continuous-time hidden dynamics and canbe efficiently incorporated into convolutional kernel weights. We, thus,propose the time-parameterized convolutional neural network (TPCNN), whichshares similar properties with vanilla convolutions but is carefully designedfor irregularly sampled time series. We evaluate TPCNN on both interpolationand classification tasks involving real-world irregularly sampled multivariatetime series datasets. Our experimental results indicate the competitiveperformance of the proposed TPCNN model which is also significantly moreefficient than other state-of-the-art methods. At the same time, the proposedarchitecture allows the interpretability of the input series by leveraging thecombination of learnable time functions that improve the network performance insubsequent tasks and expedite the inaugural application of convolutions in thisfield.", "output": "Time-Parameterized Convolutional Neural Networks for Irregularly Sampled Time Series."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study Off-Policy Evaluation (OPE) in contextual bandit settings with largeaction spaces. The benchmark estimators suffer from severe bias and variancetradeoffs. Parametric approaches suffer from bias due to difficulty specifyingthe correct model, whereas ones with importance weight suffer from variance. Toovercome these limitations, Marginalized Inverse Propensity Scoring (MIPS) wasproposed to mitigate the estimator's variance via embeddings of an action. Tomake the estimator more accurate, we propose the doubly robust estimator ofMIPS called the Marginalized Doubly Robust (MDR) estimator. Theoreticalanalysis shows that the proposed estimator is unbiased under weaker assumptionsthan MIPS while maintaining variance reduction against IPS, which was the mainadvantage of MIPS. The empirical experiment verifies the supremacy of MDRagainst existing estimators.", "output": "Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A major challenge in Explainable AI is in correctly interpreting activationsof hidden neurons: accurate interpretations would provide insights into thequestion of what a deep learning system has internally detected as relevant onthe input, demystifying the otherwise black-box character of deep learningsystems. The state of the art indicates that hidden node activations can, insome cases, be interpretable in a way that makes sense to humans, butsystematic automated methods that would be able to hypothesize and verifyinterpretations of hidden neuron activations are underexplored. In this paper,we provide such a method and demonstrate that it provides meaningfulinterpretations. Our approach is based on using large-scale backgroundknowledge approximately 2 million classes curated from the Wikipedia concepthierarchy together with a symbolic reasoning approach called Concept Inductionbased on description logics, originally developed for applications in theSemantic Web field. Our results show that we can automatically attachmeaningful labels from the background knowledge to individual neurons in thedense layer of a Convolutional Neural Network through a hypothesis andverification process.", "output": "Understanding CNN Hidden Neuron Activations Using Structured Background Knowledge and Deductive Reasoning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Causal inference is a crucial goal of science, enabling researchers to arriveat meaningful conclusions regarding the predictions of hypotheticalinterventions using observational data. Path models, Structural Equation Models(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means tounambiguously specify assumptions regarding the causal structure underlying aphenomenon. Unlike DAGs, which make very few assumptions about the functionaland parametric form, SEM assumes linearity. This can result in functionalmisspecification which prevents researchers from undertaking reliable effectsize estimation. In contrast, we propose Super Learner Equation Modeling, apath modeling technique integrating machine learning Super Learner ensembles.We empirically demonstrate its ability to provide consistent and unbiasedestimates of causal effects, its competitive performance for linear models whencompared with SEM, and highlight its superiority over SEM when dealing withnon-linear relationships. We provide open-source code, and a tutorial notebookwith example usage, accentuating the easy-to-use nature of the method.", "output": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One aim of Process Mining (PM) is the discovery of process models from eventlogs of information systems. PM has been successfully applied toprocess-oriented enterprise systems but is less suited for communication- anddocument-oriented Enterprise Collaboration Systems (ECS). ECS event logs arevery fine-granular and PM applied to their logs results in spaghetti models. Acommon solution for this is event abstraction, i.e., converting low-level logsinto more abstract high-level logs before running discovery algorithms. ECSlogs come with special characteristics that have so far not been fullyaddressed by existing event abstraction approaches. We aim to close this gapwith a tailored ECS event abstraction (ECSEA) approach that trains a model bycomparing recorded actual user activities (high-level traces) with thesystem-generated low-level traces (extracted from the ECS). The model allows usto automatically convert future low-level traces into an abstracted high-levellog that can be used for PM. Our evaluation shows that the algorithm producesaccurate results. ECSEA is a preprocessing method that is essential for theinterpretation of collaborative work activity in ECS, which we call SocialProcess Mining.", "output": "Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent studies of two-view correspondence learning usually establish anend-to-end network to jointly predict correspondence reliability and relativepose. We improve such a framework from two aspects. First, we propose a LocalFeature Consensus (LFC) plugin block to augment the features of existingmodels. Given a correspondence feature, the block augments its neighboringfeatures with mutual neighborhood consensus and aggregates them to produce anenhanced feature. As inliers obey a uniform cross-view transformation and sharemore consistent learned features than outliers, feature consensus strengthensinlier correlation and suppresses outlier distraction, which makes outputfeatures more discriminative for classifying inliers/outliers. Second, existingapproaches supervise network training with the ground truth correspondences andessential matrix projecting one image to the other for an input image pair,without considering the information from the reverse mapping. We extendexisting models to a Siamese network with a reciprocal loss that exploits thesupervision of mutual projection, which considerably promotes the matchingperformance without introducing additional model parameters. Building uponMSA-Net, we implement the two proposals and experimentally achievestate-of-the-art performance on benchmark datasets.", "output": "Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view Correspondence Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "When searching for products, the opinions of others play an important role inmaking informed decisions. Subjective experiences about a product can be avaluable source of information. This is also true in sales conversations, wherea customer and a sales assistant exchange facts and opinions about products.However, training an AI for such conversations is complicated by the fact thatlanguage models do not possess authentic opinions for their lack of real-worldexperience. We address this problem by leveraging product reviews as a richsource of product opinions to ground conversational AI in true subjectivenarratives. With OpinionConv, we develop the first conversational AI forsimulating sales conversations. To validate the generated conversations, weconduct several user studies showing that the generated opinions are perceivedas realistic. Our assessors also confirm the importance of opinions as aninformative basis for decision-making.", "output": "OpinionConv: Conversational Product Search with Grounded Opinions."}]