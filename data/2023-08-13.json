[{"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an investigation into machine learning techniques forviolence detection in videos and their adaptation to a federated learningcontext. The study includes experiments with spatio-temporal features extractedfrom benchmark video datasets, comparison of different methods, and proposal ofa modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\"Additionally, various machine learning techniques, including super-convergenceand transfer learning, are explored, and a method for adapting centralizeddatasets to a federated learning context is developed. The research achievesbetter accuracy results compared to state-of-the-art models by training thebest violence detection model in a federated learning context.", "output": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A significant number of machine learning models are vulnerable to modelextraction attacks, which focus on stealing the models by using speciallycurated queries against the target model. This task is well accomplished byusing part of the training data or a surrogate dataset to train a new modelthat mimics a target model in a white-box environment. In pragmatic situations,however, the target models are trained on private datasets that areinaccessible to the adversary. The data-free model extraction techniquereplaces this problem when it comes to using queries artificially curated by agenerator similar to that used in Generative Adversarial Nets. We propose forthe first time, to the best of our knowledge, an adversary black box attackextending to a regression problem for predicting bounding box coordinates inobject detection. As part of our study, we found that defining a loss functionand using a novel generator setup is one of the key aspects in extracting thetarget model. We find that the proposed model extraction method achievessignificant results by using reasonable queries. The discovery of this objectdetection vulnerability will support future prospects for securing such models.", "output": "Data-Free Model Extraction Attacks in the Context of Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks achieve state-of-the-art performance in image classification,speech recognition, scientific analysis and many more application areas. Withthe ever-increasing need for faster computation and lower power consumption,driven by real-time systems and Internet-of-Things (IoT) devices, FPGAs haveemerged as suitable devices for deep learning inference. Due to the highcomputational complexity and memory footprint of neural networks, variouscompression techniques, such as pruning, quantization and knowledgedistillation, have been proposed in literature. Pruning sparsifies a neuralnetwork, reducing the number of multiplications and memory. However, pruningoften fails to capture properties of the underlying hardware, causingunstructured sparsity and load-balance inefficiency, thus bottleneckingresource improvements. We propose a hardware-centric formulation of pruning, byformulating it as a knapsack problem with resource-aware tensor structures. Theprimary emphasis is on real-time inference, with latencies in the order of1$mu$s, accelerated with hls4ml, an open-source framework for deep learninginference on FPGAs. Evaluated on a range of tasks, including real-time particleclassification at CERN's Large Hadron Collider and fast image classification,the proposed method achieves a reduction ranging between 55% and 92% in theutilization of digital signal processing blocks (DSP) and up to 81% in blockmemory (BRAM) utilization.", "output": "FPGA Resource-aware Structured Pruning for Real-Time Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Epilepsy is a prevalent neurological disorder characterized by recurrent andunpredictable seizures, necessitating accurate prediction for effectivemanagement and patient care. Application of machine learning (ML) onelectroencephalogram (EEG) recordings, along with its ability to providevaluable insights into brain activity during seizures, is able to make accurateand robust seizure prediction an indispensable component in relevant studies.In this research, we present a comprehensive comparative analysis of fivemachine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees(ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the predictionof epileptic seizures using EEG data. The dataset underwent meticulouspreprocessing, including cleaning, normalization, outlier handling, andoversampling, ensuring data quality and facilitating accurate model training.These preprocessing techniques played a crucial role in enhancing the models'performance. The results of our analysis demonstrate the performance of eachmodel in terms of accuracy. The LR classifier achieved an accuracy of 56.95%,while GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of98.99%, while the ET model exhibited the best performance with an accuracy of99.29%. Our findings reveal that the ET model outperformed not only the othermodels in the comparative analysis but also surpassed the state-of-the-artresults from previous research. The superior performance of the ET model makesit a compelling choice for accurate and robust epileptic seizure predictionusing EEG data.", "output": "Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While diffusion-based text-to-image (T2I) models provide a simple andpowerful way to generate images, guiding this generation remains a challenge.For concepts that are difficult to describe through language, users maystruggle to create prompts. Moreover, many of these models are built asend-to-end systems, lacking support for iterative shaping of the image. Inresponse, we introduce PromptPaint, which combines T2I generation withinteractions that model how we use colored paints. PromptPaint allows users togo beyond language to mix prompts that express challenging concepts. Just as weiteratively tune colors through layered placements of paint on a physicalcanvas, PromptPaint similarly allows users to apply different prompts todifferent canvas areas and times of the generative process. Through a set ofstudies, we characterize different approaches for mixing prompts, designtrade-offs, and socio-technical challenges for generative models. WithPromptPaint we provide insight into future steerable generative tools.", "output": "PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This PhD. Thesis concerns the study and development of hierarchicalrepresentations for spatio-temporal visual attention modeling and understandingin video sequences. More specifically, we propose two computational models forvisual attention. First, we present a generative probabilistic model forcontext-aware visual attention modeling and understanding. Secondly, we developa deep network architecture for visual attention modeling, which firstestimates top-down spatio-temporal visual attention, and ultimately serves formodeling attention in the temporal domain.", "output": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the advent of general-purpose Generative AI, the interest in discerningits impact on the labor market escalates. In an attempt to bridge the extantempirical void, we interpret the launch of ChatGPT as an exogenous shock, andimplement a Difference-in-Differences (DID) approach to quantify its influenceon text-related jobs and freelancers within an online labor marketplace. Ourresults reveal a significant decrease in transaction volume for gigs andfreelancers directly exposed to ChatGPT. Additionally, this decline isparticularly marked in units of relatively higher past transaction volume orlower quality standards. Yet, the negative effect is not universallyexperienced among service providers. Subsequent analyses illustrate thatfreelancers proficiently adapting to novel advancements and offering servicesthat augment AI technologies can yield substantial benefits amidst thistransformative period. Consequently, even though the advent of ChatGPT couldconceivably substitute existing occupations, it also unfolds immenseopportunities and carries the potential to reconfigure the future of work. Thisresearch contributes to the limited empirical repository exploring the profoundinfluence of LLM-based generative AI on the labor market, furnishing invaluableinsights for workers, job intermediaries, and regulatory bodies navigating thisevolving landscape.", "output": "\"Generate\" the Future of Work through AI: Empirical Evidence from Online Labor Markets."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Alexa Prize program has empowered numerous university students toexplore, experiment, and showcase their talents in building conversationalagents through challenges like the SocialBot Grand Challenge and the TaskBotChallenge. As conversational agents increasingly appear in multimodal andembodied contexts, it is important to explore the affordances of conversationalinteraction augmented with computer vision and physical embodiment. This paperdescribes the SimBot Challenge, a new challenge in which university teamscompete to build robot assistants that complete tasks in a simulated physicalenvironment. This paper provides an overview of the SimBot Challenge, whichincluded both online and offline challenge phases. We describe theinfrastructure and support provided to the teams including Alexa Arena, thesimulated environment, and the ML toolkit provided to teams to accelerate theirbuilding of vision and language models. We summarize the approaches theparticipating teams took to overcome research challenges and extract keylessons learned. Finally, we provide analysis of the performance of thecompeting SimBots during the competition.", "output": "Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Environmental perception is a key element of autonomous driving because theinformation received from the perception module influences core drivingdecisions. An outstanding challenge in real-time perception for autonomousdriving lies in finding the best trade-off between detection quality andlatency. Major constraints on both computation and power have to be taken intoaccount for real-time perception in autonomous vehicles. Larger objectdetection models tend to produce the best results, but are also slower atruntime. Since the most accurate detectors cannot run in real-time locally, weinvestigate the possibility of offloading computation to edge and cloudplatforms, which are less resource-constrained. We create a synthetic datasetto train object detection models and evaluate different offloading strategies.Using real hardware and network simulations, we compare different trade-offsbetween prediction quality and end-to-end delay. Since sending raw frames overthe network implies additional transmission delays, we also explore the use ofJPEG and H.265 compression at varying qualities and measure their impact onprediction metrics. We show that models with adequate compression can be run inreal-time on the cloud while outperforming local detection performance.", "output": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study performs an ablation analysis of Vector Quantized GenerativeAdversarial Networks (VQGANs), concentrating on image-to-image synthesisutilizing a single NVIDIA A100 GPU. The current work explores the nuancedeffects of varying critical parameters including the number of epochs, imagecount, and attributes of codebook vectors and latent dimensions, specificallywithin the constraint of limited resources. Notably, our focus is pinpointed onthe vector quantization loss, keeping other hyperparameters and loss components(GAN loss) fixed. This was done to delve into a deeper understanding of thediscrete latent space, and to explore how varying its size affects thereconstruction. Though, our results do not surpass the existing benchmarks,however, our findings shed significant light on VQGAN's behaviour for a smallerdataset, particularly concerning artifacts, codebook size optimization, andcomparative analysis with Principal Component Analysis (PCA). The study alsouncovers the promising direction by introducing 2D positional encodings,revealing a marked reduction in artifacts and insights into balancing clarityand overfitting.", "output": "Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The AI4GCC competition presents a bold step forward in the direction ofintegrating machine learning with traditional economic policy analysis. Below,we highlight two potential areas for improvement that could enhance thecompetition's ability to identify and evaluate proposed negotiation protocols.Firstly, we suggest the inclusion of an additional index that accounts forconsumption/utility as part of the evaluation criteria. Secondly, we recommendfurther investigation into the learning dynamics of agents in the simulator andthe game theoretic properties of outcomes from proposed negotiation protocols.We hope that these suggestions can be of use for future iterations of thecompetition/simulation.", "output": "AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, heterogeneous graph few-shot learning has been proposed toaddress the label sparsity issue in heterogeneous graphs (HGs), which containvarious types of nodes and edges. The existing methods have achieved goodperformance by transferring generalized knowledge extracted from rich-labeledclasses in source HG(s) to few-labeled classes in a target HG. However, thesemethods only consider the single-heterogeneity scenario where the source andtarget HGs share a fixed set of node/edge types, ignoring the more generalscenario of cross-heterogeneity, where each HG can have a different andnon-fixed set of node/edge types. To this end, we focus on the unexploredcross-heterogeneity scenario and propose a novel model for Cross-heterogeneityGraph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patternsto capture heterogeneous information and propose a multi-view heterogeneousgraph neural network (MHGN) to learn meta-patterns across HGs. Then, we proposea score module to measure the informativeness of labeled samples and determinethe transferability of each source HG. Finally, by integrating MHGN and thescore module into a meta-learning mechanism, CGFL can effectively transfergeneralized knowledge to predict new classes with few-labeled data. Extensiveexperiments on four real-world datasets have demonstrated the superiorperformance of CGFL over the state-of-the-art methods.", "output": "Cross-heterogeneity Graph Few-shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently developed pretrained models can encode rich world knowledgeexpressed in multiple modalities, such as text and images. However, the outputsof these models cannot be integrated into algorithms to solve sequentialdecision-making tasks. We develop an algorithm that utilizes the knowledge frompretrained models to construct and verify controllers for sequentialdecision-making tasks, and to ground these controllers to task environmentsthrough visual observations. In particular, the algorithm queries a pretrainedmodel with a user-provided, text-based task description and uses the model'soutput to construct an automaton-based controller that encodes the model'stask-relevant knowledge. It then verifies whether the knowledge encoded in thecontroller is consistent with other independently available knowledge, whichmay include abstract information on the environment or user-providedspecifications. If this verification step discovers any inconsistency, thealgorithm automatically refines the controller to resolve the inconsistency.Next, the algorithm leverages the vision and language capabilities ofpretrained models to ground the controller to the task environment. It collectsimage-based observations from the task environment and uses the pretrainedmodel to link these observations to the text-based control logic encoded in thecontroller (e.g., actions and conditions that trigger the actions). We proposea mechanism to ensure the controller satisfies the user-provided specificationeven when perceptual uncertainties are present. We demonstrate the algorithm'sability to construct, verify, and ground automaton-based controllers through asuite of real-world tasks, including daily life and robot manipulation tasks.", "output": "Multimodal Pretrained Models for Sequential Decision-Making: Synthesis, Verification, Grounding, and Perception."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reconstructing 3D poses from 2D poses lacking depth information isparticularly challenging due to the complexity and diversity of human motion.The key is to effectively model the spatial constraints between joints toleverage their inherent dependencies. Thus, we propose a novel model, calledDouble-chain Graph Convolutional Transformer (DC-GCT), to constrain the posethrough a double-chain design consisting of local-to-global and global-to-localchains to obtain a complex representation more suitable for the current humanpose. Specifically, we combine the advantages of GCN and Transformer and designa Local Constraint Module (LCM) based on GCN and a Global Constraint Module(GCM) based on self-attention mechanism as well as a Feature Interaction Module(FIM). The proposed method fully captures the multi-level dependencies betweenhuman body joints to optimize the modeling capability of the model. Moreover,we propose a method to use temporal information into the single-frame model byguiding the video sequence embedding through the joint embedding of the targetframe, with negligible increase in computational cost. Experimental resultsdemonstrate that DC-GCT achieves state-of-the-art performance on twochallenging datasets (Human3.6M and MPI-INF-3DHP). Notably, our model achievesstate-of-the-art performance on all action categories in the Human3.6M datasetusing detected 2D poses from CPN, and our code is available at:", "output": "Double-chain Constraints for 3D Human Pose Estimation in Images and Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph clustering is a fundamental task in graph analysis, and recent advancesin utilizing graph neural networks (GNNs) have shown impressive results.Despite the success of existing GNN-based graph clustering methods, they oftenoverlook the quality of graph structure, which is inherent in real-world graphsdue to their sparse and multifarious nature, leading to subpar performance.Graph structure learning allows refining the input graph by adding missinglinks and removing spurious connections. However, previous endeavors in graphstructure learning have predominantly centered around supervised settings, andcannot be directly applied to our specific clustering tasks due to the absenceof ground-truth labels. To bridge the gap, we propose a novel method calledtextbf{ho}mophily-enhanced structure textbf{le}arning for graph clustering(HoLe). Our motivation stems from the observation that subtly enhancing thedegree of homophily within the graph structure can significantly improve GNNsand clustering outcomes. To realize this objective, we develop twoclustering-oriented structure learning modules, i.e., hierarchical correlationestimation and cluster-aware sparsification. The former module enables a moreaccurate estimation of pairwise node relationships by leveraging guidance fromlatent and clustering spaces, while the latter one generates a sparsifiedstructure based on the similarity matrix and clustering assignments.Additionally, we devise a joint optimization approach alternating betweentraining the homophily-enhanced structure learning and GNN-based clustering,thereby enforcing their reciprocal effects. Extensive experiments on sevenbenchmark datasets of various types and scales, across a range of clusteringmetrics, demonstrate the superiority of HoLe against state-of-the-artbaselines.", "output": "Homophily-enhanced Structure Learning for Graph Clustering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rudimentary adversarial attacks utilize additive noise to attack facialrecognition (FR) models. However, because manipulating the total face isimpractical in the physical setting, most real-world FR attacks are based onadversarial patches, which limit perturbations to a small area. Previousadversarial patch attacks often resulted in unnatural patterns and clearboundaries that were easily noticeable. In this paper, we argue that generatingadversarial patches with plausible content can result in strongertransferability than using additive noise or directly sampling from the latentspace. To generate natural-looking and highly transferable adversarial patches,we propose an innovative two-stage coarse-to-fine attack framework calledAdv-Inpainting. In the first stage, we propose an attention-guided StyleGAN(Att-StyleGAN) that adaptively combines texture and identity features based onthe attention map to generate high-transferable and natural adversarialpatches. In the second stage, we design a refinement network with a newboundary variance loss to further improve the coherence between the patch andits surrounding area. Experiment results demonstrate that Adv-Inpainting isstealthy and can produce adversarial patches with stronger transferability andimproved visual quality than previous adversarial patch attacks.", "output": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, generative AIs like ChatGPT have become available to the widepublic. These tools can for instance be used by students to generate essays orwhole theses. But how does a teacher know whether a text is written by astudent or an AI? In our work, we explore traditional and new features to (1)detect text generated by AI from scratch and (2) text rephrased by AI. Since wefound that classification is more difficult when the AI has been instructed tocreate the text in a way that a human would not recognize that it was generatedby an AI, we also investigate this more advanced case. For our experiments, weproduced a new text corpus covering 10 school topics. Our best systems toclassify basic and advanced human-generated/AI-generated texts have F1-scoresof over 96%. Our best systems for classifying basic and advancedhuman-generated/AI-rephrased texts have F1-scores of more than 78%. The systemsuse a combination of perplexity, semantic, list lookup, error-based,readability, AI feedback, and text vector features. Our results show that thenew features substantially help to improve the performance of many classifiers.Our best basic text rephrasing detection system even outperforms GPTZero by183.8% relative in F1-score.", "output": "Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In Large Language Models (LLMs), there have been consistent advancements intask-specific performance, largely influenced by effective prompt design. Whilerecent research on prompting has enhanced the reasoning capabilities of LLMs, agap remains in further improving their understanding abilities. In this study,we introduce metacognitive prompting (MP), a strategy inspired by humanintrospective reasoning processes. Using MP, LLMs undergo a systematic seriesof structured, self-aware evaluations, drawing on both their vast inherentknowledge and new insights. Our experiments involve five prevalent LLMs:Llama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various generalnatural language understanding (NLU) tasks from the GLUE and SuperGLUEbenchmarks. Results indicate that, although GPT-4 consistently excels in mosttasks, PaLM, when equipped with MP, approaches its performance level.Furthermore, across models and datasets, MP consistently outperforms existingprompting methods, including standard and chain-of-thought prompting. Thisstudy underscores the potential to amplify the understanding abilities of LLMsand highlights the benefits of mirroring human introspective reasoning in NLUtasks.", "output": "Metacognitive Prompting Improves Understanding in Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Efficient and timely calculations of Machine Learning (ML) algorithms areessential for emerging technologies like autonomous driving, the Internet ofThings (IoT), and edge computing. One of the primary ML algorithms used in suchsystems is Convolutional Neural Networks (CNNs), which demand highcomputational resources. This requirement has led to the use of ML acceleratorslike GPGPUs to meet design constraints. However, selecting the most suitableaccelerator involves Design Space Exploration (DSE), a process that is usuallytime-consuming and requires significant manual effort. Our work presentsapproaches to expedite the DSE process by identifying the most appropriateGPGPU for CNN inferencing systems. We have developed a quick and precisetechnique for forecasting the power and performance of CNNs during inference,with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computerarchitects to estimate power and performance in the early stages ofdevelopment, reducing the necessity for numerous prototypes. This saves timeand money while also improving the time-to-market period.", "output": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ensuring alignment, which refers to making models behave in accordance withhuman intentions [1,2], has become a critical task before deploying largelanguage models (LLMs) in real-world applications. For instance, OpenAI devotedsix months to iteratively aligning GPT-4 before its release [3]. However, amajor challenge faced by practitioners is the lack of clear guidance onevaluating whether LLM outputs align with social norms, values, andregulations. This obstacle hinders systematic iteration and deployment of LLMs.To address this issue, this paper presents a comprehensive survey of keydimensions that are crucial to consider when assessing LLM trustworthiness. Thesurvey covers seven major categories of LLM trustworthiness: reliability,safety, fairness, resistance to misuse, explainability and reasoning, adherenceto social norms, and robustness. Each major category is further divided intoseveral sub-categories, resulting in a total of 29 sub-categories.Additionally, a subset of 8 sub-categories is selected for furtherinvestigation, where corresponding measurement studies are designed andconducted on several widely-used LLMs. The measurement results indicate that,in general, more aligned models tend to perform better in terms of overalltrustworthiness. However, the effectiveness of alignment varies across thedifferent trustworthiness categories considered. This highlights the importanceof conducting more fine-grained analyses, testing, and making continuousimprovements on LLM alignment. By shedding light on these key dimensions of LLMtrustworthiness, this paper aims to provide valuable insights and guidance topractitioners in the field. Understanding and addressing these concerns will becrucial in achieving reliable and ethically sound deployment of LLMs in variousapplications.", "output": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Relevance modeling aims to locate desirable items for corresponding queries,which is crucial for search engines to ensure user experience. Although mostconventional approaches address this problem by assessing the semanticsimilarity between the query and item, pure semantic matching is noteverything. In reality, auxiliary query-item interactions extracted from userhistorical behavior data of the search log could provide hints to reveal users'search intents further. Drawing inspiration from this, we devise a novelBehavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) thatleverages neighbor queries of target item and neighbor items of target query tocomplement target query-item semantic matching. Specifically, our model buildsmulti-level co-attention for distilling coarse-grained and fine-grainedsemantic representations from both neighbor and target views. The modelsubsequently employs neighbor-target self-supervised learning to improve theaccuracy and robustness of BARL-ASe by strengthening representation and logitlearning. Furthermore, we discuss how to deal with the long-tail query-itemmatching of the mini apps search scenario of Alipay practically. Experiments onreal-world industry data and online A/B testing demonstrate our proposalachieves promising performance with low latency.", "output": "Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Patent classification aims to assign multiple International PatentClassification (IPC) codes to a given patent. Recent methods for automaticallyclassifying patents mainly focus on analyzing the text descriptions of patents.However, apart from the texts, each patent is also associated with someassignees, and the knowledge of their applied patents is often valuable forclassification. Furthermore, the hierarchical taxonomy formulated by the IPCsystem provides important contextual information and enables models to leveragethe correlations between IPC codes for more accurate classification. However,existing methods fail to incorporate the above aspects. In this paper, wepropose an integrated framework that comprehensively considers the informationon patents for patent classification. To be specific, we first present an IPCcodes correlations learning module to derive their semantic representations viaadaptively passing and aggregating messages within the same level and acrossdifferent levels along the hierarchical taxonomy. Moreover, we design ahistorical application patterns learning component to incorporate thecorresponding assignee's previous patents by a dual channel aggregationmechanism. Finally, we combine the contextual information of patent texts thatcontains the semantics of IPC codes, and assignees' sequential preferences tomake predictions. Experiments on real-world datasets demonstrate thesuperiority of our approach over the existing methods. Besides, we present themodel's ability to capture the temporal patterns of assignees and the semanticdependencies among IPC codes.", "output": "Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Trust in AI agents has been extensively studied in the literature, resultingin significant advancements in our understanding of this field. However, therapid advancements in Large Language Models (LLMs) and the emergence ofLLM-based AI agent frameworks pose new challenges and opportunities for furtherresearch. In the field of process automation, a new generation of AI-basedagents has emerged, enabling the execution of complex tasks. At the same time,the process of building automation has become more accessible to business usersvia user-friendly no-code tools and training mechanisms. This paper exploresthese new challenges and opportunities, analyzes the main aspects of trust inAI agents discussed in existing literature, and identifies specificconsiderations and challenges relevant to this new generation of automationagents. We also evaluate how nascent products in this category address theseconsiderations. Finally, we highlight several challenges that the researchcommunity should address in this evolving landscape.", "output": "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With a rapidly increasing amount and diversity of remote sensing (RS) datasources, there is a strong need for multi-view learning modeling. This is acomplex task when considering the differences in resolution, magnitude, andnoise of RS data. The typical approach for merging multiple RS sources has beeninput-level fusion, but other - more advanced - fusion strategies mayoutperform this traditional approach. This work assesses different fusionstrategies for crop classification in the CropHarvest dataset. The fusionmethods proposed in this work outperform models based on individual views andprevious fusion methods. We do not find one single fusion method thatconsistently outperforms all other approaches. Instead, we present a comparisonof multi-view fusion methods for three different datasets and show that,depending on the test region, different methods obtain the best performance.Despite this, we suggest a preliminary criterion for the selection of fusionmethods.", "output": "A Comparative Assessment of Multi-view fusion learning for Crop Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial Intelligence in Medicine has made significant progress withemerging applications in medical imaging, patient care, and other areas. Whilethese applications have proven successful in retrospective studies, very few ofthem were applied in practice.The field of Medical AI faces various challenges,in terms of building user trust, complying with regulations, using dataethically.Explainable AI (XAI) aims to enable humans understand AI and trustits results. This paper presents a literature review on the recent developmentsof XAI solutions for medical decision support, based on a representative sampleof 198 articles published in recent years. The systematic synthesis of therelevant articles resulted in several findings. (1) model-agnostic XAItechniques were mostly employed in these solutions, (2) deep learning modelsare utilized more than other types of machine learning models, (3)explainability was applied to promote trust, but very few works reported thephysicians participation in the loop, (4) visual and interactive user interfaceis more useful in understanding the explanation and the recommendation of thesystem. More research is needed in collaboration between medical and AIexperts, that could guide the development of suitable frameworks for thedesign, implementation, and evaluation of XAI solutions in medicine.", "output": "Explainable AI applications in the Medical Domain: a systematic review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent developments and the beginning market introduction of high-resolutionimaging 4D (3+1D) radar sensors have initialized deep learning-based radarperception research. We investigate deep learning-based models operating onradar point clouds for 3D object detection. 3D object detection on lidar pointcloud data is a mature area of 3D vision. Many different architectures havebeen proposed, each with strengths and weaknesses. Due to similarities between3D lidar point clouds and 3+1D radar point clouds, those existing 3D objectdetectors are a natural basis to start deep learning-based 3D object detectionon radar data. Thus, the first step is to analyze the detection performance ofthe existing models on the new data modality and evaluate them in depth. Inorder to apply existing 3D point cloud object detectors developed for lidarpoint clouds to the radar domain, they need to be adapted first. While somedetectors, such as PointPillars, have already been adapted to be applicable toradar data, we have adapted others, e.g., Voxel R-CNN, SECOND, PointRCNN, andPV-RCNN. To this end, we conduct a cross-model validation (evaluating a set ofmodels on one particular data set) as well as a cross-data set validation(evaluating all models in the model set on several data sets). Thehigh-resolution radar data used are the View-of-Delft and Astyx data sets.Finally, we evaluate several adaptations of the models and their trainingprocedures. We also discuss major factors influencing the detection performanceon radar data and propose possible solutions indicating potential futureresearch avenues.", "output": "Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Database administrators (DBAs) play a crucial role in managing, maintainingand optimizing a database system to ensure data availability, performance, andreliability. However, it is hard and tedious for DBAs to manage a large numberof database instances (e.g., millions of instances on the cloud databases).Recently large language models (LLMs) have shown great potential to understandvaluable documents and accordingly generate reasonable answers. Thus, wepropose D-Bot, a LLM-based database administrator that can continuously acquiredatabase maintenance experience from textual sources, and provide reasonable,well-founded, in-time diagnosis and optimization advice for target databases.This paper presents a revolutionary LLM-centric framework for databasemaintenance, including (i) database maintenance knowledge detection fromdocuments and tools, (ii) tree of thought reasoning for root cause analysis,and (iii) collaborative diagnosis among multiple LLMs. Our preliminaryexperimental results that D-Bot can efficiently and effectively diagnose theroot causes and our code is available atgithub.com/TsinghuaDatabaseGroup/DB-GPT.", "output": "LLM As DBA."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Explainable AI has the potential to support more interactive and fluidco-creative AI systems which can creatively collaborate with people. To dothis, creative AI models need to be amenable to debugging by offeringeXplainable AI (XAI) features which are inspectable, understandable, andmodifiable. However, currently there is very little XAI for the arts. In thiswork, we demonstrate how a latent variable model for music generation can bemade more explainable; specifically we extend MeasureVAE which generatesmeasures of music. We increase the explainability of the model by: i) usinglatent space regularisation to force some specific dimensions of the latentspace to map to meaningful musical attributes, ii) providing a user interfacefeedback loop to allow people to adjust dimensions of the latent space andobserve the results of these changes in real-time, iii) providing avisualisation of the musical attributes in the latent space to help peopleunderstand and predict the effect of changes to latent space dimensions. Wesuggest that in doing so we bridge the gap between the latent space and thegenerated musical outcomes in a meaningful way which makes the model and itsoutputs more explainable and more debuggable.", "output": "Exploring XAI for the Arts: Explaining Latent Space in Generative Music."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Patient's vital signs, which are displayed on monitors, make theanesthesiologist's visual attention (VA) a key component in the safe managementof patients under general anesthesia; moreover, the distribution of said VA andthe ability to acquire specific cues throughout the anesthetic, may have adirect impact on patient's outcome. Currently, most studies employ wearableeye-tracking technologies to analyze anesthesiologists' visual patterns. Albeitbeing able to produce meticulous data, wearable devices are not a sustainablesolution for large-scale or long-term use for data collection in the operatingroom (OR). Thus, by utilizing a novel eye-tracking method in the form of deeplearning models that process monitor-mounted webcams, we collected continuousbehavioral data and gained insight into the anesthesiologist's VA distributionwith minimal disturbance to their natural workflow. In this study, we collectedOR video recordings using the proposed framework and compared different visualbehavioral patterns. We distinguished between baseline VA distribution duringuneventful periods to patterns associated with active phases or duringcritical, unanticipated incidents. In the future, such a platform may serve asa crucial component of context-aware assistive technologies in the OR.", "output": "More Than Meets the Eye: Analyzing Anesthesiologists' Visual Attention in the Operating Room Using Deep Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Transformer-based language models (TLMs) have widely been recognized to be acutting-edge technology for the successful development of deep-learning-basedsolutions to problems and applications that require natural language processingand understanding. Like for other textual domains, TLMs have indeed pushed thestate-of-the-art of AI approaches for many tasks of interest in the legaldomain. Despite the first Transformer model being proposed about six years ago,there has been a rapid progress of this technology at an unprecedented rate,whereby BERT and related models represent a major reference, also in the legaldomain. This article provides the first systematic overview of TLM-basedmethods for AI-driven problems and tasks in the legal sphere. A major goal isto highlight research advances in this field so as to understand, on the onehand, how the Transformers have contributed to the success of AI in supportinglegal processes, and on the other hand, what are the current limitations andopportunities for further research development.", "output": "Bringing order into the realm of Transformer-based language models for artificial intelligence and law."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We study the fair division problem and the existence of allocationssatisfying the fairness criterion envy-freeness up to any item (EFX). Theexistence of EFX allocations is a major open problem in the fair divisionliterature. We consider binary valuations where the marginal gain of the valueby receiving an extra item is either $0$ or $1$. Babaioff et al. [2021] provedthat EFX allocations always exist for binary and submodular valuations. In thispaper, by using completely different techniques, we extend this existenceresult to general binary valuations that are not necessarily submodular, and wepresent a polynomial time algorithm for computing an EFX allocation.", "output": "EFX Allocations Exist for Binary Valuations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multi-domain recommendation (MDR) aims to provide recommendations fordifferent domains (e.g., types of products) with overlapping users/items and iscommon for platforms such as Amazon, Facebook, and LinkedIn that host multipleservices. Existing MDR models face two challenges: First, it is difficult todisentangle knowledge that generalizes across domains (e.g., a user likes cheapitems) and knowledge specific to a single domain (e.g., a user likes blueclothing but not blue cars). Second, they have limited ability to transferknowledge across domains with small overlaps. We propose a new MDR method namedEDDA with two key components, i.e., embedding disentangling recommender anddomain alignment, to tackle the two challenges respectively. In particular, theembedding disentangling recommender separates both the model and embedding forthe inter-domain part and the intra-domain part, while most existing MDRmethods only focus on model-level disentangling. The domain alignment leveragesrandom walks from graph processing to identify similar user/item pairs fromdifferent domains and encourages similar user/item pairs to have similarembeddings, enhancing knowledge transfer. We compare EDDA with 12state-of-the-art baselines on 3 real datasets. The results show that EDDAconsistently outperforms the baselines on all datasets and domains. Alldatasets and codes are available at ", "output": "Multi-domain Recommendation with Embedding Disentangling and Domain Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability of robots to autonomously navigate through 3D environmentsdepends on their comprehension of spatial concepts, ranging from low-levelgeometry to high-level semantics, such as objects, places, and buildings. Toenable such comprehension, 3D scene graphs have emerged as a robust tool forrepresenting the environment as a layered graph of concepts and theirrelationships. However, building these representations using monocular visionsystems in real-time remains a difficult task that has not been explored indepth. This paper puts forth a real-time spatial perception system Mono-Hydra,combining a monocular camera and an IMU sensor setup, focusing on indoorscenarios. However, the proposed approach is adaptable to outdoor applications,offering flexibility in its potential uses. The system employs a suite of deeplearning algorithms to derive depth and semantics. It uses a robocentricvisual-inertial odometry (VIO) algorithm based on square-root information,thereby ensuring consistent visual odometry with an IMU and a monocular camera.This system achieves sub-20 cm error in real-time processing at 15 fps,enabling real-time 3D scene graph construction using a laptop GPU (NVIDIA3080). This enhances decision-making efficiency and effectiveness in simplecamera setups, augmenting robotic system agility. We make Mono-Hydra publiclyavailable at: ", "output": "Mono-hydra: Real-time 3D scene graph construction from monocular camera input with IMU."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Retrosynthesis consists of breaking down a chemical compound recursivelystep-by-step into molecular precursors until a set of commercially availablemolecules is found with the goal to provide a synthesis route. Its two primaryresearch directions, single-step retrosynthesis prediction, which models thechemical reaction logic, and multi-step synthesis planning, which tries to findthe correct sequence of reactions, are inherently intertwined. Still, thisconnection is not reflected in contemporary research. In this work, we combinethese two major research directions by applying multiple single-stepretrosynthesis models within multi-step synthesis planning and analyzing theirimpact using public and proprietary reaction data. We find a disconnectionbetween high single-step performance and potential route-finding success,suggesting that single-step models must be evaluated within synthesis planningin the future. Furthermore, we show that the commonly used single-stepretrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluationtask does not represent model performance and scalability on larger and morediverse datasets. For multi-step synthesis planning, we show that the choice ofthe single-step model can improve the overall success rate of synthesisplanning by up to +28% compared to the commonly used baseline model. Finally,we show that each single-step model finds unique synthesis routes, and differsin aspects such as route-finding success, the number of found synthesis routes,and chemical validity, making the combination of single-step retrosynthesisprediction and multi-step synthesis planning a crucial aspect when developingfuture methods.", "output": "Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous underwater vehicles (AUVs) play a crucial role in surveying marineenvironments, carrying out underwater inspection tasks, and ocean exploration.However, in order to ensure that the AUV is able to carry out its missionsuccessfully, a control system capable of adapting to changing environmentalconditions is required. Furthermore, to ensure the robotic platform's safeoperation, the onboard controller should be able to operate under certainconstraints. In this work, we investigate the feasibility of Model PredictivePath Integral Control (MPPI) for the control of an AUV. We utilise a non-linearmodel of the AUV to propagate the samples of the MPPI, which allow us tocompute the control action in real time. We provide a detailed evaluation ofthe effect of the main hyperparameters on the performance of the MPPIcontroller. Furthermore, we compared the performance of the proposed methodwith a classical PID and Cascade PID approach, demonstrating the superiority ofour proposed controller. Finally, we present results where environmentalconstraints are added and show how MPPI can handle them by simply incorporatingthose constraints in the cost function.", "output": "Enhancing AUV Autonomy With Model Predictive Path Integral Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper provides an overview of the historical progression of distributedoptimization techniques, tracing their development from early duality-basedmethods pioneered by Dantzig, Wolfe, and Benders in the 1960s to the emergenceof the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN)algorithm. The initial focus on Lagrangian relaxation for convex problems anddecomposition strategies led to the refinement of methods like the AlternatingDirection Method of Multipliers (ADMM). The resurgence of interest indistributed optimization in the late 2000s, particularly in machine learningand imaging, demonstrated ADMM's practical efficacy and its unifying potential.This overview also highlights the emergence of the proximal center method andits applications in diverse domains. Furthermore, the paper underscores thedistinctive features of ALADIN, which offers convergence guarantees fornon-convex scenarios without introducing auxiliary variables, differentiatingit from traditional augmentation techniques. In essence, this work encapsulatesthe historical trajectory of distributed optimization and underscores thepromising prospects of ALADIN in addressing non-convex optimization challenges.", "output": "Learning (With) Distributed Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A deepfake is a photo or video of a person whose image has been digitallyaltered or partially replaced with an image of someone else. Deepfakes have thepotential to cause a variety of problems and are often used maliciously. Acommon usage is altering videos of prominent political figures and celebrities.These deepfakes can portray them making offensive, problematic, and/or untruestatements. Current deepfakes can be very realistic, and when used in this way,can spread panic and even influence elections and political opinions. There aremany deepfake detection strategies currently in use but finding the mostcomprehensive and universal method is critical. So, in this survey we willaddress the problems of malicious deepfake creation and the lack of universaldeepfake detection methods. Our objective is to survey and analyze a variety ofcurrent methods and advances in the field of deepfake detection.", "output": "Recent Advancements In The Field Of Deepfake Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large language models (LLMs), such as ChatGPT, have demonstrated outstandingperformance in various fields, particularly in natural language understandingand generation tasks. In complex application scenarios, users tend to engage inmulti-turn conversations with ChatGPT to keep contextual information and obtaincomprehensive responses. However, human forgetting and model contextualforgetting remain prominent issues in multi-turn conversation scenarios, whichchallenge the users' conversation comprehension and contextual continuity forChatGPT. To address these challenges, we propose an interactive conversationvisualization system called C5, which includes Global View, Topic View, andContext-associated Q&amp;A View. The Global View uses the GitLog diagram metaphorto represent the conversation structure, presenting the trend of conversationevolution and supporting the exploration of locally salient features. The TopicView is designed to display all the question and answer nodes and theirrelationships within a topic using the structure of a knowledge graph, therebydisplay the relevance and evolution of conversations. The Context-associatedQ&amp;A View consists of three linked views, which allow users to exploreindividual conversations deeply while providing specific contextual informationwhen posing questions. The usefulness and effectiveness of C5 were evaluatedthrough a case study and a user study.", "output": "C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Channel modelling is essential to designing modern wireless communicationsystems. The increasing complexity of channel modelling and the cost ofcollecting high-quality wireless channel data have become major challenges. Inthis paper, we propose a diffusion model based channel sampling approach forrapidly synthesizing channel realizations from limited data. We use a diffusionmodel with a U Net based architecture operating in the frequency space domain.To evaluate how well the proposed model reproduces the true distribution ofchannels in the training dataset, two evaluation metrics are used: $i)$ theapproximate $2$-Wasserstein distance between real and generated distributionsof the normalized power spectrum in the antenna and frequency domains and $ii)$precision and recall metric for distributions. We show that, compared toexisting GAN based approaches which suffer from mode collapse and unstabletraining, our diffusion based approach trains stably and generates diverse andhigh-fidelity samples from the true channel distribution. We also show that wecan pretrain the model on a simulated urban macro-cellular channel dataset andfine-tune it on a smaller, out-of-distribution urban micro-cellular dataset,therefore showing that it is feasible to model real world channels usinglimited data with this approach.", "output": "Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role inshaping the impact of large language models (LLMs), contributing significantlyto controlling output toxicity and selecting output styles, particularly asLLMs often harbor misleading content, highlighting the urgency to align themwith human values for secure AI systems. The RLHF, characterized by complexity,instability, and sensitivity to hyperparameters, makes the evaluation of thereward model for complex tasks challenging, thereby further complicating theuse of Proximal Policy Optimization (PPO). In this paper, we introduce a simpletask designed to employ Gloden as a reward model that validates theeffectiveness of PPO and inspires it, primarily explaining the task ofutilizing PPO to manipulate the tokenizer length of the output generated by themodel. Experiments confirm that PPO is not only effective in manipulating theoutput tokenizer length to a certain extent in this type of task but alsoexhibits facilitated training once the influence of the reward model effect isexcluded, making it an exciting development.", "output": "Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Inter-city highway transportation is significant for urban life. As one ofthe key functions in intelligent transportation system (ITS), trafficevaluation always plays significant role nowadays, and daily traffic flowprediction still faces challenges at network-wide toll stations. On the onehand, the data imbalance in practice among various locations deteriorates theperformance of prediction. On the other hand, complex correlativespatio-temporal factors cannot be comprehensively employed in long-termduration. In this paper, a prediction method is proposed for daily traffic flowin highway domain through spatio-temporal deep learning. In our method, datanormalization strategy is used to deal with data imbalance, due to long-taildistribution of traffic flow at network-wide toll stations. And then, based ongraph convolutional network, we construct networks in distinct semantics tocapture spatio-temporal features. Beside that, meteorology and calendarfeatures are used by our model in the full connection stage to extra externalcharacteristics of traffic flow. By extensive experiments and case studies inone Chinese provincial highway, our method shows clear improvement inpredictive accuracy than baselines and practical benefits in business.", "output": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In today's chemical production plants, human field operators perform frequentchecks on the plant's integrity to guarantee high safety standards, and thusare possibly the first to encounter dangerous operating conditions. Toalleviate their tasks of failure detection and monitoring by audio, visual, andolfactory perceptions, we present a robotic system that consists of anautonomously navigating robot integrated with various sensors and dataprocessing. We aim to resemble the human sensing and interpretationcapabilities of sight, smell, and hearing, for providing automated inspection.We evaluate our system extensively at a wastewater facility in full workingconditions. Our results demonstrate that the system is able to robustlynavigate a plant and to provide useful information about critical operatingconditions.", "output": "A Smart Robotic System for Industrial Plant Supervision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Discrete-choice models are used in economics, marketing and revenuemanagement to predict customer purchase probabilities, say as a function ofprices and other features of the offered assortment. While they have been shownto be expressive, capturing customer heterogeneity and behaviour, they are alsohard to estimate, often based on many unobservables like utilities; andmoreover, they still fail to capture many salient features of customerbehaviour. A natural question then, given their success in other contexts, isif neural networks can eliminate the necessity of carefully building acontext-dependent customer behaviour model and hand-coding and tuning theestimation. It is unclear however how one would incorporate assortment effectsinto such a neural network, and also how one would optimize the assortment withsuch a black-box generative model of choice probabilities. In this paper weinvestigate first whether a single neural network architecture can predictpurchase probabilities for datasets from various contexts and generated undervarious models and assumptions. Next, we develop an assortment optimizationformulation that is solvable by off-the-shelf integer programming solvers. Wecompare against a variety of benchmark discrete-choice models on simulated aswell as real-world datasets, developing training tricks along the way to makethe neural network prediction and subsequent optimization robust and comparablein performance to the alternates.", "output": "A Neural Network Based Choice Model for Assortment Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As data shift or new data become available, updating clinical machinelearning models may be necessary to maintain or improve performance over time.However, updating a model can introduce compatibility issues when the behaviorof the updated model does not align with user expectations, resulting in pooruser-model team performance. Existing compatibility measures depend on modeldecision thresholds, limiting their applicability in settings where models areused to generate rankings based on estimated risk. To address this limitation,we propose a novel rank-based compatibility measure, $C^R$, and a new lossfunction that aims to optimize discriminative performance while encouraginggood compatibility. Applied to a case study in mortality risk stratificationleveraging data from MIMIC, our approach yields more compatible models whilemaintaining discriminative performance compared to existing model selectiontechniques, with an increase in $C^R$ of $0.019$ ($95%$ confidence interval:$0.005$, $0.035$). This work provides new tools to analyze and update riskstratification models used in clinical care.", "output": "Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In today's rapidly evolving urban landscapes, efficient and accurate mappingof road infrastructure is critical for optimizing transportation systems,enhancing road safety, and improving the overall mobility experience fordrivers and commuters. Yet, a formidable bottleneck obstructs progress - thelaborious and time-intensive manual identification of intersections. Simplyconsidering the shear number of intersections that need to be identified, andthe labor hours required per intersection, the need for an automated solutionbecomes undeniable. To address this challenge, we propose a novel approach thatleverages connected vehicle data and cutting-edge deep learning techniques. Byemploying geohashing to segment vehicle trajectories and then generating imagerepresentations of road segments, we utilize the YOLOv5 (You Only Look Onceversion 5) algorithm for accurate classification of both straight road segmentsand intersections. Experimental results demonstrate an impressive overallclassification accuracy of 95%, with straight roads achieving a remarkable 97%F1 score and intersections reaching a 90% F1 score. This approach not onlysaves time and resources but also enables more frequent updates and acomprehensive understanding of the road network. Our research showcases thepotential impact on traffic management, urban planning, and autonomous vehiclenavigation systems. The fusion of connected vehicle data and deep learningmodels holds promise for a transformative shift in road infrastructure mapping,propelling us towards a smarter, safer, and more connected transportationecosystem.", "output": "Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Modern transportation planning relies heavily on accurate predictions ofperson and vehicle trips. However, traditional planning models often fail toaccount for the intricacies and dynamics of travel behavior, leading toless-than-optimal accuracy in these predictions. This study explores thepotential of deep learning techniques to transform the way we approach trippredictions, and ultimately, transportation planning. Utilizing a comprehensivedataset from the National Household Travel Survey (NHTS), we developed andtrained a deep learning model for predicting person and vehicle trips. Theproposed model leverages the vast amount of information in the NHTS data,capturing complex, non-linear relationships that were previously overlooked bytraditional models. As a result, our deep learning model achieved an impressiveaccuracy of 98% for person trip prediction and 96% for vehicle trip estimation.This represents a significant improvement over the performances of traditionaltransportation planning models, thereby demonstrating the power of deeplearning in this domain. The implications of this study extend beyond just moreaccurate predictions. By enhancing the accuracy and reliability of tripprediction models, planners can formulate more effective, data-driventransportation policies, infrastructure, and services. As such, our researchunderscores the need for the transportation planning field to embrace advancedtechniques like deep learning. The detailed methodology, along with a thoroughdiscussion of the results and their implications, are presented in thesubsequent sections of this paper.", "output": "Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, methods for skeleton-based human activity recognition have beenshown to be vulnerable to adversarial attacks. However, these attack methodsrequire either the full knowledge of the victim (i.e. white-box attacks),access to training data (i.e. transfer-based attacks) or frequent model queries(i.e. black-box attacks). All their requirements are highly restrictive,raising the question of how detrimental the vulnerability is. In this paper, weshow that the vulnerability indeed exists. To this end, we consider a newattack task: the attacker has no access to the victim model or the trainingdata or labels, where we coin the term hard no-box attack. Specifically, wefirst learn a motion manifold where we define an adversarial loss to compute anew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Ourgradient contains information of the motion dynamics, which is different fromexisting gradient-based attack methods that compute the loss gradient assumingeach dimension in the data is independent. The SMI gradient can augment manygradient-based attack methods, leading to a new family of no-box attackmethods. Extensive evaluation and comparison show that our method imposes areal threat to existing classifiers. They also show that the SMI gradientimproves the transferability and imperceptibility of adversarial samples inboth no-box and transfer-based black-box settings.", "output": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervised learning (SSL) has gained significant interest in recentyears as a solution to address the challenges posed by sparse and noisy data inrecommender systems. Despite the growing number of SSL algorithms designed toprovide state-of-the-art performance in various recommendation scenarios (e.g.,graph collaborative filtering, sequential recommendation, socialrecommendation, KG-enhanced recommendation), there is still a lack of unifiedframeworks that integrate recommendation algorithms across different domains.Such a framework could serve as the cornerstone for self-supervisedrecommendation algorithms, unifying the validation of existing methods anddriving the design of new ones. To address this gap, we introduce SSLRec, anovel benchmark platform that provides a standardized, flexible, andcomprehensive framework for evaluating various SSL-enhanced recommenders. TheSSLRec library features a modular architecture that allows users to easilyevaluate state-of-the-art models and a complete set of data augmentation andself-supervised toolkits to help create SSL recommendation models with specificneeds. Furthermore, SSLRec simplifies the process of training and evaluatingdifferent recommendation models with consistent and fair settings. Our SSLRecplatform covers a comprehensive set of state-of-the-art SSL-enhancedrecommendation models across different scenarios, enabling researchers toevaluate these cutting-edge models and drive further innovation in the field.Our implemented SSLRec framework is available at the source code repository", "output": "SSLRec: A Self-Supervised Learning Library for Recommendation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years there have been remarkable advancements in autonomousdriving. While autonomous vehicles demonstrate high performance in closed-setconditions, they encounter difficulties when confronted with unexpectedsituations. At the same time, world models emerged in the field of model-basedreinforcement learning as a way to enable agents to predict the futuredepending on potential actions. This led to outstanding results in sparsereward and complex control tasks. This work provides an overview of how worldmodels can be leveraged to perform anomaly detection in the domain ofautonomous driving. We provide a characterization of world models and relateindividual components to previous works in anomaly detection to facilitatefurther research in the field.", "output": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report describes a test of the large language model GPT-4 with theWolfram Alpha and the Code Interpreter plug-ins on 105 original problems inscience and math, at the high school and college levels, carried out inJune-August 2023. Our tests suggest that the plug-ins significantly enhanceGPT's ability to solve these problems. Having said that, there are still often\"interface\" failures; that is, GPT often has trouble formulating problems in away that elicits useful answers from the plug-ins. Fixing these interfacefailures seems like a central challenge in making GPT a reliable tool forcollege-level calculation problems.", "output": "Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated driving has the potential to revolutionize personal, public, andfreight mobility. Besides the enormous challenge of perception, i.e. accuratelyperceiving the environment using available sensor data, automated drivingcomprises planning a safe, comfortable, and efficient motion trajectory. Topromote safety and progress, many works rely on modules that predict the futuremotion of surrounding traffic. Modular automated driving systems commonlyhandle prediction and planning as sequential separate tasks. While thisaccounts for the influence of surrounding traffic on the ego-vehicle, it failsto anticipate the reactions of traffic participants to the ego-vehicle'sbehavior. Recent works suggest that integrating prediction and planning in aninterdependent joint step is necessary to achieve safe, efficient, andcomfortable driving. While various models implement such integrated systems, acomprehensive overview and theoretical understanding of different principlesare lacking. We systematically review state-of-the-art deep learning-basedprediction, planning, and integrated prediction and planning models. Differentfacets of the integration ranging from model architecture and model design tobehavioral aspects are considered and related to each other. Moreover, wediscuss the implications, strengths, and limitations of different integrationmethods. By pointing out research gaps, describing relevant future challenges,and highlighting trends in the research field, we identify promising directionsfor future research.", "output": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time-dependent partial differential equations (PDEs) are ubiquitous inscience and engineering. Recently, mostly due to the high computational cost oftraditional solution techniques, deep neural network based surrogates havegained increased interest. The practical utility of such neural PDE solversrelies on their ability to provide accurate, stable predictions over long timehorizons, which is a notoriously hard problem. In this work, we present alarge-scale analysis of common temporal rollout strategies, identifying theneglect of non-dominant spatial frequency information, often associated withhigh frequencies in PDE solutions, as the primary pitfall limiting stable,accurate rollout performance. Based on these insights, we draw inspiration fromrecent advances in diffusion models to introduce PDE-Refiner; a novel modelclass that enables more accurate modeling of all frequency components via amultistep refinement process. We validate PDE-Refiner on challenging benchmarksof complex fluid dynamics, demonstrating stable and accurate rollouts thatconsistently outperform state-of-the-art models, including neural, numerical,and hybrid neural-numerical architectures. We further demonstrate thatPDE-Refiner greatly enhances data efficiency, since the denoising objectiveimplicitly induces a novel form of spectral data augmentation. Finally,PDE-Refiner's connection to diffusion models enables an accurate and efficientassessment of the model's predictive uncertainty, allowing us to estimate whenthe surrogate becomes inaccurate.", "output": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although audio generation shares commonalities across different types ofaudio, such as speech, music, and sound effects, designing models for each typerequires careful consideration of specific objectives and biases that cansignificantly differ from those of other types. To bring us closer to a unifiedperspective of audio generation, this paper proposes a framework that utilizesthe same learning method for speech, music, and sound effect generation. Ourframework introduces a general representation of audio, called language ofaudio (LOA). Any audio can be translated into LOA based on AudioMAE, aself-supervised pre-trained representation learning model. In the generationprocess, we translate any modalities into LOA by using a GPT-2 model, and weperform self-supervised audio generation learning with a latent diffusion modelconditioned on LOA. The proposed framework naturally brings advantages such asin-context learning abilities and reusable self-supervised pretrained AudioMAEand latent diffusion models. Experiments on the major benchmarks oftext-to-audio, text-to-music, and text-to-speech demonstrate newstate-of-the-art or competitive performance to previous approaches. Our demoand code are available at ", "output": "AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recent proliferation of 3D content that can be consumed on hand-helddevices necessitates efficient tools for transmitting large geometric data,e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose achallenge to storage as well as transmission bandwidth, and level-of-detailtechniques are often used to transmit an asset using an appropriate bandwidthbudget. It is especially desirable for these methods to transmit dataprogressively, improving the quality of the geometry with more data. Our keyinsight is that the geometric details of 3D meshes often exhibit similar localpatterns even across different shapes, and thus can be effectively representedwith a shared learned generative space. We learn this space using asubdivision-based encoder-decoder architecture trained in advance on a largecollection of surfaces. We further observe that additional residual featurescan be transmitted progressively between intermediate levels of subdivisionthat enable the client to control the tradeoff between bandwidth cost andquality of reconstruction, providing a neural progressive mesh representation.We evaluate our method on a diverse set of complex 3D shapes and demonstratethat it outperforms baselines in terms of compression ratio and reconstructionquality.", "output": "Neural Progressive Meshes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning disentangled representations with variational autoencoders (VAEs) isoften attributed to the regularisation component of the loss. In this work, wehighlight the interaction between data and the reconstruction term of the lossas the main contributor to disentanglement in VAEs. We show that standardbenchmark datasets have unintended correlations between their subjectiveground-truth factors and perceived axes in the data according to typical VAEreconstruction losses. Our work exploits this relationship to provide a theoryfor what constitutes an adversarial dataset under a given reconstruction loss.We verify this by constructing an example dataset that prevents disentanglementin state-of-the-art frameworks while maintaining human-intuitive ground-truthfactors. Finally, we re-enable disentanglement by designing an examplereconstruction loss that is once again able to perceive the ground-truthfactors. Our findings demonstrate the subjective nature of disentanglement andthe importance of considering the interaction between the ground-truth factors,data and notably, the reconstruction loss, which is under-recognised in theliterature.", "output": "Overlooked Implications of the Reconstruction Loss for VAE Disentanglement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous navigation in agricultural environments is challenged by varyingfield conditions that arise in arable fields. State-of-the-art solutions forautonomous navigation in such environments require expensive hardware such asRTK-GNSS. This paper presents a robust crop row detection algorithm thatwithstands such field variations using inexpensive cameras. Existing datasetsfor crop row detection does not represent all the possible field variations. Adataset of sugar beet images was created representing 11 field variationscomprised of multiple grow stages, light levels, varying weed densities, curvedcrop rows and discontinuous crop rows. The proposed pipeline segments the croprows using a deep learning-based method and employs the predicted segmentationmask for extraction of the central crop using a novel central crop rowselection algorithm. The novel crop row detection algorithm was tested for croprow detection performance and the capability of visual servoing along a croprow. The visual servoing-based navigation was tested on a realistic simulationscenario with the real ground and plant textures. Our algorithm demonstratedrobust vision-based crop row detection in challenging field conditionsoutperforming the baseline.", "output": "Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The state-of-the-art predictive maintenance (PdM) techniques have shown greatsuccess in reducing maintenance costs and downtime of complicated machineswhile increasing overall productivity through extensive utilization ofInternet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors andDL algorithms are both prone to cyber-attacks. For instance, DL algorithms areknown for their susceptibility to adversarial examples. Such adversarialattacks are vastly under-explored in the PdM domain. This is because theadversarial attacks in the computer vision domain for classification taskscannot be directly applied to the PdM domain for multivariate time series (MTS)regression tasks. In this work, we propose an end-to-end methodology to designadversarially robust PdM systems by extensively analyzing the effect ofdifferent types of adversarial attacks and proposing a novel adversarialdefense technique for DL-enabled PdM models. First, we propose novel MTSProjected Gradient Descent (PGD) and MTS PGD with random restarts (PGD_r)attacks. Then, we evaluate the impact of MTS PGD and PGD_r along with MTS FastGradient Sign Method (FGSM) and MTS Basic Iterative Method (BIM) on LongShort-Term Memory (LSTM), Gated Recurrent Unit (GRU), Convolutional NeuralNetwork (CNN), and Bi-directional LSTM based PdM system. Our results usingNASA's turbofan engine dataset show that adversarial attacks can cause a severedefect (up to 11X) in the RUL prediction, outperforming the effectiveness ofthe state-of-the-art PdM attacks by 3X. Furthermore, we present a novelapproximate adversarial training method to defend against adversarial attacks.We observe that approximate adversarial training can significantly improve therobustness of PdM models (up to 54X) and outperforms the state-of-the-art PdMdefense methods by offering 3X more robustness.", "output": "RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The emergence of an AI-powered chatbot that can generate human-like sentencesand write coherent essays has caught the world's attention. This paperdiscusses the historical overview of chatbots and the technology behind ChatGenerative Pre-trained Transformer, better known as ChatGPT. Moreover,potential applications of ChatGPT in various domains, including healthcare,education, and research, are highlighted. Despite promising results, there areseveral privacy and ethical concerns surrounding ChatGPT. In addition, wehighlight some of the important limitations of the current version of ChatGPT.We also ask ChatGPT to provide its point of view and present its responses toseveral questions we attempt to answer.", "output": "Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As the use of machine learning continues to expand, the importance ofensuring its safety cannot be overstated. A key concern in this regard is theability to identify whether a given sample is from the training distribution,or is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries canmanipulate OOD samples in ways that lead a classifier to make a confidentprediction. In this study, we present a novel approach for certifying therobustness of OOD detection within a $ell_2$-norm around the input, regardlessof network architecture and without the need for specific components oradditional training. Further, we improve current techniques for detectingadversarial attacks on OOD samples, while providing high levels of certifiedand adversarial robustness on in-distribution samples. The average of all OODdetection metrics on CIFAR10/100 shows an increase of $sim 13 % / 5%$relative to previous approaches.", "output": "Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph neural network (GNN) models are increasingly being used for theclassification of electroencephalography (EEG) data. However, GNN-baseddiagnosis of neurological disorders, such as Alzheimer's disease (AD), remainsa relatively unexplored area of research. Previous studies have relied onfunctional connectivity methods to infer brain graph structures and used simpleGNN architectures for the diagnosis of AD. In this work, we propose a noveladaptive gated graph convolutional network (AGGCN) that can provide explainablepredictions. AGGCN adaptively learns graph structures by combiningconvolution-based node feature enhancement with a well-known correlation-basedmeasure of functional connectivity. Furthermore, the gated graph convolutioncan dynamically weigh the contribution of various spatial scales. The proposedmodel achieves high accuracy in both eyes-closed and eyes-open conditions,indicating the stability of learned representations. Finally, we demonstratethat the proposed AGGCN model generates consistent explanations of itspredictions that might be relevant for further study of AD-related alterationsof brain networks.", "output": "Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a neural network-based simulation super-resolution framework thatcan efficiently and realistically enhance a facial performance produced by alow-cost, realtime physics-based simulation to a level of detail that closelyapproximates that of a reference-quality off-line simulator with much higherresolution (26x element count in our examples) and accurate physical modeling.Our approach is rooted in our ability to construct - via simulation - atraining set of paired frames, from the low- and high-resolution simulatorsrespectively, that are in semantic correspondence with each other. We use faceanimation as an exemplar of such a simulation domain, where creating thissemantic congruence is achieved by simply dialing in the same muscle actuationcontrols and skeletal pose in the two simulators. Our proposed neural networksuper-resolution framework generalizes from this training set to unseenexpressions, compensates for modeling discrepancies between the two simulationsdue to limited resolution or cost-cutting approximations in the real-timevariant, and does not require any semantic descriptors or parameters to beprovided as input, other than the result of the real-time simulation. Weevaluate the efficacy of our pipeline on a variety of expressive performancesand provide comparisons and ablation experiments for plausible variations andalternatives to our proposed scheme.", "output": "Near-realtime Facial Animation by Deep 3D Simulation Super-Resolution."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in visual-language models have shown remarkable zero-shottext-image matching ability that is transferable to downstream tasks such asobject detection and segmentation. Adapting these models for object counting,however, remains a formidable challenge. In this study, we first investigatetransferring vision-language models (VLMs) for class-agnostic object counting.Specifically, we propose CLIP-Count, the first end-to-end pipeline thatestimates density maps for open-vocabulary objects with text guidance in azero-shot manner. To align the text embedding with dense visual features, weintroduce a patch-text contrastive loss that guides the model to learninformative patch-level visual representations for dense prediction. Moreover,we design a hierarchical patch-text interaction module to propagate semanticinformation across different resolution levels of visual features. Benefitingfrom the full exploitation of the rich image-text alignment knowledge ofpretrained VLMs, our method effectively generates high-quality density maps forobjects-of-interest. Extensive experiments on FSC-147, CARPK, and ShanghaiTechcrowd counting datasets demonstrate state-of-the-art accuracy andgeneralizability of the proposed method. Code is available:", "output": "CLIP-Count: Towards Text-Guided Zero-Shot Object Counting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This research project investigates Lenia, an artificial life platform thatsimulates ecosystems of digital creatures. Lenia's ecosystem consists ofsimple, artificial organisms that can move, consume, grow, and reproduce. Theplatform is important as a tool for studying artificial life and evolution, asit provides a scalable and flexible environment for creating a diverse range oforganisms with varying abilities and behaviors. Measuring complexity in Leniais a key aspect of the study, which identifies the metrics for measuringlong-term complex emerging behavior of rules, with the aim of evolving betterLenia behaviors which are yet not discovered. The Genetic Algorithm usesneighborhoods or kernels as genotype while keeping the rest of the parametersof Lenia as fixed, for example growth function, to produce different behaviorsrespective to the population and then measures fitness value to decide thecomplexity of the resulting behavior. First, we use Variation over Time as afitness function where higher variance between the frames are rewarded. Second,we use Auto-encoder based fitness where variation of the list of reconstructionloss for the frames is rewarded. Third, we perform combined fitness wherehigher variation of the pixel density of reconstructed frames is rewarded. Allthree experiments are tweaked with pixel alive threshold and frames used.Finally, after performing nine experiments of each fitness for 500 generations,we pick configurations from all experiments such that there is a scope offurther evolution, and run it for 2500 generations. Results show that thekernel's center of mass increases with a specific set of pixels and togetherwith borders the kernel try to achieve a Gaussian distribution. Results areavailable at ", "output": "Capturing Emerging Complexity in Lenia."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement Learning (RL), bolstered by the expressive capabilities of DeepNeural Networks (DNNs) for function approximation, has demonstratedconsiderable success in numerous applications. However, its practicality inaddressing various real-world scenarios, characterized by diverse andunpredictable dynamics, noisy signals, and large state and action spaces,remains limited. This limitation stems from issues such as poor dataefficiency, limited generalization capabilities, a lack of safety guarantees,and the absence of interpretability, among other factors. To overcome thesechallenges and improve performance across these crucial metrics, one promisingavenue is to incorporate additional structural information about the probleminto the RL learning process. Various sub-fields of RL have proposed methodsfor incorporating such inductive biases. We amalgamate these diversemethodologies under a unified framework, shedding light on the role ofstructure in the learning problem, and classify these methods into distinctpatterns of incorporating structure. By leveraging this comprehensiveframework, we provide valuable insights into the challenges of structured RLand lay the groundwork for a design pattern perspective on RL research. Thisnovel perspective paves the way for future advancements and aids in developingmore effective and efficient RL algorithms that can potentially handlereal-world scenarios better.", "output": "Structure in Reinforcement Learning: A Survey and Open Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (DA) with the aid of pseudo labelingtechniques has emerged as a crucial approach for domain-adaptive 3D objectdetection. While effective, existing DA methods suffer from a substantial dropin performance when applied to a multi-class training setting, due to theco-existence of low-quality pseudo labels and class imbalance issues. In thispaper, we address this challenge by proposing a novel ReDB framework tailoredfor learning to detect all classes at once. Our approach produces Reliable,Diverse, and class-Balanced pseudo 3D boxes to iteratively guide theself-training on a distributionally different target domain. To alleviatedisruptions caused by the environmental discrepancy (e.g., beam numbers), theproposed cross-domain examination (CDE) assesses the correctness of pseudolabels by copy-pasting target instances into a source environment and measuringthe prediction consistency. To reduce computational overhead and mitigate theobject shift (e.g., scales and point densities), we design an overlapped boxescounting (OBC) metric that allows to uniformly downsample pseudo-labeledobjects across different geometric characteristics. To confront the issue ofinter-class imbalance, we progressively augment the target point clouds with aclass-balanced set of pseudo-labeled target instances and source objects, whichboosts recognition accuracies on both frequently appearing and rare classes.Experimental results on three benchmark datasets using both voxel-based (i.e.,SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that ourproposed ReDB approach outperforms existing 3D domain adaptation methods by alarge margin, improving 23.15% mAP on the nuScenes $rightarrow$ KITTI task.The code is available at ", "output": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper details the challenges in applying two computer vision systems, anEfficientDET supervised learning model and the unsupervised RX spectralclassifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search andrescue (WSAR) effort in Japan and identifies 3 directions for future research.There have been at least 19 proposed approaches and 3 datasets aimed atlocating missing persons in drone imagery, but only 3 approaches (2unsupervised and 1 of an unknown structure) are referenced in the literature ashaving been used in an actual WSAR operation. Of these proposed approaches, theEfficientDET architecture and the unsupervised spectral RX classifier wereselected as the most appropriate for this setting. The EfficientDET model wasapplied to the HERIDAL dataset and despite achieving performance that isstatistically equivalent to the state-of-the-art, the model fails to translateto the real world in terms of false positives (e.g., identifying tree limbs androcks as people), and false negatives (e.g., failing to identify members of thesearch team). The poor results in practice for algorithms that showed goodresults on datasets suggest 3 areas of future research: more realistic datasetsfor wilderness SAR, computer vision models that are capable of seamlesslyhandling the variety of imagery that can be collected during actual WSARoperations, and better alignment on performance measures.", "output": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent research in language-guided visual navigation has demonstrated asignificant demand for the diversity of traversable environments and thequantity of supervision for training generalizable agents. To tackle the commondata scarcity issue in existing vision-and-language navigation datasets, wepropose an effective paradigm for generating large-scale data for learning,which applies 1200+ photo-realistic environments from HM3D and Gibson datasetsand synthesizes 4.9 million instruction trajectory pairs using fully-accessibleresources on the web. Importantly, we investigate the influence of eachcomponent in this paradigm on the agent's performance and study how toadequately apply the augmented data to pre-train and fine-tune an agent. Thanksto our large-scale dataset, the performance of an existing agent can be pushedup (+11% absolute with regard to previous SoTA) to a significantly new best of80% single-run success rate on the R2R test split by simple imitation learning.The long-lasting generalization gap between navigating in seen and unseenenvironments is also reduced to less than 1% (versus 8% in the previous bestmethod). Moreover, our paradigm also facilitates different models to achievenew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuousenvironments.", "output": "Scaling Data Generation in Vision-and-Language Navigation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Over the last decade, Q&amp;A platforms have played a crucial role in howprogrammers seek help online. The emergence of ChatGPT, however, is causing ashift in this pattern. Despite ChatGPT's popularity, there hasn't been athorough investigation into the quality and usability of its responses tosoftware engineering queries. To address this gap, we undertook a comprehensiveanalysis of ChatGPT's replies to 517 questions from Stack Overflow (SO). Weassessed the correctness, consistency, comprehensiveness, and conciseness ofthese responses. Additionally, we conducted an extensive linguistic analysisand a user study to gain insights into the linguistic and human aspects ofChatGPT's answers. Our examination revealed that 52% of ChatGPT's answerscontain inaccuracies and 77% are verbose. Nevertheless, users still preferChatGPT's responses 39.34% of the time due to their comprehensiveness andarticulate language style. These findings underscore the need for meticulouserror correction in ChatGPT while also raising awareness among users about thepotential risks associated with seemingly accurate answers.", "output": "Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ocean modeling is a powerful tool for simulating the physical, chemical, andbiological processes of the ocean, which is the foundation for marine scienceresearch and operational oceanography. Modern numerical ocean modeling mainlyconsists of governing equations and numerical algorithms. Nonlinearinstability, computational expense, low reusability efficiency and highcoupling costs have gradually become the main bottlenecks for the furtherdevelopment of numerical ocean modeling. Recently, artificialintelligence-based modeling in scientific computing has shown revolutionarypotential for digital twins and scientific simulations, but the bottlenecks ofnumerical ocean modeling have not been further solved. Here, we presentAI-GOMS, a large AI-driven global ocean modeling system, for accurate andefficient global ocean daily prediction. AI-GOMS consists of a backbone modelwith the Fourier-based Masked Autoencoder structure for basic ocean variableprediction and lightweight fine-tuning models incorporating regionaldownscaling, wave decoding, and biochemistry coupling modules. AI-GOMS hasachieved the best performance in 30 days of prediction for the global oceanbasic variables with 15 depth layers at 1/4{deg} spatial resolution. Beyondthe good performance in statistical metrics, AI-GOMS realizes the simulation ofmesoscale eddies in the Kuroshio region at 1/12{deg} spatial resolution andocean stratification in the tropical Pacific Ocean. AI-GOMS provides a newbackbone-downstream paradigm for Earth system modeling, which makes the systemtransferable, scalable and reusable.", "output": "AI-GOMS: Large AI-Driven Global Ocean Modeling System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Online violence against children has increased globally recently, demandingurgent attention. Competent authorities manually analyze abuse complaints tocomprehend crime dynamics and identify patterns. However, the manual analysisof these complaints presents a challenge because it exposes analysts to harmfulcontent during the review process. Given these challenges, we present a novelsolution, an automated tool designed to analyze children's sexual abuse reportscomprehensively. By automating the analysis process, our tool significantlyreduces the risk of exposure to harmful content by categorizing the reports onthree dimensions: Subject, Degree of Criminality, and Damage. Furthermore,leveraging our multidisciplinary team's expertise, we introduce a novelapproach to annotate the collected data, enabling a more in-depth analysis ofthe reports. This approach improves the comprehension of fundamental patternsand trends, enabling law enforcement agencies and policymakers to createfocused strategies in the fight against children's violence.", "output": "Guarding the Guardians: Automated Analysis of Online Child Sexual Abuse."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing approaches to understanding, developing and researching modernwireless communication technologies involves time-intensive and arduous processof sifting through numerous webpages and technical specification documents,gathering the required information and synthesizing it. This paper presentsNextGen Communications Copilot, a conversational artificial intelligence toolfor information synthesis of wireless communication specifications. The systembuilds on top of recent advancements in foundation models and consists of threekey additional components: a domain-specific database, a context extractor, anda feedback mechanism. The system appends user queries with concise andquery-dependent contextual information extracted from a database of wirelesstechnical specifications and incorporates tools for expert feedback and datacontributions. On evaluation using a benchmark dataset of queries and referenceresponses created by subject matter experts, the system demonstrated morerelevant and accurate answers with an average BLEU score and BERTScoreF1-measure of 0.37 and 0.79 respectively compared to the corresponding valuesof 0.07 and 0.59 achieved by state-of-the-art tools like ChatGPT.", "output": "Adapting Foundation Models for Information Synthesis of Wireless Communication Specifications."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "At the Worldwide Developers Conference (WWDC) in June 2023, Apple introducedthe Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, morespecifically it is a Virtual Reality (VR) device with an additional VideoSee-Through (VST) capability. The VST capability turns the Vision Pro also intoan Augmented Reality (AR) device. The AR feature is enabled by streaming thereal world via cameras to the (VR) screens in front of the user's eyes. This isof course not unique and similar to other devices, like the Varjo XR-3.Nevertheless, the Vision Pro has some interesting features, like an inside-outscreen that can show the headset wearers' eyes to \"outsiders\" or a button onthe top, called \"Digital Crown\", that allows you to seamlessly blend digitalcontent with your physical space by turning it. In addition, it is untethered,except for the cable to the battery, which makes the headset more agile,compared to the Varjo XR-3. This could actually come closer to the \"UltimateDisplay\", which Ivan Sutherland had already sketched in 1965. Not available tothe public yet, like the Ultimate Display, we want to take a look into thecrystal ball in this perspective to see if it can overcome some clinicalchallenges that - especially - AR still faces in the medical domain, but alsogo beyond and discuss if the Vision Pro could support clinicians in essentialtasks to spend more time with their patients.", "output": "Apple Vision Pro for Healthcare: \"The Ultimate Display\"? -- Entering the Wonderland of Precision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While language models are powerful and versatile, they often fail to addresshighly complex problems. This is because solving complex problems requiresdeliberate thinking, which has been only minimally guided during training. Inthis paper, we propose a new method called Cumulative Reasoning (CR), whichemploys language models in a cumulative and iterative manner to emulate humanthought processes. By decomposing tasks into smaller components, CR streamlinesthe problem-solving process, rendering it both more manageable and effective.For logical inference tasks, CR consistently outperforms existing methods withan improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% onthe curated FOLIO wiki dataset. In the context of the Game of 24, CR achievesan accuracy of 94%, which signifies a substantial enhancement of 20% over theprevious state-of-the-art method (code is available at", "output": "Cumulative Reasoning with Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot SemanticSegmentation (FSS) to simultaneously segment unseen classes and seen classesduring evaluation. Previous works leverage additional branch or prototypicalaggregation to eliminate the constrained setting of FSS. However,representation division and embedding prejudice, which heavily results in poorperformance of GFSS, have not been synthetical considered. We address theaforementioned problems by jointing the prototypical kernel learning andopen-set foreground perception. Specifically, a group of learnable kernels isproposed to perform segmentation with each kernel in charge of a stuff class.Then, we explore to merge the prototypical learning to the update of base-classkernels, which is consistent with the prototype knowledge aggregation offew-shot novel classes. In addition, a foreground contextual perception modulecooperating with conditional bias based inference is adopted to performclass-agnostic as well as open-set foreground detection, thus to mitigate theembedding prejudice and prevent novel targets from being misclassified asbackground. Moreover, we also adjust our method to the Class IncrementalFew-shot Semantic Segmentation (CIFSS) which takes the knowledge of novelclasses in a incremental stream. Extensive experiments on PASCAL-5i andCOCO-20i datasets demonstrate that our method performs better than previousstate-of-the-art.", "output": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Lesion segmentation of ultrasound medical images based on deep learningtechniques is a widely used method for diagnosing diseases. Although there is alarge amount of ultrasound image data in medical centers and other places,labeled ultrasound datasets are a scarce resource, and it is likely that nodatasets are available for new tissues/organs. Transfer learning provides thepossibility to solve this problem, but there are too many features in naturalimages that are not related to the target domain. As a source domain, redundantfeatures that are not conducive to the task will be extracted. Migrationbetween ultrasound images can avoid this problem, but there are few types ofpublic datasets, and it is difficult to find sufficiently similar sourcedomains. Compared with natural images, ultrasound images have less information,and there are fewer transferable features between different ultrasound images,which may cause negative transfer. To this end, a multi-source adversarialtransfer learning network for ultrasound image segmentation is proposed.Specifically, to address the lack of annotations, the idea of adversarialtransfer learning is used to adaptively extract common features between acertain pair of source and target domains, which provides the possibility toutilize unlabeled ultrasound data. To alleviate the lack of knowledge in asingle source domain, multi-source transfer learning is adopted to fuseknowledge from multiple source domains. In order to ensure the effectiveness ofthe fusion and maximize the use of precious data, a multi-source domainindependent strategy is also proposed to improve the estimation of the targetdomain data distribution, which further increases the learning ability of themulti-source adversarial migration learning network in multiple domains.", "output": "Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an investigation into machine learning techniques forviolence detection in videos and their adaptation to a federated learningcontext. The study includes experiments with spatio-temporal features extractedfrom benchmark video datasets, comparison of different methods, and proposal ofa modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\"Additionally, various machine learning techniques, including super-convergenceand transfer learning, are explored, and a method for adapting centralizeddatasets to a federated learning context is developed. The research achievesbetter accuracy results compared to state-of-the-art models by training thebest violence detection model in a federated learning context.", "output": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a technique for efficiently modeling dynamic humans byexplicifying the implicit neural fields via a Neural Explicit Surface (NES).Implicit neural fields have advantages over traditional explicitrepresentations in modeling dynamic 3D content from sparse observations andeffectively representing complex geometries and appearances. Implicit neuralfields defined in 3D space, however, are expensive to render due to the needfor dense sampling during volumetric rendering. Moreover, their memoryefficiency can be further optimized when modeling sparse 3D space. To overcomethese issues, the paper proposes utilizing Neural Explicit Surface (NES) toexplicitly represent implicit neural fields, facilitating memory andcomputational efficiency. To achieve this, the paper creates a fullydifferentiable conversion between the implicit neural fields and the explicitrendering interface of NES, leveraging the strengths of both implicit andexplicit approaches. This conversion enables effective training of the hybridrepresentation using implicit methods and efficient rendering by integratingthe explicit rendering interface with a newly proposed rasterization-basedneural renderer that only incurs a texture color query once for the initial rayinteraction with the explicit surface, resulting in improved inferenceefficiency. NES describes dynamic human geometries with pose-dependent neuralimplicit surface deformation fields and their dynamic neural textures both in2D space, which is a more memory-efficient alternative to traditional 3Dmethods, reducing redundancy and computational load. The comprehensiveexperiments show that NES performs similarly to previous 3D approaches, withgreatly improved rendering speed and reduced memory cost.", "output": "Explicifying Neural Implicit Fields for Efficient Dynamic Human Avatar Modeling via a Neural Explicit Surface."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The multifactorial etiology of autism spectrum disorder (ASD) suggests thatits study would benefit greatly from multimodal approaches that combine datafrom widely varying platforms, e.g., neuroimaging, genetics, and clinicalcharacterization. Prior neuroimaging-genetic analyses often apply naive featureconcatenation approaches in data-driven work or use the findings from onemodality to guide posthoc analysis of another, missing the opportunity toanalyze the paired multimodal data in a truly unified approach. In this paper,we develop a more integrative model for combining genetic, demographic, andneuroimaging data. Inspired by the influence of genotype on phenotype, wepropose using an attention-based approach where the genetic data guidesattention to neuroimaging features of importance for model prediction. Thegenetic data is derived from copy number variation parameters, while theneuroimaging data is from functional magnetic resonance imaging. We evaluatethe proposed approach on ASD classification and severity prediction tasks,using a sex-balanced dataset of 228 ASD and typically developing subjects in a10-fold cross-validation framework. We demonstrate that our attention-basedmodel combining genetic information, demographic data, and functional magneticresonance imaging results in superior prediction performance compared to othermultimodal approaches.", "output": "Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Manually grading structural changes with the modified Stoke AnkylosingSpondylitis Spinal Score (mSASSS) on spinal X-ray imaging is costly andtime-consuming due to bone shape complexity and image quality variations. Inthis study, we address this challenge by prototyping a 2-step auto-gradingpipeline, called VertXGradeNet, to automatically predict mSASSS scores for thecervical and lumbar vertebral units (VUs) in X-ray spinal imaging. TheVertXGradeNet utilizes VUs generated by our previously developed VU extractionpipeline (VertXNet) as input and predicts mSASSS based on those VUs.VertXGradeNet was evaluated on an in-house dataset of lateral cervical andlumbar X-ray images for axial spondylarthritis patients. Our results show thatVertXGradeNet can predict the mSASSS score for each VU when the data is limitedin quantity and imbalanced. Overall, it can achieve a balanced accuracy of 0.56and 0.51 for 4 different mSASSS scores (i.e., a score of 0, 1, 2, 3) on twotest datasets. The accuracy of the presented method shows the potential tostreamline the spinal radiograph readings and therefore reduce the cost offuture clinical trials.", "output": "Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A significant number of machine learning models are vulnerable to modelextraction attacks, which focus on stealing the models by using speciallycurated queries against the target model. This task is well accomplished byusing part of the training data or a surrogate dataset to train a new modelthat mimics a target model in a white-box environment. In pragmatic situations,however, the target models are trained on private datasets that areinaccessible to the adversary. The data-free model extraction techniquereplaces this problem when it comes to using queries artificially curated by agenerator similar to that used in Generative Adversarial Nets. We propose forthe first time, to the best of our knowledge, an adversary black box attackextending to a regression problem for predicting bounding box coordinates inobject detection. As part of our study, we found that defining a loss functionand using a novel generator setup is one of the key aspects in extracting thetarget model. We find that the proposed model extraction method achievessignificant results by using reasonable queries. The discovery of this objectdetection vulnerability will support future prospects for securing such models.", "output": "Data-Free Model Extraction Attacks in the Context of Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we parallelize high-level features in deep networks toselectively skip or select class-specific features to reduce inference costs.This challenges most deep learning methods due to their limited ability toefficiently and effectively focus on selected class-specific features withoutretraining. We propose a serial-parallel hybrid architecture with serialgeneric low-level features and parallel high-level features. This accounts forthe fact that many high-level features are class-specific rather than generic,and has connections to recent neuroscientific findings that observe spatiallyand contextually separated neural activations in the human brain. Our approachprovides the unique functionality of cutouts: selecting parts of the network tofocus on only relevant subsets of classes without requiring retraining. Highperformance is maintained, but the cost of inference can be significantlyreduced. In some of our examples, up to $75,%$ of parameters are skipped and$35,%$ fewer GMACs (Giga multiply-accumulate) operations are used as theapproach adapts to a change in task complexity. This is important for mobile,industrial, and robotic applications where reducing the number of parameters,the computational complexity, and thus the power consumption can be paramount.Another unique functionality is that it allows processing to be directlyinfluenced by enhancing or inhibiting high-level class-specific features,similar to the mechanism of selective attention in the human brain. This can berelevant for cross-modal applications, the use of semantic prior knowledge,and/or context-aware processing.", "output": "High-Level Features Parallelization for Inference Cost Reduction Through Selective Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While many studies have assessed the fairness of AI algorithms in the medicalfield, the causes of differences in prediction performance are often unknown.This lack of knowledge about the causes of bias hampers the efficacy of biasmitigation, as evidenced by the fact that simple dataset balancing still oftenperforms best in reducing performance gaps but is unable to resolve allperformance differences. In this work, we investigate the causes of gender biasin machine learning-based chest X-ray diagnosis. In particular, we explore thehypothesis that breast tissue leads to underexposure of the lungs and causeslower model performance. Methodologically, we propose a new sampling methodwhich addresses the highly skewed distribution of recordings per patient in twowidely used public datasets, while at the same time reducing the impact oflabel errors. Our comprehensive analysis of gender differences across diseases,datasets, and gender representations in the training set shows that datasetimbalance is not the sole cause of performance differences. Moreover, relativegroup performance differs strongly between datasets, indicating importantdataset-specific factors influencing male/female group performance. Finally, weinvestigate the effect of breast tissue more specifically, by cropping out thebreasts from recordings, finding that this does not resolve the observedperformance gaps. In conclusion, our results indicate that dataset-specificfactors, not fundamental physiological differences, are the main drivers ofmale--female performance gaps in chest X-ray analyses on widely used NIH andCheXpert Dataset.", "output": "Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Weakly supervised methods, such as class activation maps (CAM) based, havebeen applied to achieve bleeding segmentation with low annotation efforts inWireless Capsule Endoscopy (WCE) images. However, the CAM labels tend to beextremely noisy, and there is an irreparable gap between CAM labels and groundtruths for medical images. This paper proposes a new Discrepancy-basEd ActiveLearning (DEAL) approach to bridge the gap between CAMs and ground truths witha few annotations. Specifically, to liberate labor, we design a noveldiscrepancy decoder model and a CAMPUS (CAM, Pseudo-label and groUnd-truthSelection) criterion to replace the noisy CAMs with accurate model predictionsand a few human labels. The discrepancy decoder model is trained with a uniquescheme to generate standard, coarse and fine predictions. And the CAMPUScriterion is proposed to predict the gaps between CAMs and ground truths basedon model divergence and CAM divergence. We evaluate our method on the WCEdataset and results show that our method outperforms the state-of-the-artactive learning methods and reaches comparable performance to those trainedwith full annotated datasets with only 10% of the training data labeled.", "output": "Discrepancy-based Active Learning for Weakly Supervised Bleeding Segmentation in Wireless Capsule Endoscopy Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object modeling has become a core part of recent tracking frameworks. Currentpopular tackers use Transformer attention to extract the template featureseparately or interactively with the search region. However, separate templatelearning lacks communication between the template and search regions, whichbrings difficulty in extracting discriminative target-oriented features. On theother hand, interactive template learning produces hybrid template features,which may introduce potential distractors to the template via the clutteredsearch regions. To enjoy the merits of both methods, we propose a robust objectmodeling framework for visual tracking (ROMTrack), which simultaneously modelsthe inherent template and the hybrid template features. As a result, harmfuldistractors can be suppressed by combining the inherent features of targetobjects with search regions' guidance. Target-related features can also beextracted using the hybrid template, thus resulting in a more robust objectmodeling framework. To further enhance robustness, we present novel variationtokens to depict the ever-changing appearance of target objects. Variationtokens are adaptable to object deformation and appearance variations, which canboost overall performance with negligible computation. Experiments show thatour ROMTrack sets a new state-of-the-art on multiple benchmarks.", "output": "Robust Object Modeling for Visual Tracking."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The present work discusses the use of a weakly-supervised deep learningalgorithm that reduces the cost of labelling pixel-level masks for complexradio galaxies with multiple components. The algorithm is trained on weakclass-level labels of radio galaxies to get class activation maps (CAMs). TheCAMs are further refined using an inter-pixel relations network (IRNet) to getinstance segmentation masks over radio galaxies and the positions of theirinfrared hosts. We use data from the Australian Square Kilometre ArrayPathfinder (ASKAP) telescope, specifically the Evolutionary Map of the Universe(EMU) Pilot Survey, which covered a sky area of 270 square degrees with an RMSsensitivity of 25-35 $mu$Jy/beam. We demonstrate that weakly-supervised deeplearning algorithms can achieve high accuracy in predicting pixel-levelinformation, including masks for the extended radio emission encapsulating allgalaxy components and the positions of the infrared host galaxies. We evaluatethe performance of our method using mean Average Precision (mAP) acrossmultiple classes at a standard intersection over union (IoU) threshold of 0.5.We show that the model achieves a mAP$_{50}$ of 67.5% and 76.8% for radiomasks and infrared host positions, respectively. The network architecture canbe found at the following link: ", "output": "Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Existing model evaluation tools mainly focus on evaluating classificationmodels, leaving a gap in evaluating more complex models, such as objectdetection. In this paper, we develop an open-source visual analysis tool,Uni-Evaluator, to support a unified model evaluation for classification, objectdetection, and instance segmentation in computer vision. The key idea behindour method is to formulate both discrete and continuous predictions indifferent tasks as unified probability distributions. Based on thesedistributions, we develop 1) a matrix-based visualization to provide anoverview of model performance; 2) a table visualization to identify theproblematic data subsets where the model performs poorly; 3) a gridvisualization to display the samples of interest. These visualizations worktogether to facilitate the model evaluation from a global overview toindividual samples. Two case studies demonstrate the effectiveness ofUni-Evaluator in evaluating model performance and making informed improvements.", "output": "A Unified Interactive Model Evaluation for Classification, Object Detection, and Instance Segmentation in Computer Vision."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Diabetic Retinopathy (DR) is an ocular condition caused by a sustained highlevel of sugar in the blood, which causes the retinal capillaries to block andbleed, causing retinal tissue damage. It usually results in blindness. Earlydetection can help in lowering the risk of DR and its severity. The robust andaccurate prediction and detection of diabetic retinopathy is a challengingtask. This paper develops a machine learning model for detecting DiabeticRetinopathy that is entirely accurate. Pre-trained models such as ResNet50,InceptionV3, Xception, DenseNet121, VGG19, NASNetMobile, MobileNetV2,DensNet169, and DenseNet201 with pooling layer, dense layer, and appropriatedropout layer at the bottom of them were carried out in transfer learning (TL)approach. Data augmentation and regularization was performed to reduceoverfitting. Transfer Learning model of DenseNet121, Average and weightedensemble of DenseNet169 and DenseNet201 TL architectures contributeindividually the highest accuracy of 100%, the highest precision, recall, F-1score of 100%, 100%, and 100%, respectively.", "output": "An Improved Model for Diabetic Retinopathy Detection by using Transfer Learning and Ensemble Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In certain Asian countries, Jute is one of the primary sources of income andGross Domestic Product (GDP) for the agricultural sector. Like many othercrops, Jute is prone to pest infestations, and its identification is typicallymade visually in countries like Bangladesh, India, Myanmar, and China. Inaddition, this method is time-consuming, challenging, and somewhat imprecise,which poses a substantial financial risk. To address this issue, the studyproposes a high-performing and resilient transfer learning (TL) basedJutePestDetect model to identify jute pests at the early stage. Firstly, weprepared jute pest dataset containing 17 classes and around 380 photos per pestclass, which were evaluated after manual and automatic pre-processing andcleaning, such as background removal and resizing. Subsequently, five prominentpre-trained models -DenseNet201, InceptionV3, MobileNetV2, VGG19, and ResNet50were selected from a previous study to design the JutePestDetect model. Eachmodel was revised by replacing the classification layer with a global averagepooling layer and incorporating a dropout layer for regularization. To evaluatethe models performance, various metrics such as precision, recall, F1 score,ROC curve, and confusion matrix were employed. These analyses providedadditional insights for determining the efficacy of the models. Among them, thecustomized regularized DenseNet201-based proposed JutePestDetect modeloutperformed the others, achieving an impressive accuracy of 99%. As a result,our proposed method and strategy offer an enhanced approach to pestidentification in the case of Jute, which can significantly benefit farmersworldwide.", "output": "JutePestDetect: An Intelligent Approach for Jute Pest Identification Using Fine-Tuned Transfer Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This PhD. Thesis concerns the study and development of hierarchicalrepresentations for spatio-temporal visual attention modeling and understandingin video sequences. More specifically, we propose two computational models forvisual attention. First, we present a generative probabilistic model forcontext-aware visual attention modeling and understanding. Secondly, we developa deep network architecture for visual attention modeling, which firstestimates top-down spatio-temporal visual attention, and ultimately serves formodeling attention in the temporal domain.", "output": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Surgical instrument segmentation is recognised as a key enabler to provideadvanced surgical assistance and improve computer assisted interventions. Inthis work, we propose SegMatch, a semi supervised learning method to reduce theneed for expensive annotation for laparoscopic and robotic surgical images.SegMatch builds on FixMatch, a widespread semi supervised classificationpipeline combining consistency regularization and pseudo labelling, and adaptsit for the purpose of segmentation. In our proposed SegMatch, the unlabelledimages are weakly augmented and fed into the segmentation model to generate apseudo-label to enforce the unsupervised loss against the output of the modelfor the adversarial augmented image on the pixels with a high confidence score.Our adaptation for segmentation tasks includes carefully considering theequivariance and invariance properties of the augmentation functions we relyon. To increase the relevance of our augmentations, we depart from using onlyhandcrafted augmentations and introduce a trainable adversarial augmentationstrategy. Our algorithm was evaluated on the MICCAI Instrument SegmentationChallenge datasets Robust-MIS 2019 and EndoVis 2017. Our results demonstratethat adding unlabelled data for training purposes allows us to surpass theperformance of fully supervised approaches which are limited by theavailability of training data in these challenges. SegMatch also outperforms arange of state-of-the-art semi-supervised learning semantic segmentation modelsin different labelled to unlabelled data ratios.", "output": "SegMatch: A semi-supervised learning method for surgical instrument segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Environmental perception is a key element of autonomous driving because theinformation received from the perception module influences core drivingdecisions. An outstanding challenge in real-time perception for autonomousdriving lies in finding the best trade-off between detection quality andlatency. Major constraints on both computation and power have to be taken intoaccount for real-time perception in autonomous vehicles. Larger objectdetection models tend to produce the best results, but are also slower atruntime. Since the most accurate detectors cannot run in real-time locally, weinvestigate the possibility of offloading computation to edge and cloudplatforms, which are less resource-constrained. We create a synthetic datasetto train object detection models and evaluate different offloading strategies.Using real hardware and network simulations, we compare different trade-offsbetween prediction quality and end-to-end delay. Since sending raw frames overthe network implies additional transmission delays, we also explore the use ofJPEG and H.265 compression at varying qualities and measure their impact onprediction metrics. We show that models with adequate compression can be run inreal-time on the cloud while outperforming local detection performance.", "output": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional Neural Networks (CNNs) are models that are utilized extensivelyfor the hierarchical extraction of features. Vision transformers (ViTs),through the use of a self-attention mechanism, have recently achieved superiormodeling of global contextual information compared to CNNs. However, to realizetheir image classification strength, ViTs require substantial trainingdatasets. Where the available training data are limited, current advancedmulti-layer perceptrons (MLPs) can provide viable alternatives to both deepCNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithmthat effectively uses both MLPs and spatial gating units (SGUs) for preciseland use land cover (LULC) mapping. Results illustrated the superiority of thedeveloped SGU-MLP classification algorithm over several CNN and CNN-ViT-basedmodels, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. Theproposed SGU-MLP algorithm was tested through three experiments in Houston,USA, Berlin, Germany and Augsburg, Germany. The SGU-MLP classification modelwas found to consistently outperform the benchmark CNN and CNN-ViT-basedalgorithms. For example, for the Houston experiment, SGU-MLP significantlyoutperformed HybridSN, CoAtNet, Efficientformer, iFormer and ResNet byapproximately 15%, 19%, 20%, 21%, and 25%, respectively, in terms of averageaccuracy. The code will be made publicly available at", "output": "Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study performs an ablation analysis of Vector Quantized GenerativeAdversarial Networks (VQGANs), concentrating on image-to-image synthesisutilizing a single NVIDIA A100 GPU. The current work explores the nuancedeffects of varying critical parameters including the number of epochs, imagecount, and attributes of codebook vectors and latent dimensions, specificallywithin the constraint of limited resources. Notably, our focus is pinpointed onthe vector quantization loss, keeping other hyperparameters and loss components(GAN loss) fixed. This was done to delve into a deeper understanding of thediscrete latent space, and to explore how varying its size affects thereconstruction. Though, our results do not surpass the existing benchmarks,however, our findings shed significant light on VQGAN's behaviour for a smallerdataset, particularly concerning artifacts, codebook size optimization, andcomparative analysis with Principal Component Analysis (PCA). The study alsouncovers the promising direction by introducing 2D positional encodings,revealing a marked reduction in artifacts and insights into balancing clarityand overfitting.", "output": "Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Aphids are efficient vectors to transmit virus yellows in sugar beet fields.Timely monitoring and control of their populations are thus critical to preventthe large-scale outbreak of virus yellows. However, the manual counting ofaphids, which is the most common practice, is labor-intensive andtime-consuming. Additionally, two of the biggest challenges in aphid countingare that aphids are small objects and their density distributions are varied indifferent areas of the field. To address these challenges, we proposed a hybridautomatic aphid counting network architecture which integrates the detectionnetwork and the density map estimation network. When the distribution densityof aphids is low, it utilizes an improved Yolov5 to count aphids. Conversely,when the distribution density of aphids is high, its witches to CSRNet to countaphids. To the best of our knowledge, this is the first framework integratingthe detection network and the density map estimation network for countingtasks. Through comparison experiments of counting aphids, it verified that ourproposed approach outperforms all other methods in counting aphids. It achievedthe lowest MAE and RMSE values for both the standard and high-density aphiddatasets: 2.93 and 4.01 (standard), and 34.19 and 38.66 (high-density),respectively. Moreover, the AP of the improved Yolov5 is 5% higher than that ofthe original Yolov5. Especially for extremely small aphids and denselydistributed aphids, the detection performance of the improved Yolov5 issignificantly better than the original Yolov5. This work provides an effectiveearly warning for the virus yellows risk caused by aphids in sugar beet fields,offering protection for sugar beet growth and ensuring sugar beet yield. Thedatasets and project code are released at:", "output": "Advancing Early Detection of Virus Yellows: Developing a Hybrid Convolutional Neural Network for Automatic Aphid Counting in Sugar Beet Fields."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The evaluation datasets and metrics for image manipulation detection andlocalization (IMDL) research have been standardized. But the training datasetfor such a task is still nonstandard. Previous researchers have usedunconventional and deviating datasets to train neural networks for detectingimage forgeries and localizing pixel maps of manipulated regions. For a faircomparison, the training set, test set, and evaluation metrics should bepersistent. Hence, comparing the existing methods may not seem fair as theresults depend heavily on the training datasets as well as the modelarchitecture. Moreover, none of the previous works release the synthetictraining dataset used for the IMDL task. We propose a standardized benchmarktraining dataset for image splicing, copy-move forgery, removal forgery, andimage enhancement forgery. Furthermore, we identify the problems with theexisting IMDL datasets and propose the required modifications. We also trainthe state-of-the-art IMDL methods on our proposed TrainFors1 dataset for a fairevaluation and report the actual performance of these methods under similarconditions.", "output": "TrainFors: A Large Benchmark Training Dataset for Image Manipulation Detection and Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The task of dynamic scene graph generation (DynSGG) aims to generate scenegraphs for given videos, which involves modeling the spatial-temporalinformation in the video. However, due to the long-tailed distribution ofsamples in the dataset, previous DynSGG models fail to predict the tailpredicates. We argue that this phenomenon is due to previous methods that onlypay attention to the local spatial-temporal information and neglect theconsistency of multiple frames. To solve this problem, we propose a novelDynSGG model based on multi-task learning, DynSGG-MTL, which introduces thelocal interaction information and global human-action interaction information.The interaction between objects and frame features makes the model more fullyunderstand the visual context of the single image. Long-temporal human actionssupervise the model to generate multiple scene graphs that conform to theglobal constraints and avoid the model being unable to learn the tailpredicates. Extensive experiments on Action Genome dataset demonstrate theefficacy of our proposed framework, which not only improves the dynamic scenegraph generation but also alleviates the long-tail problem.", "output": "Local-Global Information Interaction Debiasing for Dynamic Scene Graph Generation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Scene graph generation aims to detect visual relationship triplets, (subject,predicate, object). Due to biases in data, current models tend to predictcommon predicates, e.g. \"on\" and \"at\", instead of informative ones, e.g.\"standing on\" and \"looking at\". This tendency results in the loss of preciseinformation and overall performance. If a model only uses \"stone on road\"rather than \"stone blocking road\" to describe an image, it may be a gravemisunderstanding. We argue that this phenomenon is caused by two imbalances:semantic space level imbalance and training sample level imbalance. For thisproblem, we propose DB-SGG, an effective framework based on debiasing but notthe conventional distribution fitting. It integrates two components: SemanticDebiasing (SD) and Balanced Predicate Learning (BPL), for these imbalances. SDutilizes a confusion matrix and a bipartite graph to construct predicaterelationships. BPL adopts a random undersampling strategy and an ambiguityremoving strategy to focus on informative predicates. Benefiting from themodel-agnostic process, our method can be easily applied to SGG models andoutperforms Transformer by 136.3%, 119.5%, and 122.6% on mR@20 at three SGGsub-tasks on the SGG-VG dataset. Our method is further verified on anothercomplex SGG dataset (SGG-GQA) and two downstream tasks (sentence-to-graphretrieval and image captioning).", "output": "Informative Scene Graph Generation via Debiasing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reconstructing 3D poses from 2D poses lacking depth information isparticularly challenging due to the complexity and diversity of human motion.The key is to effectively model the spatial constraints between joints toleverage their inherent dependencies. Thus, we propose a novel model, calledDouble-chain Graph Convolutional Transformer (DC-GCT), to constrain the posethrough a double-chain design consisting of local-to-global and global-to-localchains to obtain a complex representation more suitable for the current humanpose. Specifically, we combine the advantages of GCN and Transformer and designa Local Constraint Module (LCM) based on GCN and a Global Constraint Module(GCM) based on self-attention mechanism as well as a Feature Interaction Module(FIM). The proposed method fully captures the multi-level dependencies betweenhuman body joints to optimize the modeling capability of the model. Moreover,we propose a method to use temporal information into the single-frame model byguiding the video sequence embedding through the joint embedding of the targetframe, with negligible increase in computational cost. Experimental resultsdemonstrate that DC-GCT achieves state-of-the-art performance on twochallenging datasets (Human3.6M and MPI-INF-3DHP). Notably, our model achievesstate-of-the-art performance on all action categories in the Human3.6M datasetusing detected 2D poses from CPN, and our code is available at:", "output": "Double-chain Constraints for 3D Human Pose Estimation in Images and Videos."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we study state estimation of multi-visual-inertial systems(MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrarynumber of asynchronous inertial measurement units (IMUs) or gyroscopes andglobal and(or) rolling shutter cameras. We are especially interested in thefull calibration of the associated visual-inertial sensors, including the IMUor camera intrinsics and the IMU-IMU(or camera) spatiotemporal extrinsics aswell as the image readout time of rolling-shutter cameras (if used). To thisend, we develop a new analytic combined IMU integration with intrinsics-termedACI3-to preintegrate IMU measurements, which is leveraged to fuse auxiliaryIMUs and(or) gyroscopes alongside a base IMU. We model the multi-inertialmeasurements to include all the necessary inertial intrinsic and IMU-IMUspatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-bodyconstraints to eliminate the necessity of auxiliary inertial poses and thusreducing computational complexity. By performing observability analysis ofMVIS, we prove that the standard four unobservable directions remain - nomatter how many inertial sensors are used, and also identify, for the firsttime, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliaryinertial intrinsics. In addition to the extensive simulations that validate ouranalysis and algorithms, we have built our own MVIS sensor rig and collectedover 25 real-world datasets to experimentally verify the proposed calibrationagainst the state-of-the-art calibration method such as Kalibr. We show thatthe proposed MVIS calibration is able to achieve competing accuracy withimproved convergence and repeatability, which is open sourced to better benefitthe community.", "output": "Multi-Visual-Inertial System: Analysis,Calibration and Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical image segmentation is an important step in medical image analysis,especially as a crucial prerequisite for efficient disease diagnosis andtreatment. The use of deep learning for image segmentation has become aprevalent trend. The widely adopted approach currently is U-Net and itsvariants. Additionally, with the remarkable success of pre-trained models innatural language processing tasks, transformer-based models like TransUNet haveachieved desirable performance on multiple medical image segmentation datasets.In this paper, we conduct a survey of the most representative four medicalimage segmentation models in recent years. We theoretically analyze thecharacteristics of these models and quantitatively evaluate their performanceon two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors).Finally, we discuss the main challenges and future trends in medical imagesegmentation. Our work can assist researchers in the related field to quicklyestablish medical segmentation models tailored to specific regions.", "output": "From CNN to Transformer: A Review of Medical Image Segmentation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Domain adaptation is commonly employed in crowd counting to bridge the domaingaps between different datasets. However, existing domain adaptation methodstend to focus on inter-dataset differences while overlooking theintra-differences within the same dataset, leading to additional learningambiguities. These domain-agnostic factors, e.g., density, surveillanceperspective, and scale, can cause significant in-domain variations, and themisalignment of these factors across domains can lead to a drop in performancein cross-domain crowd counting. To address this issue, we propose aDomain-agnostically Aligned Optimal Transport (DAOT) strategy that alignsdomain-agnostic factors between domains. The DAOT consists of three steps.First, individual-level differences in domain-agnostic factors are measuredusing structural similarity (SSIM). Second, the optimal transfer (OT) strategyis employed to smooth out these differences and find the optimaldomain-to-domain misalignment, with outlier individuals removed via a virtual\"dustbin\" column. Third, knowledge is transferred based on the aligneddomain-agnostic factors, and the model is retrained for domain adaptation tobridge the gap across domains. We conduct extensive experiments on fivestandard crowd-counting benchmarks and demonstrate that the proposed method hasstrong generalizability across diverse datasets. Our code will be available at:", "output": "DAOT: Domain-Agnostically Aligned Optimal Transport for Domain-Adaptive Crowd Counting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The current point cloud registration methods are mainly based on geometricinformation and usually ignore the semantic information in the point clouds. Inthis paper, we treat the point cloud registration problem as semantic instancematching and registration task, and propose a deep semantic graph matchingmethod for large-scale outdoor point cloud registration. Firstly, the semanticcategory labels of 3D point clouds are obtained by utilizing large-scale pointcloud semantic segmentation network. The adjacent points with the same categorylabels are then clustered together by using Euclidean clustering algorithm toobtain the semantic instances. Secondly, the semantic adjacency graph isconstructed based on the spatial adjacency relation of semantic instances.Three kinds of high-dimensional features including geometric shape features,semantic categorical features and spatial distribution features are learnedthrough graph convolutional network, and enhanced based on attention mechanism.Thirdly, the semantic instance matching problem is modeled as an optimaltransport problem, and solved through an optimal matching layer. Finally,according to the matched semantic instances, the geometric transformationmatrix between two point clouds is first obtained by SVD algorithm and thenrefined by ICP algorithm. The experiments are cconducted on the KITTI Odometrydataset, and the average relative translation error and average relativerotation error of the proposed method are 6.6cm and 0.229{deg} respectively.", "output": "Deep Semantic Graph Matching for Large-scale Outdoor Point Clouds Registration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Robust estimation is a crucial and still challenging task, which involvesestimating model parameters in noisy environments. Although conventionalsampling consensus-based algorithms sample several times to achieve robustness,these algorithms cannot use data features and historical informationeffectively. In this paper, we propose RLSAC, a novel Reinforcement Learningenhanced SAmple Consensus framework for end-to-end robust estimation. RLSACemploys a graph neural network to utilize both data and memory features toguide exploring directions for sampling the next minimum set. The feedback ofdownstream tasks serves as the reward for unsupervised training. Therefore,RLSAC can avoid differentiating to learn the features and the feedback ofdownstream tasks for end-to-end robust estimation. In addition, RLSACintegrates a state transition module that encodes both data and memoryfeatures. Our experimental results demonstrate that RLSAC can learn fromfeatures to gradually explore a better hypothesis. Through analysis, it isapparent that RLSAC can be easily transferred to other sampling consensus-basedrobust estimation tasks. To the best of our knowledge, RLSAC is also the firstmethod that uses reinforcement learning to sample consensus for end-to-endrobust estimation. We release our codes at ", "output": "RLSAC: Reinforcement Learning enhanced Sample Consensus for End-to-End Robust Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The rudimentary adversarial attacks utilize additive noise to attack facialrecognition (FR) models. However, because manipulating the total face isimpractical in the physical setting, most real-world FR attacks are based onadversarial patches, which limit perturbations to a small area. Previousadversarial patch attacks often resulted in unnatural patterns and clearboundaries that were easily noticeable. In this paper, we argue that generatingadversarial patches with plausible content can result in strongertransferability than using additive noise or directly sampling from the latentspace. To generate natural-looking and highly transferable adversarial patches,we propose an innovative two-stage coarse-to-fine attack framework calledAdv-Inpainting. In the first stage, we propose an attention-guided StyleGAN(Att-StyleGAN) that adaptively combines texture and identity features based onthe attention map to generate high-transferable and natural adversarialpatches. In the second stage, we design a refinement network with a newboundary variance loss to further improve the coherence between the patch andits surrounding area. Experiment results demonstrate that Adv-Inpainting isstealthy and can produce adversarial patches with stronger transferability andimproved visual quality than previous adversarial patch attacks.", "output": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Background: Prostate cancer (PC) MRI-based risk calculators are commonlybased on biological (e.g. PSA), MRI markers (e.g. volume), and patient age.Whilst patient age measures the amount of years an individual has existed,biological age (BA) might better reflect the physiology of an individual.However, surrogates from prostate MRI and linkage with clinically significantPC (csPC) remain to be explored. Purpose: To obtain and evaluate Prostate AgeGap (PAG) as an MRI marker tool for csPC risk. Study type: Retrospective.Population: A total of 7243 prostate MRI slices from 468 participants who hadundergone prostate biopsies. A deep learning model was trained on 3223 MRIslices cropped around the gland from 81 low-grade PC (ncsPC, Gleason score &lt;=6)and 131 negative cases and tested on the remaining 256 participants.Assessment: Chronological age was defined as the age of the participant at thetime of the visit and used to train the deep learning model to predict the ageof the patient. Following, we obtained PAG, defined as the model predicted ageminus the patient's chronological age. Multivariate logistic regression modelswere used to estimate the association through odds ratio (OR) and predictivevalue of PAG and compared against PSA levels and PI-RADS&gt;=3. Statistical tests:T-test, Mann-Whitney U test, Permutation test and ROC curve analysis. Results:The multivariate adjusted model showed a significant difference in the odds ofclinically significant PC (csPC, Gleason score &gt;=7) (OR =3.78, 95% confidenceinterval (CI):2.32-6.16, P &lt;.001). PAG showed a better predictive ability whencompared to PI-RADS&gt;=3 and adjusted by other risk factors, including PSAlevels: AUC =0.981 vs AUC =0.704, p&lt;.001. Conclusion: PAG was significantlyassociated with the risk of clinically significant PC and outperformed otherwell-established PC risk factors.", "output": "Prostate Age Gap (PAG): An MRI surrogate marker of aging for prostate cancer detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a common natural weather condition, rain can obscure video frames and thusaffect the performance of the visual system, so video derain receives a lot ofattention. In natural environments, rain has a wide variety of streak types,which increases the difficulty of the rain removal task. In this paper, wepropose a Rain Review-based General video derain Network via knowledgedistillation (named RRGNet) that handles different rain streak types with onepre-training weight. Specifically, we design a frame grouping-basedencoder-decoder network that makes full use of the temporal information of thevideo. Further, we use the old task model to guide the current model inlearning new rain streak types while avoiding forgetting. To consolidate thenetwork's ability to derain, we design a rain review module to play back datafrom old tasks for the current model. The experimental results show that ourdeveloped general method achieves the best results in terms of running speedand derain effect.", "output": "Towards General and Fast Video Derain via Knowledge Distillation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In implant prosthesis treatment, the surgical guide of implant is used toensure accurate implantation. However, such design heavily relies on the manuallocation of the implant position. When deep neural network has been proposed toassist the dentist in locating the implant position, most of them take a singleslice as input, which do not fully explore 3D contextual information andignoring the influence of implant slope. In this paper, we design a Text Guided3D Context and Slope Aware Triple Network (TCSloT) which enables the perceptionof contextual information from multiple adjacent slices and awareness ofvariation of implant slopes. A Texture Variation Perception (TVP) module iscorrespondingly elaborated to process the multiple slices and capture thetexture variation among slices and a Slope-Aware Loss (SAL) is proposed todynamically assign varying weights for the regression head. Additionally, wedesign a conditional text guidance (CTG) module to integrate the text condition(i.e., left, middle and right) from the CLIP for assisting the implant positionprediction. Extensive experiments on a dental implant dataset through five-foldcross-validation demonstrated that the proposed TCSloT achieves superiorperformance than existing methods.", "output": "TCSloT: Text Guided 3D Context and Slope Aware Triple Network for Dental Implant Position Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The diversity of building architecture styles of global cities situated onvarious landforms, the degraded optical imagery affected by clouds and shadows,and the significant inter-class imbalance of roof types pose challenges fordesigning a robust and accurate building roof instance segmentor. To addressthese issues, we propose an effective framework to fulfill semanticinterpretation of individual buildings with high-resolution optical satelliteimagery. Specifically, the leveraged domain adapted pretraining strategy andcomposite dual-backbone greatly facilitates the discriminative featurelearning. Moreover, new data augmentation pipeline, stochastic weight averaging(SWA) training and instance segmentation based model ensemble in testing areutilized to acquire additional performance boost. Experiment results show thatour approach ranks in the first place of the 2023 IEEE GRSS Data Fusion Contest(DFC) Track 1 test phase ($mAP_{50}$:50.6%). Note-worthily, we have alsoexplored the potential of multimodal data fusion with both optical satelliteimagery and SAR data.", "output": "Fine-grained building roof instance segmentation based on domain adapted pretraining and composite dual-backbone."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Pseudo-labeling is significant for semi-supervised instance segmentation,which generates instance masks and classes from unannotated images forsubsequent training. However, in existing pipelines, pseudo-labels that containvaluable information may be directly filtered out due to mismatches in classand mask quality. To address this issue, we propose a novel framework, calledpseudo-label aligning instance segmentation (PAIS), in this paper. In PAIS, wedevise a dynamic aligning loss (DALoss) that adjusts the weights ofsemi-supervised loss terms with varying class and mask score pairs. Throughextensive experiments conducted on the COCO and Cityscapes datasets, wedemonstrate that PAIS is a promising framework for semi-supervised instancesegmentation, particularly in cases where labeled data is severely limited.Notably, with just 1% labeled data, PAIS achieves 21.2 mAP (based onMask-RCNN) and 19.9 mAP (based on K-Net) on the COCO dataset, outperforming thecurrent state-of-the-art model, ie, NoisyBoundary with 7.7 mAP, by a margin ofover 12 points. Code is available at: url{", "output": "Pseudo-label Alignment for Semi-supervised Instance Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "To obtain high-quality positron emission tomography (PET) images whileminimizing radiation exposure, various methods have been proposed forreconstructing standard-dose PET (SPET) images from low-dose PET (LPET)sinograms directly. However, current methods often neglect boundaries duringsinogram-to-image reconstruction, resulting in high-frequency distortion in thefrequency domain and diminished or fuzzy edges in the reconstructed images.Furthermore, the convolutional architectures, which are commonly used, lack theability to model long-range non-local interactions, potentially leading toinaccurate representations of global structures. To alleviate these problems,we propose a transformer-based model that unites triple domains of sinogram,image, and frequency for direct PET reconstruction, namely TriDo-Former.Specifically, the TriDo-Former consists of two cascaded networks, i.e., asinogram enhancement transformer (SE-Former) for denoising the input LPETsinograms and a spatial-spectral reconstruction transformer (SSR-Former) forreconstructing SPET images from the denoised sinograms. Different from thevanilla transformer that splits an image into 2D patches, based specifically onthe PET imaging mechanism, our SE-Former divides the sinogram into 1Dprojection view angles to maintain its inner-structure while denoising,preventing the noise in the sinogram from prorogating into the image domain.Moreover, to mitigate high-frequency distortion and improve reconstructiondetails, we integrate global frequency parsers (GFPs) into SSR-Former. The GFPserves as a learnable frequency filter that globally adjusts the frequencycomponents in the frequency domain, enforcing the network to restorehigh-frequency details resembling real SPET images. Validations on a clinicaldataset demonstrate that our TriDo-Former outperforms the state-of-the-artmethods qualitatively and quantitatively.", "output": "TriDo-Former: A Triple-Domain Transformer for Direct PET Reconstruction from Low-Dose Sinograms."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This work considers gradient-based mesh optimization, where we iterativelyoptimize for a 3D surface mesh by representing it as the isosurface of a scalarfield, an increasingly common paradigm in applications includingphotogrammetry, generative modeling, and inverse physics. Existingimplementations adapt classic isosurface extraction algorithms like MarchingCubes or Dual Contouring; these techniques were designed to extract meshes fromfixed, known fields, and in the optimization setting they lack the degrees offreedom to represent high-quality feature-preserving meshes, or suffer fromnumerical instabilities. We introduce FlexiCubes, an isosurface representationspecifically designed for optimizing an unknown mesh with respect to geometric,visual, or even physical objectives. Our main insight is to introduceadditional carefully-chosen parameters into the representation, which allowlocal flexible adjustments to the extracted mesh geometry and connectivity.These parameters are updated along with the underlying scalar field viaautomatic differentiation when optimizing for a downstream task. We base ourextraction scheme on Dual Marching Cubes for improved topological properties,and present extensions to optionally generate tetrahedral andhierarchically-adaptive meshes. Extensive experiments validate FlexiCubes onboth synthetic benchmarks and real-world applications, showing that it offerssignificant improvements in mesh quality and geometric fidelity.", "output": "Flexible Isosurface Extraction for Gradient-Based Mesh Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes joint attention estimation in a single image. Differentfrom related work in which only the gaze-related attributes of people areindependently employed, (I) their locations and actions are also employed ascontextual cues for weighting their attributes, and (ii) interactions among allof these attributes are explicitly modeled in our method. For the interactionmodeling, we propose a novel Transformer-based attention network to encodejoint attention as low-dimensional features. We introduce a specialized MLPhead with positional embedding to the Transformer so that it predicts pixelwiseconfidence of joint attention for generating the confidence heatmap. Thispixelwise prediction improves the heatmap accuracy by avoiding the ill-posedproblem in which the high-dimensional heatmap is predicted from thelow-dimensional features. The estimated joint attention is further improved bybeing integrated with general image-based attention estimation. Our methodoutperforms SOTA methods quantitatively in comparative experiments. Code:", "output": "Interaction-aware Joint Attention Estimation Using People Attributes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unifying the correlative single-view satellite image building extraction andheight estimation tasks indicates a promising way to share representations andacquire generalist model for large-scale urban 3D reconstruction. However, thecommon spatial misalignment between building footprints andstereo-reconstructed nDSM height labels incurs degraded performance on bothtasks. To address this issue, we propose a Height-hierarchy Guided Dual-decoderNetwork (HGDNet) to estimate building height. Under the guidance of synthesizeddiscrete height-hierarchy nDSM, auxiliary height-hierarchical buildingextraction branch enhance the height estimation branch with implicitconstraints, yielding an accuracy improvement of more than 6% on the DFC 2023track2 dataset. Additional two-stage cascade architecture is adopted to achievemore accurate building extraction. Experiments on the DFC 2023 Track 2 datasetshows the superiority of the proposed method in building height estimation({delta}1:0.8012), instance extraction (AP50:0.7730), and the final averagescore 0.7871 ranks in the first place in test phase.", "output": "HGDNet: A Height-Hierarchy Guided Dual-Decoder Network for Single View Building Extraction and Height Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In a fashion e-commerce platform where customers can't physically examine theproducts on their own, being able to see other customers' text and imagereviews of the product is critical while making purchase decisions. Given thehigh reliance on these reviews, over the years we have observed customersproactively sharing their reviews. With an increase in the coverage of UserGenerated Content (UGC), there has been a corresponding increase in the numberof customer images. It is thus imperative to display the most relevant imageson top as it may influence users' online shopping choices and behavior. In thispaper, we propose a simple yet effective training procedure for rankingcustomer images. We created a dataset consisting of Myntra (A Major IndianFashion e-commerce company) studio posts and highly engaged (upvotes/downvotes)UGC images as our starting point and used selected distortion techniques on theimages of the above dataset to bring their quality at par with those of bad UGCimages. We train our network to rank bad-quality images lower than high-qualityones. Our proposed method outperforms the baseline models on two metrics,namely correlation coefficient, and accuracy, by substantial margins.", "output": "Product Review Image Ranking for Fashion E-commerce."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Visual Inertial Odometry (VIO) is an essential component of modern AugmentedReality (AR) applications. However, VIO only tracks the relative pose of thedevice, leading to drift over time. Absolute pose estimation methods infer thedevice's absolute pose, but their accuracy depends on the input quality. Thispaper introduces VIO-APR, a new framework for markerless mobile AR thatcombines an absolute pose regressor (APR) with a local VIO tracking system.VIO-APR uses VIO to assess the reliability of the APR and the APR to identifyand compensate for VIO drift. This feedback loop results in more accuratepositioning and more stable AR experiences. To evaluate VIO-APR, we created adataset that combines camera images with ARKit's VIO system output for sixindoor and outdoor scenes of various scales. Over this dataset, VIO-APRimproves the median accuracy of popular APR by up to 36% in position and 29%in orientation, increases the percentage of frames in the high ($0.25 m,2^{circ}$) accuracy level by up to 112% and reduces the percentage of framespredicted below the low ($5 m, 10^circ$) accuracy greatly. We implementVIO-APR into a mobile AR application using Unity to demonstrate itscapabilities. VIO-APR results in noticeably more accurate localization and amore stable overall experience.", "output": "Robust Localization with Visual-Inertial Odometry Constraints for Markerless Mobile AR."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Extracting and using class-discriminative features is critical forfine-grained recognition. Existing works have demonstrated the possibility ofapplying deep CNNs to exploit features that distinguish similar classes.However, CNNs suffer from problems including frequency bias and loss ofdetailed local information, which restricts the performance of recognizingfine-grained categories. To address the challenge, we propose a novel texturebranch as complimentary to the CNN branch for feature extraction. Weinnovatively utilize Gabor filters as a powerful extractor to exploit texturefeatures, motivated by the capability of Gabor filters in effectively capturingmulti-frequency features and detailed local information. We implement severaldesigns to enhance the effectiveness of Gabor filters, including imposingconstraints on parameter values and developing a learning method to determinethe optimal parameters. Moreover, we introduce a statistical feature extractorto utilize informative statistical information from the signals captured byGabor filters, and a gate selection mechanism to enable efficient computationby only considering qualified regions as input for texture extraction. Throughthe integration of features from the Gabor-filter-based texture branch andCNN-based semantic branch, we achieve comprehensive information extraction. Wedemonstrate the efficacy of our method on multiple datasets, includingCUB-200-2011, NA-bird, Stanford Dogs, and GTOS-mobile. State-of-the-artperformance is achieved using our approach.", "output": "Learning Gabor Texture Features for Fine-Grained Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents a novel and interpretable end-to-end learning framework,called the deep compensation unfolding network (DCUNet), for restoring lightfield (LF) images captured under low-light conditions. DCUNet is designed witha multi-stage architecture that mimics the optimization process of solving aninverse imaging problem in a data-driven fashion. The framework uses theintermediate enhanced result to estimate the illumination map, which is thenemployed in the unfolding process to produce a new enhanced result.Additionally, DCUNet includes a content-associated deep compensation module ateach optimization stage to suppress noise and illumination map estimationerrors. To properly mine and leverage the unique characteristics of LF images,this paper proposes a pseudo-explicit feature interaction module thatcomprehensively exploits redundant information in LF images. The experimentalresults on both simulated and real datasets demonstrate the superiority of ourDCUNet over state-of-the-art methods, both qualitatively and quantitatively.Moreover, DCUNet preserves the essential geometric structure of enhanced LFimages much better. The code will be publicly available at", "output": "Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With a rapidly increasing amount and diversity of remote sensing (RS) datasources, there is a strong need for multi-view learning modeling. This is acomplex task when considering the differences in resolution, magnitude, andnoise of RS data. The typical approach for merging multiple RS sources has beeninput-level fusion, but other - more advanced - fusion strategies mayoutperform this traditional approach. This work assesses different fusionstrategies for crop classification in the CropHarvest dataset. The fusionmethods proposed in this work outperform models based on individual views andprevious fusion methods. We do not find one single fusion method thatconsistently outperforms all other approaches. Instead, we present a comparisonof multi-view fusion methods for three different datasets and show that,depending on the test region, different methods obtain the best performance.Despite this, we suggest a preliminary criterion for the selection of fusionmethods.", "output": "A Comparative Assessment of Multi-view fusion learning for Crop Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper proposes a new method to infer keypoints from arbitrary objectcategories in practical scenarios where point cloud data (PCD) are noisy,down-sampled and arbitrarily rotated. Our proposed model adheres to thefollowing principles: i) keypoints inference is fully unsupervised (noannotation given), ii) keypoints position error should be low and resilient toPCD perturbations (robustness), iii) keypoints should not change their indexesfor the intra-class objects (semantic coherence), iv) keypoints should be closeto or proximal to PCD surface (compactness). We achieve these desiderata byproposing a new self-supervised training strategy for keypoints estimation thatdoes not assume any a priori knowledge of the object class, and a modelarchitecture with coupled auxiliary losses that promotes the desired keypointsproperties. We compare the keypoints estimated by the proposed approach withthose of the state-of-the-art unsupervised approaches. The experiments showthat our approach outperforms by estimating keypoints with improved coverage(+9.41%) while being semantically consistent (+4.66%) that best characterizesthe object's 3D shape for downstream tasks. Code and data are available at:", "output": "SC3K: Self-supervised and Coherent 3D Keypoints Estimation from Rotated, Noisy, and Decimated Point Cloud Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Audio-Visual Question Answering (AVQA) task aims to answer questions aboutdifferent visual objects, sounds, and their associations in videos. Suchnaturally multi-modal videos are composed of rich and complex dynamicaudio-visual components, where most of which could be unrelated to the givenquestions, or even play as interference in answering the content of interest.Oppositely, only focusing on the question-aware audio-visual content could getrid of influence, meanwhile enabling the model to answer more efficiently. Inthis paper, we propose a Progressive Spatio-Temporal Perception Network(PSTP-Net), which contains three modules that progressively identify keyspatio-temporal regions w.r.t. questions. Specifically, a temporal segmentselection module is first introduced to select the most relevant audio-visualsegments related to the given question. Then, a spatial region selection moduleis utilized to choose the most relevant regions associated with the questionfrom the selected temporal segments. To further refine the selection offeatures, an audio-guided visual attention module is employed to perceive theassociation between auido and selected spatial regions. Finally, thespatio-temporal features from these modules are integrated for answering thequestion. Extensive experimental results on the public MUSIC-AVQA and AVQAdatasets provide compelling evidence of the effectiveness and efficiency ofPSTP-Net. Code is available at:href{", "output": "Progressive Spatio-temporal Perception for Audio-Visual Question Answering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Foundation models, such as OpenAI's GPT-3 and GPT-4, Meta's LLaMA, andGoogle's PaLM2, have revolutionized the field of artificial intelligence. Anotable paradigm shift has been the advent of the Segment Anything Model (SAM),which has exhibited a remarkable capability to segment real-world objects,trained on 1 billion masks and 11 million images. Although SAM excels ingeneral object segmentation, it lacks the intrinsic ability to detect salientobjects, resulting in suboptimal performance in this domain. To address thischallenge, we present the Segment Salient Object Model (SSOM), an innovativeapproach that adaptively fine-tunes SAM for salient object detection byharnessing the low-rank structure inherent in deep learning. Comprehensivequalitative and quantitative evaluations across five challenging RGB benchmarkdatasets demonstrate the superior performance of our approach, surpassingstate-of-the-art methods.", "output": "Adaptive Low Rank Adaptation of Segment Anything to Salient Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Speech-driven 3D face animation poses significant challenges due to theintricacy and variability inherent in human facial movements. This paperemphasizes the importance of considering both the composite and regionalnatures of facial movements in speech-driven 3D face animation. The compositenature pertains to how speech-independent factors globally modulatespeech-driven facial movements along the temporal dimension. Meanwhile, theregional nature alludes to the notion that facial movements are not globallycorrelated but are actuated by local musculature along the spatial dimension.It is thus indispensable to incorporate both natures for engendering vividanimation. To address the composite nature, we introduce an adaptive modulationmodule that employs arbitrary facial movements to dynamically adjustspeech-driven facial movements across frames on a global scale. To accommodatethe regional nature, our approach ensures that each constituent of the facialfeatures for every frame focuses on the local spatial movements of 3D faces.Moreover, we present a non-autoregressive backbone for translating audio to 3Dfacial movements, which maintains high-frequency nuances of facial movementsand facilitates efficient inference. Comprehensive experiments and user studiesdemonstrate that our method surpasses contemporary state-of-the-art approachesboth qualitatively and quantitatively.", "output": "Speech-Driven 3D Face Animation with Composite and Regional Facial Movements."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work, we propose an ensemble modeling approach for multimodal actionrecognition. We independently train individual modality models using a variantof focal loss tailored to handle the long-tailed distribution of the MECCANO[21] dataset. Based on the underlying principle of focal loss, which capturesthe relationship between tail (scarce) classes and their predictiondifficulties, we propose an exponentially decaying variant of focal loss forour current task. It initially emphasizes learning from the hard misclassifiedexamples and gradually adapts to the entire range of examples in the dataset.This annealing process encourages the model to strike a balance betweenfocusing on the sparse set of hard samples, while still leveraging theinformation provided by the easier ones. Additionally, we opt for the latefusion strategy to combine the resultant probability distributions from RGB andDepth modalities for final action prediction. Experimental evaluations on theMECCANO dataset demonstrate the effectiveness of our approach.", "output": "Ensemble Modeling for Multimodal Visual Action Recognition."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "One critical challenge in 6D object pose estimation from a single RGBD imageis efficient integration of two different modalities, i.e., color and depth. Inthis work, we tackle this problem by a novel Deep Fusion Transformer~(DFTr)block that can aggregate cross-modality features for improving pose estimation.Unlike existing fusion methods, the proposed DFTr can better modelcross-modality semantic correlation by leveraging their semantic similarity,such that globally enhanced features from different modalities can be betterintegrated for improved information extraction. Moreover, to further improverobustness and efficiency, we introduce a novel weighted vector-wise votingalgorithm that employs a non-iterative global optimization strategy for precise3D keypoint localization while achieving near real-time inference. Extensiveexperiments show the effectiveness and strong generalization capability of ourproposed 3D keypoint voting algorithm. Results on four widely used benchmarksalso demonstrate that our method outperforms the state-of-the-art methods bylarge margins.", "output": "Deep Fusion Transformer Network with Weighted Vector-Wise Keypoints Voting for Robust 6D Object Pose Estimation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose an experimental method for measuring bias in face recognitionsystems. Existing methods to measure bias depend on benchmark datasets that arecollected in the wild and annotated for protected (e.g., race, gender) andnon-protected (e.g., pose, lighting) attributes. Such observational datasetsonly permit correlational conclusions, e.g., \"Algorithm A's accuracy isdifferent on female and male faces in dataset X.\". By contrast, experimentalmethods manipulate attributes individually and thus permit causal conclusions,e.g., \"Algorithm A's accuracy is affected by gender and skin color.\"Our method is based on generating synthetic faces using a neural facegenerator, where each attribute of interest is modified independently whileleaving all other attributes constant. Human observers crucially provide theground truth on perceptual identity similarity between synthetic image pairs.We validate our method quantitatively by evaluating race and gender biases ofthree research-grade face recognition models. Our synthetic pipeline revealsthat for these algorithms, accuracy is lower for Black and East Asianpopulation subgroups. Our method can also quantify how perceptual changes inattributes affect face identity distances reported by these models. Our largesynthetic dataset, consisting of 48,000 synthetic face image pairs (10,200unique synthetic faces) and 555,000 human annotations (individual attributesand pairwise identity comparisons) is available to researchers in thisimportant area.", "output": "Benchmarking Algorithmic Bias in Face Recognition: An Experimental Approach Using Synthetic Faces and Human Evaluation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Underwater images often suffer from color distortion and low contrastresulting in various image types, due to the scattering and absorption of lightby water. While it is difficult to obtain high-quality paired training sampleswith a generalized model. To tackle these challenges, we design a GeneralizedUnderwater image enhancement method via a Physical-knowledge-guided DynamicModel (short for GUPDM), consisting of three parts: Atmosphere-based DynamicStructure (ADS), Transmission-guided Dynamic Structure (TDS), and Prior-basedMulti-scale Structure (PMS). In particular, to cover complex underwater scenes,this study changes the global atmosphere light and the transmission to simulatevarious underwater image types (e.g., the underwater image color ranging fromyellow to blue) through the formation model. We then design ADS and TDS thatuse dynamic convolutions to adaptively extract prior information fromunderwater images and generate parameters for PMS. These two modules enable thenetwork to select appropriate parameters for various water types adaptively.Besides, the multi-scale feature extraction module in PMS uses convolutionblocks with different kernel sizes and obtains weights for each feature map viachannel attention block and fuses them to boost the receptive field of thenetwork. The source code will be available athref{", "output": "A Generalized Physical-knowledge-guided Dynamic Model for Underwater Image Enhancement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ultrasound (US) imaging is better suited for intraoperative settings becauseit is real-time and more portable than other imaging techniques, such asmammography. However, US images are characterized by lower spatial resolutionnoise-like artifacts. This research aims to address these limitations byproviding surgeons with mammogram-like image quality in real-time from noisy USimages. Unlike previous approaches for improving US image quality that aim toreduce artifacts by treating them as (speckle noise), we recognize their valueas informative wave interference pattern (WIP). To achieve this, we utilize theStride software to numerically solve the forward model, generating ultrasoundimages from mammograms images by solving wave-equations. Additionally, weleverage the power of domain adaptation to enhance the realism of the simulatedultrasound images. Then, we utilize generative adversarial networks (GANs) totackle the inverse problem of generating mammogram-quality images fromultrasound images. The resultant images have considerably more discernibledetails than the original US images.", "output": "Transforming Breast Cancer Diagnosis: Towards Real-Time Ultrasound to Mammogram Conversion for Cost-Effective Diagnosis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Markerless Mobile Augmented Reality (AR) aims to anchor digital content inthe physical world without using specific 2D or 3D objects. Absolute PoseRegressors (APR) are end-to-end machine learning solutions that infer thedevice's pose from a single monocular image. Thanks to their low computationcost, they can be directly executed on the constrained hardware of mobile ARdevices. However, APR methods tend to yield significant inaccuracies for inputimages that are too distant from the training set. This paper introducesKS-APR, a pipeline that assesses the reliability of an estimated pose withminimal overhead by combining the inference results of the APR and the priorimages in the training set. Mobile AR systems tend to rely upon visual-inertialodometry to track the relative pose of the device during the experience. Assuch, KS-APR favours reliability over frequency, discarding unreliable poses.This pipeline can integrate most existing APR methods to improve accuracy byfiltering unreliable images with their pose estimates. We implement thepipeline on three types of APR models on indoor and outdoor datasets. Themedian error on position and orientation is reduced for all models, and theproportion of large errors is minimized across datasets. Our method enablesstate-of-the-art APRs such as DFNetdm to outperform single-image and sequentialAPR methods. These results demonstrate the scalability and effectiveness ofKS-APR for visual localization tasks that do not require one-shot decisions.", "output": "KS-APR: Keyframe Selection for Robust Absolute Pose Regression."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Self-supervision has been widely explored as a means of addressing the lackof inductive biases in vision transformer architectures, which limitsgeneralisation when networks are trained on small datasets. This is crucial inthe context of cortical imaging, where phenotypes are complex andheterogeneous, but the available datasets are limited in size. This paperbuilds upon recent advancements in translating vision transformers to surfacemeshes and investigates the potential of Masked AutoEncoder (MAE)self-supervision for cortical surface learning. By reconstructing surface datafrom a masked version of the input, the proposed method effectively modelscortical structure to learn strong representations that translate to improvedperformance in downstream tasks. We evaluate our approach on cortical phenotyperegression using the developing Human Connectome Project (dHCP) and demonstratethat pre-training leads to a 26% improvement in performance, with an 80%faster convergence, compared to models trained from scratch. Furthermore, weestablish that pre-training vision transformer models on large datasets, suchas the UK Biobank (UKB), enables the acquisition of robust representations forfinetuning in low-data scenarios. Our code and pre-trained models are publiclyavailable at url{", "output": "Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent developments and the beginning market introduction of high-resolutionimaging 4D (3+1D) radar sensors have initialized deep learning-based radarperception research. We investigate deep learning-based models operating onradar point clouds for 3D object detection. 3D object detection on lidar pointcloud data is a mature area of 3D vision. Many different architectures havebeen proposed, each with strengths and weaknesses. Due to similarities between3D lidar point clouds and 3+1D radar point clouds, those existing 3D objectdetectors are a natural basis to start deep learning-based 3D object detectionon radar data. Thus, the first step is to analyze the detection performance ofthe existing models on the new data modality and evaluate them in depth. Inorder to apply existing 3D point cloud object detectors developed for lidarpoint clouds to the radar domain, they need to be adapted first. While somedetectors, such as PointPillars, have already been adapted to be applicable toradar data, we have adapted others, e.g., Voxel R-CNN, SECOND, PointRCNN, andPV-RCNN. To this end, we conduct a cross-model validation (evaluating a set ofmodels on one particular data set) as well as a cross-data set validation(evaluating all models in the model set on several data sets). Thehigh-resolution radar data used are the View-of-Delft and Astyx data sets.Finally, we evaluate several adaptations of the models and their trainingprocedures. We also discuss major factors influencing the detection performanceon radar data and propose possible solutions indicating potential futureresearch avenues.", "output": "Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We aim at providing the object detection community with an efficient andperformant object detector, termed YOLO-MS. The core design is based on aseries of investigations on how convolutions with different kernel sizes affectthe detection performance of objects at different scales. The outcome is a newstrategy that can strongly enhance multi-scale feature representations ofreal-time object detectors. To verify the effectiveness of our strategy, webuild a network architecture, termed YOLO-MS. We train our YOLO-MS on the MSCOCO dataset from scratch without relying on any other large-scale datasets,like ImageNet, or pre-trained weights. Without bells and whistles, our YOLO-MSoutperforms the recent state-of-the-art real-time object detectors, includingYOLO-v7 and RTMDet, when using a comparable number of parameters and FLOPs.Taking the XS version of YOLO-MS as an example, with only 4.5M learnableparameters and 8.7G FLOPs, it can achieve an AP score of 43%+ on MS COCO, whichis about 2%+ higher than RTMDet with the same model size. Moreover, our workcan also be used as a plug-and-play module for other YOLO models. Typically,our method significantly improves the AP of YOLOv8 from 37%+ to 40%+ with evenfewer parameters and FLOPs. Code is available at", "output": "YOLO-MS: Rethinking Multi-Scale Representation Learning for Real-time Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Endeavors have been recently made to transfer knowledge from the labeledpinhole image domain to the unlabeled panoramic image domain via UnsupervisedDomain Adaptation (UDA). The aim is to tackle the domain gaps caused by thestyle disparities and distortion problem from the non-uniformly distributedpixels of equirectangular projection (ERP). Previous works typically focus ontransferring knowledge based on geometric priors with specially designedmulti-branch network architectures. As a result, considerable computationalcosts are induced, and meanwhile, their generalization abilities are profoundlyhindered by the variation of distortion among pixels. In this paper, we findthat the pixels' neighborhood regions of the ERP indeed introduce lessdistortion. Intuitively, we propose a novel UDA framework that can effectivelyaddress the distortion problems for panoramic semantic segmentation. Incomparison, our method is simpler, easier to implement, and morecomputationally efficient. Specifically, we propose distortion-aware attention(DA) capturing the neighboring pixel distribution without using any geometricconstraints. Moreover, we propose a class-wise feature aggregation (CFA) moduleto iteratively update the feature representations with a memory bank. As such,the feature similarity between two domains can be consistently optimized.Extensive experiments show that our method achieves new state-of-the-artperformance while remarkably reducing 80% parameters.", "output": "Look at the Neighbor: Distortion-aware Unsupervised Domain Adaptation for Panoramic Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to cope accurately and fast with Out-Of-Distribution (OOD)samples is crucial in real-world safety demanding applications. In this work wefirst study the interplay between critical points of 3D point clouds and OODsamples. Our findings are that common corruptions and outliers are ofteninterpreted as critical points. We generalize the notion of critical pointsinto importance measures. We show that training a classification network basedonly on less important points dramatically improves robustness, at a cost ofminor performance loss on the clean set. We observe that normalized entropy ishighly informative for corruption analysis. An adaptive threshold based onnormalized entropy is suggested for selecting the set of uncritical points. Ourproposed importance measure is extremely fast to compute. We show it can beused for a variety of applications, such as Explainable AI (XAI), OutlierRemoval, Uncertainty Estimation, Robust Classification and Adversarial Defense.We reach SOTA results on the two latter tasks.", "output": "Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Activity progress prediction aims to estimate what percentage of an activityhas been completed. Currently this is done with machine learning approaches,trained and evaluated on complicated and realistic video datasets. The videosin these datasets vary drastically in length and appearance. And some of theactivities have unanticipated developments, making activity progressiondifficult to estimate. In this work, we examine the results obtained byexisting progress prediction methods on these datasets. We find that currentprogress prediction methods seem not to extract useful visual information forthe progress prediction task. Therefore, these methods fail to exceed simpleframe-counting baselines. We design a precisely controlled dataset for activityprogress prediction and on this synthetic dataset we show that the consideredmethods can make use of the visual information, when this directly relates tothe progress prediction. We conclude that the progress prediction task isill-posed on the currently used real-world datasets. Moreover, to fairlymeasure activity progression we advise to consider a, simple but effective,frame-counting baseline.", "output": "Is there progress in activity progress prediction?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In real medical data, training samples typically show long-taileddistributions with multiple labels. Class distribution of the medical data hasa long-tailed shape, in which the incidence of different diseases is quitevaried, and at the same time, it is not unusual for images taken fromsymptomatic patients to be multi-label diseases. Therefore, in this paper, weconcurrently address these two issues by putting forth a robust asymmetric losson the polynomial function. Since our loss tackles both long-tailed andmulti-label classification problems simultaneously, it leads to a complexdesign of the loss function with a large number of hyper-parameters. Although amodel can be highly fine-tuned due to a large number of hyper-parameters, it isdifficult to optimize all hyper-parameters at the same time, and there might bea risk of overfitting a model. Therefore, we regularize the loss function usingthe Hill loss approach, which is beneficial to be less sensitive against thenumerous hyper-parameters so that it reduces the risk of overfitting the model.For this reason, the proposed loss is a generic method that can be applied tomost medical image classification tasks and does not make the training processmore time-consuming. We demonstrate that the proposed robust asymmetric lossperforms favorably against the long-tailed with multi-label medical imageclassification in addition to the various long-tailed single-label datasets.Notably, our method achieves Top-5 results on the CXR-LT dataset of the ICCVCVAMD 2023 competition. We opensource our implementation of the robustasymmetric loss in the public repository: ", "output": "Robust Asymmetric Loss for Multi-Label Long-Tailed Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Images taken under the low-light condition often contain blur and saturatedpixels at the same time. Deblurring images with saturated pixels is quitechallenging. Because of the limited dynamic range, the saturated pixels areusually clipped in the imaging process and thus cannot be modeled by the linearblur model. Previous methods use manually designed smooth functions toapproximate the clipping procedure. Their deblurring processes often requireempirically defined parameters, which may not be the optimal choices fordifferent images. In this paper, we develop a data-driven approach to model thesaturated pixels by a learned latent map. Based on the new model, the non-blinddeblurring task can be formulated into a maximum a posterior (MAP) problem,which can be effectively solved by iteratively computing the latent map and thelatent image. Specifically, the latent map is computed by learning from a mapestimation network (MEN), and the latent image estimation process isimplemented by a Richardson-Lucy (RL)-based updating scheme. To estimatehigh-quality deblurred images without amplified artifacts, we develop a priorestimation network (PEN) to obtain prior information, which is furtherintegrated into the RL scheme. Experimental results demonstrate that theproposed method performs favorably against state-of-the-art algorithms bothquantitatively and qualitatively on synthetic and real-world images.", "output": "Deep Richardson-Lucy Deconvolution for Low-Light Image Deblurring."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The proliferation of short video and live-streaming platforms hasrevolutionized how consumers engage in online shopping. Instead of browsingproduct pages, consumers are now turning to rich-content e-commerce, where theycan purchase products through dynamic and interactive media like short videosand live streams. This emerging form of online shopping has introducedtechnical challenges, as products may be presented differently across variousmedia domains. Therefore, a unified product representation is essential forachieving cross-domain product recognition to ensure an optimal user searchexperience and effective product recommendations. Despite the urgent industrialneed for a unified cross-domain product representation, previous studies havepredominantly focused only on product pages without taking into account shortvideos and live streams. To fill the gap in the rich-content e-commerce area,in this paper, we introduce a large-scale cRoss-dOmain Product Ecognitiondataset, called ROPE. ROPE covers a wide range of product categories andcontains over 180,000 products, corresponding to millions of short videos andlive streams. It is the first dataset to cover product pages, short videos, andlive streams simultaneously, providing the basis for establishing a unifiedproduct representation across different media domains. Furthermore, we proposea Cross-dOmain Product rEpresentation framework, namely COPE, which unifiesproduct representations in different domains through multimodal learningincluding text and vision. Extensive experiments on downstream tasksdemonstrate the effectiveness of COPE in learning a joint feature space for allproduct domains.", "output": "Cross-Domain Product Representation Learning for Rich-Content E-Commerce."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Current research in zero-shot translation is plagued by several issues suchas high compute requirements, increased training time and off targettranslations. Proposed remedies often come at the cost of additional data orcompute requirements. Pivot based neural machine translation is preferred overa single-encoder model for most settings despite the increased training andevaluation time. In this work, we overcome the shortcomings of zero-shottranslation by taking advantage of transliteration and linguistic similarity.We build a single encoder-decoder neural machine translation system forDravidian-Dravidian multilingual translation and perform zero-shot translation.We compare the data vs zero-shot accuracy tradeoff and evaluate the performanceof our vanilla method against the current state of the art pivot based method.We also test the theory that morphologically rich languages require largevocabularies by restricting the vocabulary using an optimal transport basedtechnique. Our model manages to achieves scores within 3 BLEU of large-scalepivot-based models when it is trained on 50% of the language directions.", "output": "Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual Translation of Dravidian Languages."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Aggregation of multi-stage features has been revealed to play a significantrole in semantic segmentation. Unlike previous methods employing point-wisesummation or concatenation for feature aggregation, this study proposes theCategory Feature Transformer (CFT) that explores the flow of category embeddingand transformation among multi-stage features through the prevalent multi-headattention mechanism. CFT learns unified feature embeddings for individualsemantic categories from high-level features during each aggregation processand dynamically broadcasts them to high-resolution features. Integrating theproposed CFT into a typical feature pyramid structure exhibits superiorperformance over a broad range of backbone networks. We conduct extensiveexperiments on popular semantic segmentation benchmarks. Specifically, theproposed CFT obtains a compelling 55.1% mIoU with greatly reduced modelparameters and computations on the challenging ADE20K dataset.", "output": "Category Feature Transformer for Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Skin lesion analysis models are biased by artifacts placed during imageacquisition, which influence model predictions despite carrying no clinicalinformation. Solutions that address this problem by regularizing models toprevent learning those spurious features achieve only partial success, andexisting test-time debiasing techniques are inappropriate for skin lesionanalysis due to either making unrealistic assumptions on the distribution oftest data or requiring laborious annotation from medical practitioners. Wepropose TTS (Test-Time Selection), a human-in-the-loop method that leveragespositive (e.g., lesion area) and negative (e.g., artifacts) keypoints in testsamples. TTS effectively steers models away from exploiting spuriousartifact-related correlations without retraining, and with less annotationrequirements. Our solution is robust to a varying availability of annotations,and different levels of bias. We showcase on the ISIC2019 dataset (for which werelease a subset of annotated images) how our model could be deployed in thereal-world for mitigating bias.", "output": "Test-Time Selection for Robust Skin Lesion Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural network (DNN) deployment has been confined to larger hardwaredevices due to their expensive computational requirements. This challenge hasrecently reached another scale with the emergence of large language models(LLMs). In order to reduce both their memory footprint and latency, a promisingtechnique is quantization. It consists in converting floating pointrepresentations to low bit-width fixed point representations, usually byassuming a uniform mapping onto a regular grid. This process, referred to inthe literature as uniform quantization, may however be ill-suited as most DNNweights and activations follow a bell-shaped distribution. This is even worseon LLMs whose weight distributions are known to exhibit large, high impact,outlier values. In this work, we propose an improvement over the most commonlyadopted way to tackle this limitation in deep learning models quantization,namely, non-uniform quantization. NUPES leverages automorphisms to preserve thescalar multiplications. Such transformations are derived from power functions.However, the optimization of the exponent parameter and weight values remains achallenging and novel problem which could not be solved with previous posttraining optimization techniques which only learn to round up or down weightvalues in order to preserve the predictive function. We circumvent thislimitation with a new paradigm: learning new quantized weights over the entirequantized space. Similarly, we enable the optimization of the power exponent,i.e. the optimization of the quantization operator itself during training byalleviating all the numerical instabilities. The resulting predictive functionis compatible with integer-only low-bit inference. We show the ability of themethod to achieve state-of-the-art compression rates in both, data-free anddata-driven configurations.", "output": "NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Object goal navigation aims to navigate an agent to locations of a givenobject category in unseen environments. Classical methods explicitly build mapsof environments and require extensive engineering while lacking semanticinformation for object-oriented exploration. On the other hand, end-to-endlearning methods alleviate manual map design and predict actions using implicitrepresentations. Such methods, however, lack an explicit notion of geometry andmay have limited ability to encode navigation history. In this work, we proposean implicit spatial map for object goal navigation. Our implicit map isrecursively updated with new observations at each step using a transformer. Toencourage spatial reasoning, we introduce auxiliary tasks and train our modelto reconstruct explicit maps as well as to predict visual features, semanticlabels and actions. Our method significantly outperforms the state of the arton the challenging MP3D dataset and generalizes well to the HM3D dataset. Wesuccessfully deploy our model on a real robot and achieve encouraging objectgoal navigation results in real scenes using only a few real-worlddemonstrations. Code, trained models and videos are available aturl{", "output": "Object Goal Navigation with Recursive Implicit Maps."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Monocular depth estimation is known as an ill-posed task in which objects ina 2D image usually do not contain sufficient information to predict theirdepth. Thus, it acts differently from other tasks (e.g., classification andsegmentation) in many ways. In this paper, we find that self-supervisedmonocular depth estimation shows a direction sensitivity and environmentaldependency in the feature representation. But the current backbones borrowedfrom other tasks pay less attention to handling different types ofenvironmental information, limiting the overall depth accuracy. To bridge thisgap, we propose a new Direction-aware Cumulative Convolution Network (DaCCN),which improves the depth feature representation in two aspects. First, wepropose a direction-aware module, which can learn to adjust the featureextraction in each direction, facilitating the encoding of different types ofinformation. Secondly, we design a new cumulative convolution to improve theefficiency for aggregating important environmental information. Experimentsshow that our method achieves significant improvements on three widely usedbenchmarks, KITTI, Cityscapes, and Make3D, setting a new state-of-the-artperformance on the popular benchmarks with all three types of self-supervision.", "output": "Self-Supervised Monocular Depth Estimation by Direction-aware Cumulative Convolution Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated medical report generation has become increasingly important inmedical analysis. It can produce computer-aided diagnosis descriptions and thussignificantly alleviate the doctors' work. Inspired by the huge success ofneural machine translation and image captioning, various deep learning methodshave been proposed for medical report generation. However, due to the inherentproperties of medical data, including data imbalance and the length andcorrelation between report sequences, the generated reports by existing methodsmay exhibit linguistic fluency but lack adequate clinical accuracy. In thiswork, we propose an image-to-indicator hierarchical transformer (IIHT)framework for medical report generation. It consists of three modules, i.e., aclassifier module, an indicator expansion module and a generator module. Theclassifier module first extracts image features from the input medical imagesand produces disease-related indicators with their corresponding states. Thedisease-related indicators are subsequently utilised as input for the indicatorexpansion module, incorporating the \"data-text-data\" strategy. Thetransformer-based generator then leverages these extracted features along withimage features as auxiliary information to generate final reports. Furthermore,the proposed IIHT method is feasible for radiologists to modify diseaseindicators in real-world scenarios and integrate the operations into theindicator expansion module for fluent and accurate medical report generation.Extensive experiments and comparisons with state-of-the-art methods undervarious evaluation metrics demonstrate the great performance of the proposedmethod.", "output": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video moment localization aims to retrieve the target segment of an untrimmedvideo according to the natural language query. Weakly supervised methods gainsattention recently, as the precise temporal location of the target segment isnot always available. However, one of the greatest challenges encountered bythe weakly supervised method is implied in the mismatch between the video andlanguage induced by the coarse temporal annotations. To refine thevision-language alignment, recent works contrast the cross-modalitysimilarities driven by reconstructing masked queries between positive andnegative video proposals. However, the reconstruction may be influenced by thelatent spurious correlation between the unmasked and the masked parts, whichdistorts the restoring process and further degrades the efficacy of contrastivelearning since the masked words are not completely reconstructed from thecross-modality knowledge. In this paper, we discover and mitigate this spuriouscorrelation through a novel proposed counterfactual cross-modality reasoningmethod. Specifically, we first formulate query reconstruction as an aggregatedcausal effect of cross-modality and query knowledge. Then by introducingcounterfactual cross-modality knowledge into this aggregation, the spuriousimpact of the unmasked part contributing to the reconstruction is explicitlymodeled. Finally, by suppressing the unimodal effect of masked query, we canrectify the reconstructions of video proposals to perform reasonablecontrastive learning. Extensive experimental evaluations demonstrate theeffectiveness of our proposed method. The code is available athref{", "output": "Counterfactual Cross-modality Reasoning for Weakly Supervised Video Moment Localization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Structural MRI and PET imaging play an important role in the diagnosis ofAlzheimer's disease (AD), showing the morphological changes and glucosemetabolism changes in the brain respectively. The manifestations in the brainimage of some cognitive impairment patients are relatively inconspicuous, forexample, it still has difficulties in achieving accurate diagnosis through sMRIin clinical practice. With the emergence of deep learning, convolutional neuralnetwork (CNN) has become a valuable method in AD-aided diagnosis, but some CNNmethods cannot effectively learn the features of brain image, making thediagnosis of AD still presents some challenges. In this work, we propose anend-to-end 3D CNN framework for AD diagnosis based on ResNet, which integratesmulti-layer features obtained under the effect of the attention mechanism tobetter capture subtle differences in brain images. The attention maps showedour model can focus on key brain regions related to the disease diagnosis. Ourmethod was verified in ablation experiments with two modality images on 792subjects from the ADNI database, where AD diagnostic accuracies of 89.71% and91.18% were achieved based on sMRI and PET respectively, and also outperformedsome state-of-the-art methods.", "output": "Attention-based 3D CNN with Multi-layer Features for Alzheimer's Disease Diagnosis using Brain Images."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although deep learning models have shown impressive performance on supervisedlearning tasks, they often struggle to generalize well when the training(source) and test (target) domains differ. Unsupervised domain adaptation (DA)has emerged as a popular solution to this problem. However, current DAtechniques rely on visual backbones, which may lack semantic richness. Despitethe potential of large-scale vision-language foundation models like CLIP, theireffectiveness for DA has yet to be fully explored. To address this gap, weintroduce AD-CLIP, a domain-agnostic prompt learning strategy for CLIP thataims to solve the DA problem in the prompt space. We leverage the frozen visionbackbone of CLIP to extract both image style (domain) and content information,which we apply to learn prompt tokens. Our prompts are designed to bedomain-invariant and class-generalizable, by conditioning prompt learning onimage style and content features simultaneously. We use standard supervisedcontrastive learning in the source domain, while proposing an entropyminimization strategy to align domains in the embedding space given the targetdomain data. We also consider a scenario where only target domain samples areavailable during testing, without any source domain data, and propose across-domain style mapping network to hallucinate domain-agnostic tokens. Ourextensive experiments on three benchmark DA datasets demonstrate theeffectiveness of AD-CLIP compared to existing literature.", "output": "AD-CLIP: Adapting Domains in Prompt Space Using CLIP."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The commonly adopted detect-then-match approach to registration findsdifficulties in the cross-modality cases due to the incompatible keypointdetection and inconsistent feature description. We propose, 2D3D-MATR, adetection-free method for accurate and robust registration between images andpoint clouds. Our method adopts a coarse-to-fine pipeline where it firstcomputes coarse correspondences between downsampled patches of the input imageand the point cloud and then extends them to form dense correspondences betweenpixels and points within the patch region. The coarse-level patch matching isbased on transformer which jointly learns global contextual constraints withself-attention and cross-modality correlations with cross-attention. To resolvethe scale ambiguity in patch matching, we construct a multi-scale pyramid foreach image patch and learn to find for each point patch the best matching imagepatch at a proper resolution level. Extensive experiments on two publicbenchmarks demonstrate that 2D3D-MATR outperforms the previous state-of-the-artP2-Net by around $20$ percentage points on inlier ratio and over $10$ points onregistration recall. Our code and models are available aturl{", "output": "2D3D-MATR: 2D-3D Matching Transformer for Detection-free Registration between Images and Point Clouds."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, methods for skeleton-based human activity recognition have beenshown to be vulnerable to adversarial attacks. However, these attack methodsrequire either the full knowledge of the victim (i.e. white-box attacks),access to training data (i.e. transfer-based attacks) or frequent model queries(i.e. black-box attacks). All their requirements are highly restrictive,raising the question of how detrimental the vulnerability is. In this paper, weshow that the vulnerability indeed exists. To this end, we consider a newattack task: the attacker has no access to the victim model or the trainingdata or labels, where we coin the term hard no-box attack. Specifically, wefirst learn a motion manifold where we define an adversarial loss to compute anew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Ourgradient contains information of the motion dynamics, which is different fromexisting gradient-based attack methods that compute the loss gradient assumingeach dimension in the data is independent. The SMI gradient can augment manygradient-based attack methods, leading to a new family of no-box attackmethods. Extensive evaluation and comparison show that our method imposes areal threat to existing classifiers. They also show that the SMI gradientimproves the transferability and imperceptibility of adversarial samples inboth no-box and transfer-based black-box settings.", "output": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Denoising diffusion probabilistic models have recently demonstratedstate-of-the-art generative performance and been used as strong pixel-levelrepresentation learners. This paper decomposes the interrelation between thegenerative capability and representation learning ability inherent in diffusionmodels. We present masked diffusion model (MDM), a scalable self-supervisedrepresentation learner that substitutes the conventional additive Gaussiannoise of traditional diffusion with a masking mechanism. Our proposed approachconvincingly surpasses prior benchmarks, demonstrating remarkable advancementsin both medical and natural image semantic segmentation tasks, particularlywithin the context of few-shot scenario.", "output": "Masked Diffusion as Self-supervised Representation Learner."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Discovering causal relations among semantic factors is an emergent topic inrepresentation learning. Most causal representation learning (CRL) methods arefully supervised, which is impractical due to costly labeling. To resolve thisrestriction, weakly supervised CRL methods were introduced. To evaluate CRLperformance, four existing datasets, Pendulum, Flow, CelebA(BEARD) andCelebA(SMILE), are utilized. However, existing CRL datasets are limited tosimple graphs with few generative factors. Thus we propose two new datasetswith a larger number of diverse generative factors and more sophisticatedcausal graphs. In addition, current real datasets, CelebA(BEARD) andCelebA(SMILE), the originally proposed causal graphs are not aligned with thedataset distributions. Thus, we propose modifications to them.", "output": "Shadow Datasets, New challenging datasets for Causal Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "CNNs and Transformers have their own advantages and both have been widelyused for dense prediction in multi-task learning (MTL). Most of the currentstudies on MTL solely rely on CNN or Transformer. In this work, we present anovel MTL model by combining both merits of deformable CNN and query-basedTransformer with shared gating for multi-task learning of dense prediction.This combination may offer a simple and efficient solution owing to itspowerful and flexible task-specific learning and advantages of lower cost, lesscomplexity and smaller parameters than the traditional MTL methods. Weintroduce deformable mixer Transformer with gating (DeMTG), a simple andeffective encoder-decoder architecture up-to-date that incorporates theconvolution and attention mechanism in a unified network for MTL. It isexquisitely designed to use advantages of each block, and provide deformableand comprehensive features for all tasks from local and global perspective.First, the deformable mixer encoder contains two types of operators: thechannel-aware mixing operator leveraged to allow communication among differentchannels, and the spatial-aware deformable operator with deformable convolutionapplied to efficiently sample more informative spatial locations. Second, thetask-aware gating transformer decoder is used to perform the task-specificpredictions, in which task interaction block integrated with self-attention isapplied to capture task interaction features, and the task query blockintegrated with gating attention is leveraged to select correspondingtask-specific features. Further, the experiment results demonstrate that theproposed DeMTG uses fewer GFLOPs and significantly outperforms currentTransformer-based and CNN-based competitive models on a variety of metrics onthree dense prediction datasets. Our code and models are available at", "output": "Deformable Mixer Transformer with Gating for Multi-Task Learning of Dense Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated driving has the potential to revolutionize personal, public, andfreight mobility. Besides the enormous challenge of perception, i.e. accuratelyperceiving the environment using available sensor data, automated drivingcomprises planning a safe, comfortable, and efficient motion trajectory. Topromote safety and progress, many works rely on modules that predict the futuremotion of surrounding traffic. Modular automated driving systems commonlyhandle prediction and planning as sequential separate tasks. While thisaccounts for the influence of surrounding traffic on the ego-vehicle, it failsto anticipate the reactions of traffic participants to the ego-vehicle'sbehavior. Recent works suggest that integrating prediction and planning in aninterdependent joint step is necessary to achieve safe, efficient, andcomfortable driving. While various models implement such integrated systems, acomprehensive overview and theoretical understanding of different principlesare lacking. We systematically review state-of-the-art deep learning-basedprediction, planning, and integrated prediction and planning models. Differentfacets of the integration ranging from model architecture and model design tobehavioral aspects are considered and related to each other. Moreover, wediscuss the implications, strengths, and limitations of different integrationmethods. By pointing out research gaps, describing relevant future challenges,and highlighting trends in the research field, we identify promising directionsfor future research.", "output": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "3D scene reconstruction is a long-standing vision task. Existing approachescan be categorized into geometry-based and learning-based methods. The formerleverages multi-view geometry but can face catastrophic failures due to thereliance on accurate pixel correspondence across views. The latter wasproffered to mitigate these issues by learning 2D or 3D representationdirectly. However, without a large-scale video or 3D training data, it canhardly generalize to diverse real-world scenarios due to the presence of tensof millions or even billions of optimization parameters in the deep network.Recently, robust monocular depth estimation models trained with large-scaledatasets have been proven to possess weak 3D geometry prior, but they areinsufficient for reconstruction due to the unknown camera parameters, theaffine-invariant property, and inter-frame inconsistency. Here, we propose anovel test-time optimization approach that can transfer the robustness ofaffine-invariant depth models such as LeReS to challenging diverse scenes whileensuring inter-frame consistency, with only dozens of parameters to optimizeper video frame. Specifically, our approach involves freezing the pre-trainedaffine-invariant depth model's depth predictions, rectifying them by optimizingthe unknown scale-shift values with a geometric consistency alignment module,and employing the resulting scale-consistent depth maps to robustly obtaincamera poses and achieve dense scene reconstruction, even in low-textureregions. Experiments show that our method achieves state-of-the-artcross-dataset reconstruction on five zero-shot testing datasets.", "output": "FrozenRecon: Pose-free 3D Scene Reconstruction with Frozen Depth Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "High-definition (HD) map provides abundant and precise static environmentalinformation of the driving scene, serving as a fundamental and indispensablecomponent for planning in autonomous driving system. In this paper, we presenttextbf{Map} textbf{TR}ansformer, an end-to-end framework for onlinevectorized HD map construction. We propose a unified permutation-equivalentmodeling approach, ie, modeling map element as a point set with a group ofequivalent permutations, which accurately describes the shape of map elementand stabilizes the learning process. We design a hierarchical query embeddingscheme to flexibly encode structured map information and perform hierarchicalbipartite matching for map element learning. To speed up convergence, wefurther introduce auxiliary one-to-many matching and dense supervision. Theproposed method well copes with various map elements with arbitrary shapes. Itruns at real-time inference speed and achieves state-of-the-art performance onboth nuScenes and Argoverse2 datasets. Abundant qualitative results show stableand robust map construction quality in complex and various driving scenes. Codeand more demos are available at url{ forfacilitating further studies and applications.", "output": "MapTRv2: An End-to-End Framework for Online Vectorized HD Map Construction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tracking and following objects of interest is critical to several roboticsuse cases, ranging from industrial automation to logistics and warehousing, tohealthcare and security. In this paper, we present a robotic system to detect,track, and follow any object in real-time. Our approach, dubbed ``followanything'' (FAn), is an open-vocabulary and multimodal model -- it is notrestricted to concepts seen at training time and can be applied to novelclasses at inference time using text, images, or click queries. Leveraging richvisual descriptors from large-scale pre-trained models (foundation models), FAncan detect and segment objects by matching multimodal queries (text, images,clicks) against an input image sequence. These detected and segmented objectsare tracked across image frames, all while accounting for occlusion and objectre-emergence. We demonstrate FAn on a real-world robotic system (a micro aerialvehicle) and report its ability to seamlessly follow the objects of interest ina real-time control loop. FAn can be deployed on a laptop with a lightweight(6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. Toenable rapid adoption, deployment, and extensibility, we open-source all ourcode on our project webpage at  .We also encourage the reader the watch our 5-minutes explainer video in this .", "output": "Follow Anything: Open-set detection, tracking, and following in real-time."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Gradient-based optimization is now ubiquitous across graphics, butunfortunately can not be applied to problems with undefined or zero gradients.To circumvent this issue, the loss function can be manually replaced by a\"surrogate\" that has similar minima but is differentiable. Our proposedframework, ZeroGrads, automates this process by learning a neural approximationof the objective function, the surrogate, which in turn can be used todifferentiate through arbitrary black-box graphics pipelines. We train thesurrogate on an actively smoothed version of the objective and encouragelocality, focusing the surrogate's capacity on what matters at the currenttraining episode. The fitting is performed online, alongside the parameteroptimization, and self-supervised, without pre-computed data or pre-trainedmodels. As sampling the objective is expensive (it requires a full rendering orsimulator run), we devise an efficient sampling scheme that allows fortractable run-times and competitive performance at little overhead. Wedemonstrate optimizing diverse non-convex, non-differentiable black-boxproblems in graphics, such as visibility in rendering, discrete parameterspaces in procedural modelling or optimal control in physics-driven animation.In contrast to more traditional algorithms, our approach scales well to higherdimensions, which we demonstrate on problems with up to 35k interlinkedvariables.", "output": "Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recent proliferation of 3D content that can be consumed on hand-helddevices necessitates efficient tools for transmitting large geometric data,e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose achallenge to storage as well as transmission bandwidth, and level-of-detailtechniques are often used to transmit an asset using an appropriate bandwidthbudget. It is especially desirable for these methods to transmit dataprogressively, improving the quality of the geometry with more data. Our keyinsight is that the geometric details of 3D meshes often exhibit similar localpatterns even across different shapes, and thus can be effectively representedwith a shared learned generative space. We learn this space using asubdivision-based encoder-decoder architecture trained in advance on a largecollection of surfaces. We further observe that additional residual featurescan be transmitted progressively between intermediate levels of subdivisionthat enable the client to control the tradeoff between bandwidth cost andquality of reconstruction, providing a neural progressive mesh representation.We evaluate our method on a diverse set of complex 3D shapes and demonstratethat it outperforms baselines in terms of compression ratio and reconstructionquality.", "output": "Neural Progressive Meshes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we develop a new method to automatically convert 2D linedrawings from three orthographic views into 3D CAD models. Existing methods forthis problem reconstruct 3D models by back-projecting the 2D observations into3D space while maintaining explicit correspondence between the input andoutput. Such methods are sensitive to errors and noises in the input, thusoften fail in practice where the input drawings created by human designers areimperfect. To overcome this difficulty, we leverage the attention mechanism ina Transformer-based sequence generation model to learn flexible mappingsbetween the input and output. Further, we design shape programs which aresuitable for generating the objects of interest to boost the reconstructionaccuracy and facilitate CAD modeling applications. Experiments on a newbenchmark dataset show that our method significantly outperforms existing oneswhen the inputs are noisy or incomplete.", "output": "PlankAssembly: Robust 3D Reconstruction from Three Orthographic Views with Learnt Shape Programs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this work we present a novel optimization strategy for imagereconstruction tasks under analysis-based image regularization, which promotessparse and/or low-rank solutions in some learned transform domain. Weparameterize such regularizers using potential functions that correspond toweighted extensions of the $ell_p^p$-vector and $mathcal{S}_p^p$Schatten-matrix quasi-norms with $0 &lt; p le 1$. Our proposed minimizationstrategy extends the Iteratively Reweighted Least Squares (IRLS) method,typically used for synthesis-based $ell_p$ and $mathcal{S}_p$ norm andanalysis-based $ell_1$ and nuclear norm regularization. We prove that undermild conditions our minimization algorithm converges linearly to a stationarypoint, and we provide an upper bound for its convergence rate. Further, toselect the parameters of the regularizers that deliver the best results for theproblem at hand, we propose to learn them from training data by formulating thesupervised learning process as a stochastic bilevel optimization problem. Weshow that thanks to the convergence guarantees of our proposed minimizationstrategy, such optimization can be successfully performed with amemory-efficient implicit back-propagation scheme. We implement our learnedIRLS variants as recurrent networks and assess their performance on thechallenging image reconstruction tasks of non-blind deblurring,super-resolution and demosaicking. The comparisons against other existinglearned reconstruction approaches demonstrate that our overall method is verycompetitive and in many cases outperforms existing unrolled networks, whosenumber of parameters is orders of magnitude higher than in our case.", "output": "Iterative Reweighted Least Squares Networks With Convergence Guarantees for Solving Inverse Imaging Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this study, we proposed and validated a multi-atlas guided 3D fullyconvolutional network (FCN) ensemble model (M-FCN) for segmenting brain regionsof interest (ROIs) from structural magnetic resonance images (MRIs). One majorlimitation of existing state-of-the-art 3D FCN segmentation models is that theyoften apply image patches of fixed size throughout training and testing, whichmay miss some complex tissue appearance patterns of different brain ROIs. Toaddress this limitation, we trained a 3D FCN model for each ROI using patchesof adaptive size and embedded outputs of the convolutional layers in thedeconvolutional layers to further capture the local and global contextpatterns. In addition, with an introduction of multi-atlas based guidance inM-FCN, our segmentation was generated by combining the information of imagesand labels, which is highly robust. To reduce over-fitting of the FCN model onthe training data, we adopted an ensemble strategy in the learning procedure.Evaluation was performed on two brain MRI datasets, aiming respectively atsegmenting 14 subcortical and ventricular structures and 54 brain ROIs. Thesegmentation results of the proposed method were compared with those of astate-of-the-art multi-atlas based segmentation method and an existing 3D FCNsegmentation model. Our results suggested that the proposed method had asuperior segmentation performance.", "output": "Brain segmentation based on multi-atlas guided 3D fully convolutional network ensembles."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Contrastive Language-Image Pre-training (CLIP) has drawn increasing attentionrecently for its transferable visual representation learning. However, due tothe semantic gap within datasets, CLIP's pre-trained image-text alignmentbecomes sub-optimal on downstream tasks, which severely harms its transferringperformance. To better adapt the cross-modality embedding space, we propose toenhance CLIP via Visual-guided Texts, named VT-CLIP. Specifically, we guidetextual features of different categories to adaptively explore informativeregions on the image and aggregate visual features by attention mechanisms. Inthis way, the texts become visual-guided, namely, more semantically correlatedwith downstream images, which greatly benefits the category-wise matchingprocess. In few-shot settings, we evaluate our VT-CLIP on 11 well-knownclassification datasets to demonstrate its effectiveness.", "output": "VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent years have witnessed great advances in object segmentation research.In addition to generic objects, aquatic animals have attracted researchattention. Deep learning-based methods are widely used for aquatic animalsegmentation and have achieved promising performance. However, there is a lackof challenging datasets for benchmarking. In this work, we build a new datasetdubbed Aquatic Animal Species. We also devise a novel GUided mixup augmeNtatioNand multi-modEl fusion for aquatic animaL segmentation (GUNNEL) that leveragesthe advantages of multiple segmentation models to effectively segment aquaticanimals and improves the training performance by synthesizing hard samples.Extensive experiments demonstrated the superiority of our proposed frameworkover existing state-of-the-art instance segmentation methods. The code isavailable at  The dataset is availableat  .", "output": "GUNNEL: Guided Mixup Augmentation and Multi-View Fusion for Aquatic Animal Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a novel masked image modeling (MIM) approach, context autoencoder(CAE), for self-supervised representation pretraining. We pretrain an encoderby making predictions in the encoded representation space. The pretrainingtasks include two tasks: masked representation prediction - predict therepresentations for the masked patches, and masked patch reconstruction -reconstruct the masked patches. The network is an encoder-regressor-decoderarchitecture: the encoder takes the visible patches as input; the regressorpredicts the representations of the masked patches, which are expected to bealigned with the representations computed from the encoder, using therepresentations of visible patches and the positions of visible and maskedpatches; the decoder reconstructs the masked patches from the predicted encodedrepresentations. The CAE design encourages the separation of learning theencoder (representation) from completing the pertaining tasks: maskedrepresentation prediction and masked patch reconstruction tasks, and makingpredictions in the encoded representation space empirically shows the benefitto representation learning. We demonstrate the effectiveness of our CAE throughsuperior transfer performance in downstream tasks: semantic segmentation,object detection and instance segmentation, and classification. The code willbe available at ", "output": "Context Autoencoder for Self-Supervised Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning disentangled representations with variational autoencoders (VAEs) isoften attributed to the regularisation component of the loss. In this work, wehighlight the interaction between data and the reconstruction term of the lossas the main contributor to disentanglement in VAEs. We show that standardbenchmark datasets have unintended correlations between their subjectiveground-truth factors and perceived axes in the data according to typical VAEreconstruction losses. Our work exploits this relationship to provide a theoryfor what constitutes an adversarial dataset under a given reconstruction loss.We verify this by constructing an example dataset that prevents disentanglementin state-of-the-art frameworks while maintaining human-intuitive ground-truthfactors. Finally, we re-enable disentanglement by designing an examplereconstruction loss that is once again able to perceive the ground-truthfactors. Our findings demonstrate the subjective nature of disentanglement andthe importance of considering the interaction between the ground-truth factors,data and notably, the reconstruction loss, which is under-recognised in theliterature.", "output": "Overlooked Implications of the Reconstruction Loss for VAE Disentanglement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although audio-visual representation has been proved to be applicable in manydownstream tasks, the representation of dancing videos, which is more specificand always accompanied by music with complex auditory contents, remainschallenging and uninvestigated. Considering the intrinsic alignment between thecadent movement of dancer and music rhythm, we introduce MuDaR, a novelMusic-Dance Representation learning framework to perform the synchronization ofmusic and dance rhythms both in explicit and implicit ways. Specifically, wederive the dance rhythms based on visual appearance and motion cues inspired bythe music rhythm analysis. Then the visual rhythms are temporally aligned withthe music counterparts, which are extracted by the amplitude of soundintensity. Meanwhile, we exploit the implicit coherence of rhythms implied inaudio and visual streams by contrastive learning. The model learns the jointembedding by predicting the temporal consistency between audio-visual pairs.The music-dance representation, together with the capability of detecting audioand visual rhythms, can further be applied to three downstream tasks: (a) danceclassification, (b) music-dance retrieval, and (c) music-dance retargeting.Extensive experiments demonstrate that our proposed framework outperforms otherself-supervised methods by a large margin.", "output": "Learning Music-Dance Representations through Explicit-Implicit Rhythm Synchronization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous navigation in agricultural environments is challenged by varyingfield conditions that arise in arable fields. State-of-the-art solutions forautonomous navigation in such environments require expensive hardware such asRTK-GNSS. This paper presents a robust crop row detection algorithm thatwithstands such field variations using inexpensive cameras. Existing datasetsfor crop row detection does not represent all the possible field variations. Adataset of sugar beet images was created representing 11 field variationscomprised of multiple grow stages, light levels, varying weed densities, curvedcrop rows and discontinuous crop rows. The proposed pipeline segments the croprows using a deep learning-based method and employs the predicted segmentationmask for extraction of the central crop using a novel central crop rowselection algorithm. The novel crop row detection algorithm was tested for croprow detection performance and the capability of visual servoing along a croprow. The visual servoing-based navigation was tested on a realistic simulationscenario with the real ground and plant textures. Our algorithm demonstratedrobust vision-based crop row detection in challenging field conditionsoutperforming the baseline.", "output": "Deep learning-based Crop Row Detection for Infield Navigation of Agri-Robots."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a successful approach to self-supervised learning, contrastive learningaims to learn invariant information shared among distortions of the inputsample. While contrastive learning has yielded continuous advancements insampling strategy and architecture design, it still remains two persistentdefects: the interference of task-irrelevant information and sampleinefficiency, which are related to the recurring existence of trivial constantsolutions. From the perspective of dimensional analysis, we find out that thedimensional redundancy and dimensional confounder are the intrinsic issuesbehind the phenomena, and provide experimental evidence to support ourviewpoint. We further propose a simple yet effective approach MetaMask, shortfor the dimensional Mask learned by Meta-learning, to learn representationsagainst dimensional redundancy and confounder. MetaMask adopts theredundancy-reduction technique to tackle the dimensional redundancy issue andinnovatively introduces a dimensional mask to reduce the gradient effects ofspecific dimensions containing the confounder, which is trained by employing ameta-learning paradigm with the objective of improving the performance ofmasked representations on a typical self-supervised task. We provide solidtheoretical analyses to prove MetaMask can obtain tighter risk bounds fordownstream classification compared to typical contrastive methods. Empirically,our method achieves state-of-the-art performance on various benchmarks.", "output": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "When applied to autonomous vehicle (AV) settings, action recognition canenhance an environment model's situational awareness. This is especiallyprevalent in scenarios where traditional geometric descriptions and heuristicsin AVs are insufficient. However, action recognition has traditionally beenstudied for humans, and its limited adaptability to noisy, un-clipped,un-pampered, raw RGB data has limited its application in other fields. To pushfor the advancement and adoption of action recognition into AVs, this workproposes a novel two-stage action recognition system, termed RALACs. RALACsformulates the problem of action recognition for road scenes, and bridges thegap between it and the established field of human action recognition. This workshows how attention layers can be useful for encoding the relations acrossagents, and stresses how such a scheme can be class-agnostic. Furthermore, toaddress the dynamic nature of agents on the road, RALACs constructs a novelapproach to adapting Region of Interest (ROI) Alignment to agent tracks fordownstream action classification. Finally, our scheme also considers theproblem of active agent detection, and utilizes a novel application of fusingoptical flow maps to discern relevant agents in a road scene. We show that ourproposed scheme can outperform the baseline on the ICCV2021 Road Challengedataset and by deploying it on a real vehicle platform, we provide preliminaryinsight to the usefulness of action recognition in decision making.", "output": "RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper uses symmetry to make Convolutional Neural Network classifiers(CNNs) robust against adversarial perturbation attacks. Such attacks addperturbation to original images to generate adversarial images that foolclassifiers such as road sign classifiers of autonomous vehicles. Althoughsymmetry is a pervasive aspect of the natural world, CNNs are unable to handlesymmetry well. For example, a CNN can classify an image differently from itsmirror image. For an adversarial image that misclassifies with a wrong label$l_w$, CNN inability to handle symmetry means that a symmetric adversarialimage can classify differently from the wrong label $l_w$. Further than that,we find that the classification of a symmetric adversarial image reverts to thecorrect label. To classify an image when adversaries are unaware of thedefense, we apply symmetry to the image and use the classification label of thesymmetric image. To classify an image when adversaries are aware of thedefense, we use mirror symmetry and pixel inversion symmetry to form a symmetrygroup. We apply all the group symmetries to the image and decide on the outputlabel based on the agreement of any two of the classification labels of thesymmetry images. Adaptive attacks fail because they need to rely on lossfunctions that use conflicting CNN output values for symmetric images. Withoutattack knowledge, the proposed symmetry defense succeeds against bothgradient-based and random-search attacks, with up to near-default accuraciesfor ImageNet. The defense even improves the classification accuracy of originalimages.", "output": "Symmetry Defense Against CNN Adversarial Perturbation Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report describes our approach for the Audio-Visual Diarization (AVD)task of the Ego4D Challenge 2022. Specifically, we present multiple technicalimprovements over the official baselines. First, we improve the detectionperformance of the camera wearer's voice activity by modifying the trainingscheme of its model. Second, we discover that an off-the-shelf voice activitydetection model can effectively remove false positives when it is appliedsolely to the camera wearer's voice activities. Lastly, we show that betteractive speaker detection leads to a better AVD outcome. Our final methodobtains 65.9% DER on the test set of Ego4D, which significantly outperforms allthe baselines. Our submission achieved 1st place in the Ego4D Challenge 2022.", "output": "Intel Labs at Ego4D Challenge 2022: A Better Baseline for Audio-Visual Diarization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently proposed large-scale text-to-image generative models such asDALL$cdot$E 2, Midjourney, and StableDiffusion can generate high-quality andrealistic images from users' prompts. Not limited to the research community,ordinary Internet users enjoy these generative models, and consequently, atremendous amount of generated images have been shared on the Internet.Meanwhile, today's success of deep learning in the computer vision field owes alot to images collected from the Internet. These trends lead us to a researchquestion: \"textbf{will such generated images impact the quality of futuredatasets and the performance of computer vision models positively ornegatively?}\" This paper empirically answers this question by simulatingcontamination. Namely, we generate ImageNet-scale and COCO-scale datasets usinga state-of-the-art generative model and evaluate models trained with\"contaminated\" datasets on various tasks, including image classification andimage generation. Throughout experiments, we conclude that generated imagesnegatively affect downstream performance, while the significance depends ontasks and the amount of generated images. The generated datasets and the codesfor experiments will be publicly released for future research. Generateddatasets and source codes are available fromurl{", "output": "Will Large-scale Generative Models Corrupt Future Datasets?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we introduce a set of simple yet effective TOken REduction(TORE) strategies for Transformer-based Human Mesh Recovery from monocularimages. Current SOTA performance is achieved by Transformer-based structures.However, they suffer from high model complexity and computation cost caused byredundant tokens. We propose token reduction strategies based on two importantaspects, i.e., the 3D geometry structure and 2D image feature, where wehierarchically recover the mesh geometry with priors from body structure andconduct token clustering to pass fewer but more discriminative image featuretokens to the Transformer. Our method massively reduces the number of tokensinvolved in high-complexity interactions in the Transformer. This leads to asignificantly reduced computational cost while still achieving competitive oreven higher accuracy in shape recovery. Extensive experiments across a widerange of benchmarks validate the superior effectiveness of the proposed method.We further demonstrate the generalizability of our method on hand meshrecovery. Visit our project page at", "output": "TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The goal of this paper is to extract the visual-language correspondence froma pre-trained text-to-image diffusion model, in the form of segmentation map,i.e., simultaneously generating images and segmentation masks for thecorresponding visual entities described in the text prompt. We make thefollowing contributions: (i) we pair the existing Stable Diffusion model with anovel grounding module, that can be trained to align the visual and textualembedding space of the diffusion model with only a small number of objectcategories; (ii) we establish an automatic pipeline for constructing a dataset,that consists of {image, segmentation mask, text prompt} triplets, to train theproposed grounding module; (iii) we evaluate the performance of open-vocabularygrounding on images generated from the text-to-image diffusion model and showthat the module can well segment the objects of categories beyond seen ones attraining time; (iv) we adopt the augmented diffusion model to build a syntheticsemantic segmentation dataset, and show that, training a standard segmentationmodel on such dataset demonstrates competitive performance on the zero-shotsegmentation(ZS3) benchmark, which opens up new opportunities for adopting thepowerful diffusion model for discriminative tasks.", "output": "Open-vocabulary Object Segmentation with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Acquiring fully-sampled MRI $k$-space data is time-consuming, and collectingaccelerated data can reduce the acquisition time. Employing 2DCartesian-rectilinear subsampling schemes is a conventional approach foraccelerated acquisitions; however, this often results in imprecisereconstructions, even with the use of Deep Learning (DL), especially at highacceleration factors. Non-rectilinear or non-Cartesian trajectories can beimplemented in MRI scanners as alternative subsampling options. This workinvestigates the impact of the $k$-space subsampling scheme on the quality ofreconstructed accelerated MRI measurements produced by trained DL models. TheRecurrent Variational Network (RecurrentVarNet) was used as the DL-basedMRI-reconstruction architecture. Cartesian, fully-sampled multi-coil $k$-spacemeasurements from three datasets were retrospectively subsampled with differentaccelerations using eight distinct subsampling schemes: fourCartesian-rectilinear, two Cartesian non-rectilinear, and two non-Cartesian.Experiments were conducted in two frameworks: scheme-specific, where a distinctmodel was trained and evaluated for each dataset-subsampling scheme pair, andmulti-scheme, where for each dataset a single model was trained on datarandomly subsampled by any of the eight schemes and evaluated on datasubsampled by all schemes. In both frameworks, RecurrentVarNets trained andevaluated on non-rectilinearly subsampled data demonstrated superiorperformance, particularly for high accelerations. In the multi-scheme setting,reconstruction performance on rectilinearly subsampled data improved whencompared to the scheme-specific experiments. Our findings demonstrate thepotential for using DL-based methods, trained on non-rectilinearly subsampledmeasurements, to optimize scan time and image quality.", "output": "On Retrospective k-space Subsampling schemes For Deep MRI Reconstruction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Standard unsupervised domain adaptation methods adapt models from a source toa target domain using labeled source data and unlabeled target data jointly. Inmodel adaptation, on the other hand, access to the labeled source data isprohibited, i.e., only the source-trained model and unlabeled target data areavailable. We investigate normal-to-adverse condition model adaptation forsemantic segmentation, whereby image-level correspondences are available in thetarget domain. The target set consists of unlabeled pairs of adverse- andnormal-condition street images taken at GPS-matched locations. Our method --CMA -- leverages such image pairs to learn condition-invariant features viacontrastive learning. In particular, CMA encourages features in the embeddingspace to be grouped according to their condition-invariant semantic content andnot according to the condition under which respective inputs are captured. Toobtain accurate cross-domain semantic correspondences, we warp the normal imageto the viewpoint of the adverse image and leverage warp-confidence scores tocreate robust, aggregated features. With this approach, we achievestate-of-the-art semantic segmentation performance for model adaptation onseveral normal-to-adverse adaptation benchmarks, such as ACDC and Dark Zurich.We also evaluate CMA on a newly procured adverse-condition generalizationbenchmark and report favorable results compared to standard unsupervised domainadaptation methods, despite the comparative handicap of CMA due to source datainaccessibility. Code is available at ", "output": "Contrastive Model Adaptation for Cross-Condition Robustness in Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The decentralized and privacy-preserving nature of federated learning (FL)makes it vulnerable to backdoor attacks aiming to manipulate the behavior ofthe resulting model on specific adversary-chosen inputs. However, most existingdefenses based on statistical differences take effect only against specificattacks, especially when the malicious gradients are similar to benign ones orthe data are highly non-independent and identically distributed (non-IID). Inthis paper, we revisit the distance-based defense methods and discover that i)Euclidean distance becomes meaningless in high dimensions and ii) maliciousgradients with diverse characteristics cannot be identified by a single metric.To this end, we present a simple yet effective defense strategy withmulti-metrics and dynamic weighting to identify backdoors adaptively.Furthermore, our novel defense has no reliance on predefined assumptions overattack settings or data distributions and little impact on benign performance.To evaluate the effectiveness of our approach, we conduct comprehensiveexperiments on different datasets under various attack settings, where ourmethod achieves the best defensive performance. For instance, we achieve thelowest backdoor accuracy of 3.06% under the difficult Edge-case PGD, showingsignificant superiority over previous defenses. The results also demonstratethat our method can be well-adapted to a wide range of non-IID degrees withoutsacrificing the benign performance.", "output": "Multi-metrics adaptively identifies backdoors in Federated learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present Generative Semantic Segmentation (GSS), a generative learningapproach for semantic segmentation. Uniquely, we cast semantic segmentation asan image-conditioned mask generation problem. This is achieved by replacing theconventional per-pixel discriminative learning with a latent prior learningprocess. Specifically, we model the variational posterior distribution oflatent variables given the segmentation mask. To that end, the segmentationmask is expressed with a special type of image (dubbed as maskige). Thisposterior distribution allows to generate segmentation masks unconditionally.To achieve semantic segmentation on a given image, we further introduce aconditioning network. It is optimized by minimizing the divergence between theposterior distribution of maskige (i.e., segmentation masks) and the latentprior distribution of input training images. Extensive experiments on standardbenchmarks show that our GSS can perform competitively to prior artalternatives in the standard semantic segmentation setting, whilst achieving anew state of the art in the more challenging cross-domain setting.", "output": "Generative Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Although point cloud registration has achieved remarkable advances inobject-level and indoor scenes, large-scale registration methods are rarelyexplored. Challenges mainly arise from the huge point number, complexdistribution, and outliers of outdoor LiDAR scans. In addition, most existingregistration works generally adopt a two-stage paradigm: They first findcorrespondences by extracting discriminative local features and then leverageestimators (eg. RANSAC) to filter outliers, which are highly dependent onwell-designed descriptors and post-processing choices. To address theseproblems, we propose an end-to-end transformer network (RegFormer) forlarge-scale point cloud alignment without any further post-processing.Specifically, a projection-aware hierarchical transformer is proposed tocapture long-range dependencies and filter outliers by extracting pointfeatures globally. Our transformer has linear complexity, which guarantees highefficiency even for large-scale scenes. Furthermore, to effectively reducemismatches, a bijective association transformer is designed for regressing theinitial transformation. Extensive experiments on KITTI and NuScenes datasetsdemonstrate that our RegFormer achieves competitive performance in terms ofboth accuracy and efficiency.", "output": "RegFormer: An Efficient Projection-Aware Transformer Network for Large-Scale Point Cloud Registration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As the use of machine learning continues to expand, the importance ofensuring its safety cannot be overstated. A key concern in this regard is theability to identify whether a given sample is from the training distribution,or is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries canmanipulate OOD samples in ways that lead a classifier to make a confidentprediction. In this study, we present a novel approach for certifying therobustness of OOD detection within a $ell_2$-norm around the input, regardlessof network architecture and without the need for specific components oradditional training. Further, we improve current techniques for detectingadversarial attacks on OOD samples, while providing high levels of certifiedand adversarial robustness on in-distribution samples. The average of all OODdetection metrics on CIFAR10/100 shows an increase of $sim 13 % / 5%$relative to previous approaches.", "output": "Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Robotic underwater systems, e.g., Autonomous Underwater Vehicles (AUVs) andRemotely Operated Vehicles (ROVs), are promising tools for collectingbiogeochemical data at the ice-water interface for scientific advancements.However, state estimation, i.e., localization, is a well-known problem forrobotic systems, especially, for the ones that travel underwater. In thispaper, we present a tightly-coupled multi-sensors fusion framework to increaselocalization accuracy that is robust to sensor failure. Visual images, DopplerVelocity Log (DVL), Inertial Measurement Unit (IMU) and Pressure sensor areintegrated into the state-of-art Multi-State Constraint Kalman Filter (MSCKF)for state estimation. Besides that a new keyframe-based state clone mechanismand a new DVL-aided feature enhancement are presented to further improve thelocalization performance. The proposed method is validated with a data setcollected in the field under frozen ice, and the result is compared with 6other different sensor fusion setups. Overall, the result with the keyframeenabled and DVL-aided feature enhancement yields the best performance with aRoot-mean-square error of less than 2 m compared to the ground truth path witha total traveling distance of about 200 m.", "output": "Tightly-coupled Visual-DVL-Inertial Odometry for Robot-based Ice-water Boundary Exploration."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Audio-visual segmentation (AVS) is a complex task that involves accuratelysegmenting the corresponding sounding object based on audio-visual queries.Successful audio-visual learning requires two essential components: 1) anunbiased dataset with high-quality pixel-level multi-class labels, and 2) amodel capable of effectively linking audio information with its correspondingvisual object. However, these two requirements are only partially addressed bycurrent methods, with training sets containing biased audio-visual data, andmodels that generalise poorly beyond this biased training set. In this work, wepropose a new strategy to build cost-effective and relatively unbiasedaudio-visual semantic segmentation benchmarks. Our strategy, called VisualPost-production (VPO), explores the observation that it is not necessary tohave explicit audio-visual pairs extracted from single video sources to buildsuch benchmarks. We also refine the previously proposed AVSBench to transformit into the audio-visual semantic segmentation benchmark AVSBench-Single+.Furthermore, this paper introduces a new pixel-wise audio-visual contrastivelearning method to enable a better generalisation of the model beyond thetraining set. We verify the validity of the VPO strategy by showing thatstate-of-the-art (SOTA) models trained with datasets built by matching audioand visual data from different sources or with datasets containing audio andvisual data from the same video source produce almost the same accuracy. Then,using the proposed VPO benchmarks and AVSBench-Single+, we show that our methodproduces more accurate audio-visual semantic segmentation than SOTA models.Code and dataset will be available.", "output": "A Closer Look at Audio-Visual Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image inpainting task refers to erasing unwanted pixels from images andfilling them in a semantically consistent and realistic way. Traditionally, thepixels that are wished to be erased are defined with binary masks. From theapplication point of view, a user needs to generate the masks for the objectsthey would like to remove which can be time-consuming and prone to errors. Inthis work, we are interested in an image inpainting algorithm that estimateswhich object to be removed based on natural language input and removes it,simultaneously. For this purpose, first, we construct a dataset namedGQA-Inpaint for this task. Second, we present a novel inpainting framework,Inst-Inpaint, that can remove objects from images based on the instructionsgiven as text prompts. We set various GAN and diffusion-based baselines and runexperiments on synthetic and real image datasets. We compare methods withdifferent evaluation metrics that measure the quality and accuracy of themodels and show significant quantitative and qualitative improvements.", "output": "Inst-Inpaint: Instructing to Remove Objects with Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multiview clustering (MVC) aims to reveal the underlying structure ofmultiview data by categorizing data samples into clusters. Deep learning-basedmethods exhibit strong feature learning capabilities on large-scale datasets.For most existing deep MVC methods, exploring the invariant representations ofmultiple views is still an intractable problem. In this paper, we propose across-view contrastive learning (CVCL) method that learns view-invariantrepresentations and produces clustering results by contrasting the clusterassignments among multiple views. Specifically, we first employ deepautoencoders to extract view-dependent features in the pretraining stage. Then,a cluster-level CVCL strategy is presented to explore consistent semantic labelinformation among the multiple views in the fine-tuning stage. Thus, theproposed CVCL method is able to produce more discriminative cluster assignmentsby virtue of this learning strategy. Moreover, we provide a theoreticalanalysis of soft cluster assignment alignment. Extensive experimental resultsobtained on several datasets demonstrate that the proposed CVCL methodoutperforms several state-of-the-art approaches.", "output": "Deep Multiview Clustering by Contrasting Cluster Assignments."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in visual-language models have shown remarkable zero-shottext-image matching ability that is transferable to downstream tasks such asobject detection and segmentation. Adapting these models for object counting,however, remains a formidable challenge. In this study, we first investigatetransferring vision-language models (VLMs) for class-agnostic object counting.Specifically, we propose CLIP-Count, the first end-to-end pipeline thatestimates density maps for open-vocabulary objects with text guidance in azero-shot manner. To align the text embedding with dense visual features, weintroduce a patch-text contrastive loss that guides the model to learninformative patch-level visual representations for dense prediction. Moreover,we design a hierarchical patch-text interaction module to propagate semanticinformation across different resolution levels of visual features. Benefitingfrom the full exploitation of the rich image-text alignment knowledge ofpretrained VLMs, our method effectively generates high-quality density maps forobjects-of-interest. Extensive experiments on FSC-147, CARPK, and ShanghaiTechcrowd counting datasets demonstrate state-of-the-art accuracy andgeneralizability of the proposed method. Code is available:", "output": "CLIP-Count: Towards Text-Guided Zero-Shot Object Counting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This report introduces our novel method named STHG for the Audio-VisualDiarization task of the Ego4D Challenge 2023. Our key innovation is that wemodel all the speakers in a video using a single, unified heterogeneous graphlearning framework. Unlike previous approaches that require a separatecomponent solely for the camera wearer, STHG can jointly detect the speechactivities of all people including the camera wearer. Our final method obtains61.1% DER on the test set of Ego4D, which significantly outperforms all thebaselines as well as last year's winner. Our submission achieved 1st place inthe Ego4D Challenge 2023. We additionally demonstrate that applying theoff-the-shelf speech recognition system to the diarized speech segments by STHGproduces a competitive performance on the Speech Transcription task of thischallenge.", "output": "STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced Audio-Visual Diarization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "General-purpose foundation models have become increasingly important in thefield of artificial intelligence. While self-supervised learning (SSL) andMasked Image Modeling (MIM) have led to promising results in building suchfoundation models for remote sensing, these models primarily learn low-levelfeatures, require annotated data for fine-tuning, and not applicable forretrieval and zero-shot applications due to the lack of language understanding.In response to these limitations, we propose RemoteCLIP, the firstvision-language foundation model for remote sensing that aims to learn robustvisual features with rich semantics, as well as aligned text embeddings forseamless downstream application. To address the scarcity of pre-training data,we leverage data scaling, converting heterogeneous annotations based onBox-to-Caption (B2C) and Mask-to-Box (M2B) conversion, and furtherincorporating UAV imagery, resulting a 12xlarger pretraining dataset.RemoteCLIP can be applied to a variety of downstream tasks, including zero-shotimage classification, linear probing, k-NN classification, few-shotclassification, image-text retrieval, and object counting. Evaluations on 16datasets, including a newly introduced RemoteCount benchmark to test the objectcounting ability, show that RemoteCLIP consistently outperforms baselinefoundation models across different model scales. Impressively, RemoteCLIPoutperform previous SoTA by 9.14% mean recall on RSICD dataset and by 8.92% onRSICD dataset. For zero-shot classification, our RemoteCLIP outperform CLIPbaseline by up to 6.39% average accuracy on 12 downstream datasets.Pretrainedmodels is available at  .", "output": "RemoteCLIP: A Vision Language Foundation Model for Remote Sensing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent diffusion probabilistic models (DPMs) have shown remarkable abilitiesof generated content, however, they often suffer from complex forwardprocesses, resulting in inefficient solutions for the reversed process andprolonged sampling times. In this paper, we aim to address the aforementionedchallenges by focusing on the diffusion process itself that we propose todecouple the intricate diffusion process into two comparatively simpler processto improve the generative efficacy and speed. In particular, we present a noveldiffusion paradigm named DDM (Decoupled Diffusion Models) based on the Itodiffusion process, in which the image distribution is approximated by anexplicit transition probability while the noise path is controlled by thestandard Wiener process. We find that decoupling the diffusion process reducesthe learning difficulty and the explicit transition probability improves thegenerative speed significantly. We prove a new training objective for DPM,which enables the model to learn to predict the noise and image componentsseparately. Moreover, given the novel forward diffusion equation, we derive thereverse denoising formula of DDM that naturally supports fewer steps ofgeneration without ordinary differential equation (ODE) based accelerators. Ourexperiments demonstrate that DDM outperforms previous DPMs by a large margin infewer function evaluations setting and gets comparable performances in longfunction evaluations setting. We also show that our framework can be applied toimage-conditioned generation and high-resolution image synthesis, and that itcan generate high-quality images with only 10 function evaluations.", "output": "Decoupled Diffusion Models with Explicit Transition Probability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces MVDiffusion, a simple yet effective method forgenerating consistent multi-view images from text prompts given pixel-to-pixelcorrespondences (e.g., perspective crops from a panorama or multi-view imagesgiven depth maps and poses). Unlike prior methods that rely on iterative imagewarping and inpainting, MVDiffusion simultaneously generates all images with aglobal awareness, effectively addressing the prevalent error accumulationissue. At its core, MVDiffusion processes perspective images in parallel with apre-trained text-to-image diffusion model, while integrating novelcorrespondence-aware attention layers to facilitate cross-view interactions.For panorama generation, while only trained with 10k panoramas, MVDiffusion isable to generate high-resolution photorealistic images for arbitrary texts orextrapolate one perspective image to a 360-degree view. For multi-viewdepth-to-image generation, MVDiffusion demonstrates state-of-the-artperformance for texturing a scene mesh. The project page is at", "output": "MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (DA) with the aid of pseudo labelingtechniques has emerged as a crucial approach for domain-adaptive 3D objectdetection. While effective, existing DA methods suffer from a substantial dropin performance when applied to a multi-class training setting, due to theco-existence of low-quality pseudo labels and class imbalance issues. In thispaper, we address this challenge by proposing a novel ReDB framework tailoredfor learning to detect all classes at once. Our approach produces Reliable,Diverse, and class-Balanced pseudo 3D boxes to iteratively guide theself-training on a distributionally different target domain. To alleviatedisruptions caused by the environmental discrepancy (e.g., beam numbers), theproposed cross-domain examination (CDE) assesses the correctness of pseudolabels by copy-pasting target instances into a source environment and measuringthe prediction consistency. To reduce computational overhead and mitigate theobject shift (e.g., scales and point densities), we design an overlapped boxescounting (OBC) metric that allows to uniformly downsample pseudo-labeledobjects across different geometric characteristics. To confront the issue ofinter-class imbalance, we progressively augment the target point clouds with aclass-balanced set of pseudo-labeled target instances and source objects, whichboosts recognition accuracies on both frequently appearing and rare classes.Experimental results on three benchmark datasets using both voxel-based (i.e.,SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that ourproposed ReDB approach outperforms existing 3D domain adaptation methods by alarge margin, improving 23.15% mAP on the nuScenes $rightarrow$ KITTI task.The code is available at ", "output": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Optical metasurfaces composed of precisely engineered nanostructures havegained significant attention for their ability to manipulate light andimplement distinct functionalities based on the properties of the incidentfield. Computational imaging systems have started harnessing this capability toproduce sets of coded measurements that benefit certain tasks when paired withdigital post-processing. Inspired by these works, we introduce a new systemthat uses a birefringent metasurface with a polarizer-mosaicked photosensor tocapture four optically-coded measurements in a single exposure. We apply thissystem to the task of incoherent opto-electronic filtering, where digitalspatial-filtering operations are replaced by simpler, per-pixel sums across thefour polarization channels, independent of the spatial filter size. In contrastto previous work on incoherent opto-electronic filtering that can realize onlyone spatial filter, our approach can realize a continuous family of filtersfrom a single capture, with filters being selected from the family by adjustingthe post-capture digital summation weights. To find a metasurface that canrealize a set of user-specified spatial filters, we introduce a form ofgradient descent with a novel regularizer that encourages light efficiency anda high signal-to-noise ratio. We demonstrate several examples in simulation andwith fabricated prototypes, including some with spatial filters that haveprescribed variations with respect to depth and wavelength.Visit the Project Page at", "output": "Polarization Multi-Image Synthesis with Birefringent Metasurfaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video depth estimation aims to infer temporally consistent depth. Somemethods achieve temporal consistency by finetuning a single-image depth modelduring test time using geometry and re-projection constraints, which isinefficient and not robust. An alternative approach is to learn how to enforcetemporal consistency from data, but this requires well-designed models andsufficient video depth data. To address these challenges, we propose aplug-and-play framework called Neural Video Depth Stabilizer (NVDS) thatstabilizes inconsistent depth estimations and can be applied to differentsingle-image depth models without extra effort. We also introduce a large-scaledataset, Video Depth in the Wild (VDW), which consists of 14,203 videos withover two million frames, making it the largest natural-scene video depthdataset to our knowledge. We evaluate our method on the VDW dataset as well astwo public benchmarks and demonstrate significant improvements in consistency,accuracy, and efficiency compared to previous approaches. Our work serves as asolid baseline and provides a data foundation for learning-based video depthmodels. We will release our dataset and code for future research.", "output": "Neural Video Depth Stabilizer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent text-to-image diffusion models have demonstrated an astonishingcapacity to generate high-quality images. However, researchers mainly studiedthe way of synthesizing images with only text prompts. While some works haveexplored using other modalities as conditions, considerable paired data, e.g.,box/mask-image pairs, and fine-tuning time are required for nurturing models.As such paired data is time-consuming and labor-intensive to acquire andrestricted to a closed set, this potentially becomes the bottleneck forapplications in an open world. This paper focuses on the simplest form ofuser-provided conditions, e.g., box or scribble. To mitigate the aforementionedproblem, we propose a training-free method to control objects and contexts inthe synthesized images adhering to the given spatial conditions. Specifically,three spatial constraints, i.e., Inner-Box, Outer-Box, and Corner Constraints,are designed and seamlessly integrated into the denoising step of diffusionmodels, requiring no additional training and massive annotated layout data.Extensive results show that the proposed constraints can control what and whereto present in the images while retaining the ability of the Stable Diffusionmodel to synthesize with high fidelity and diverse concept coverage. The codeis publicly available at ", "output": "BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Human mesh reconstruction from a single image is challenging in the presenceof occlusion, which can be caused by self, objects, or other humans. Existingmethods either fail to separate human features accurately or lack propersupervision for feature completion. In this paper, we propose Dense InpaintingHuman Mesh Recovery (DIMR), a two-stage method that leverages densecorrespondence maps to handle occlusion. Our method utilizes a densecorrespondence map to separate visible human features and completes humanfeatures on a structured UV map dense human with an attention-based featurecompletion module. We also design a feature inpainting training procedure thatguides the network to learn from unoccluded features. We evaluate our method onseveral datasets and demonstrate its superior performance under heavilyoccluded scenarios compared to other methods. Extensive experiments show thatour method obviously outperforms prior SOTA methods on heavily occluded imagesand achieves comparable results on the standard benchmarks (3DPW).", "output": "Learning Dense UV Completion for Human Mesh Recovery."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper details the challenges in applying two computer vision systems, anEfficientDET supervised learning model and the unsupervised RX spectralclassifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search andrescue (WSAR) effort in Japan and identifies 3 directions for future research.There have been at least 19 proposed approaches and 3 datasets aimed atlocating missing persons in drone imagery, but only 3 approaches (2unsupervised and 1 of an unknown structure) are referenced in the literature ashaving been used in an actual WSAR operation. Of these proposed approaches, theEfficientDET architecture and the unsupervised spectral RX classifier wereselected as the most appropriate for this setting. The EfficientDET model wasapplied to the HERIDAL dataset and despite achieving performance that isstatistically equivalent to the state-of-the-art, the model fails to translateto the real world in terms of false positives (e.g., identifying tree limbs androcks as people), and false negatives (e.g., failing to identify members of thesearch team). The poor results in practice for algorithms that showed goodresults on datasets suggest 3 areas of future research: more realistic datasetsfor wilderness SAR, computer vision models that are capable of seamlesslyhandling the variety of imagery that can be collected during actual WSARoperations, and better alignment on performance measures.", "output": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent research in language-guided visual navigation has demonstrated asignificant demand for the diversity of traversable environments and thequantity of supervision for training generalizable agents. To tackle the commondata scarcity issue in existing vision-and-language navigation datasets, wepropose an effective paradigm for generating large-scale data for learning,which applies 1200+ photo-realistic environments from HM3D and Gibson datasetsand synthesizes 4.9 million instruction trajectory pairs using fully-accessibleresources on the web. Importantly, we investigate the influence of eachcomponent in this paradigm on the agent's performance and study how toadequately apply the augmented data to pre-train and fine-tune an agent. Thanksto our large-scale dataset, the performance of an existing agent can be pushedup (+11% absolute with regard to previous SoTA) to a significantly new best of80% single-run success rate on the R2R test split by simple imitation learning.The long-lasting generalization gap between navigating in seen and unseenenvironments is also reduced to less than 1% (versus 8% in the previous bestmethod). Moreover, our paradigm also facilitates different models to achievenew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuousenvironments.", "output": "Scaling Data Generation in Vision-and-Language Navigation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable toadversarial examples, threatening their practical deployment. Despite the manyresearch endeavors have been made to tackle this issue in recent years, thediversity of adversarial examples on 3D point clouds makes them morechallenging to defend against than those on 2D images. For examples, attackerscan generate adversarial examples by adding, shifting, or removing points.Consequently, existing defense strategies are hard to counter unseen pointcloud adversarial examples. In this paper, we first establish a comprehensive,and rigorous point cloud adversarial robustness benchmark to evaluateadversarial robustness, which can provide a detailed understanding of theeffects of the defense and attack methods. We then collect existing defensetricks in point cloud adversarial defenses and then perform extensive andsystematic experiments to identify an effective combination of these tricks.Furthermore, we propose a hybrid training augmentation methods that considervarious types of point cloud adversarial examples to adversarial training,significantly improving the adversarial robustness. By combining these tricks,we construct a more robust defense framework achieving an average accuracy of83.45% against various attacks, demonstrating its capability to enablingrobust learners. Our codebase are open-sourced on:url{", "output": "Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large text-to-image diffusion models have achieved remarkable success ingenerating diverse, high-quality images. Additionally, these models have beensuccessfully leveraged to edit input images by just changing the text prompt.But when these models are applied to videos, the main challenge is to ensuretemporal consistency and coherence across frames. In this paper, we proposeInFusion, a framework for zero-shot text-based video editing leveraging largepre-trained image diffusion models. Our framework specifically supports editingof multiple concepts with pixel-level control over diverse concepts mentionedin the editing prompt. Specifically, we inject the difference in featuresobtained with source and edit prompts from U-Net residual blocks of decoderlayers. When these are combined with injected attention features, it becomesfeasible to query the source contents and scale edited concepts along with theinjection of unedited parts. The editing is further controlled in afine-grained manner with mask extraction and attention fusion, which cut theedited part from the source and paste it into the denoising pipeline for theediting prompt. Our framework is a low-cost alternative to one-shot tunedmodels for editing since it does not require training. We demonstrated complexconcept editing with a generalised image model (Stable Diffusion v1.5) usingLoRA. Adaptation is compatible with all the existing image diffusiontechniques. Extensive experimental results demonstrate the effectiveness ofexisting methods in rendering high-quality and temporally consistent videos.", "output": "InFusion: Inject and Attention Fusion for Multi Concept Zero-Shot Text-based Video Editing."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Nucleus image segmentation is a crucial step in the analysis, pathologicaldiagnosis, and classification, which heavily relies on the quality of nucleussegmentation. However, the complexity of issues such as variations in nucleussize, blurred nucleus contours, uneven staining, cell clustering, andoverlapping cells poses significant challenges. Current methods for nucleussegmentation primarily rely on nuclear morphology or contour-based approaches.Nuclear morphology-based methods exhibit limited generalization ability andstruggle to effectively predict irregular-shaped nuclei, while contour-basedextraction methods face challenges in accurately segmenting overlapping nuclei.To address the aforementioned issues, we propose a dual-branch network usinghybrid attention based residual U-blocks for nucleus instance segmentation. Thenetwork simultaneously predicts target information and target contours.Additionally, we introduce a post-processing method that combines the targetinformation and target contours to distinguish overlapping nuclei and generatean instance segmentation image. Within the network, we propose a context fusionblock (CF-block) that effectively extracts and merges contextual informationfrom the network. Extensive quantitative evaluations are conducted to assessthe performance of our method. Experimental results demonstrate the superiorperformance of the proposed method compared to state-of-the-art approaches onthe BNS, MoNuSeg, CoNSeg, and CPM-17 datasets.", "output": "Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, diffusion models have emerged as the most powerful approachin image synthesis. However, applying these models directly to video synthesispresents challenges, as it often leads to noticeable flickering contents.Although recently proposed zero-shot methods can alleviate flicker to someextent, we still struggle to generate coherent videos. In this paper, wepropose DiffSynth, a novel approach that aims to convert image synthesispipelines to video synthesis pipelines. DiffSynth consists of two keycomponents: a latent in-iteration deflickering framework and a videodeflickering algorithm. The latent in-iteration deflickering framework appliesvideo deflickering to the latent space of diffusion models, effectivelypreventing flicker accumulation in intermediate steps. Additionally, we proposea video deflickering algorithm, named patch blending algorithm, that remapsobjects in different frames and blends them together to enhance videoconsistency. One of the notable advantages of DiffSynth is its generalapplicability to various video synthesis tasks, including text-guided videostylization, fashion video synthesis, image-guided video stylization, videorestoring, and 3D rendering. In the task of text-guided video stylization, wemake it possible to synthesize high-quality videos without cherry-picking. Theexperimental results demonstrate the effectiveness of DiffSynth. All videos canbe viewed on our project page. Source codes will also be released.", "output": "DiffSynth: Latent In-Iteration Deflickering for Realistic Video Synthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper asks whether current self-supervised learning methods, ifsufficiently scaled up, would be able to reach human-level visual objectrecognition capabilities with the same type and amount of visual experiencehumans learn from. Previous work on this question only considered the scalingof data size. Here, we consider the simultaneous scaling of data size, modelsize, and image resolution. We perform a scaling experiment with visiontransformers up to 633M parameters in size (ViT-H/14) trained with up to 5Khours of human-like video data (long, continuous, mostly egocentric videos)with image resolutions of up to 476x476 pixels. The efficiency of maskedautoencoders (MAEs) as a self-supervised learning algorithm makes it possibleto run this scaling experiment on an unassuming academic budget. We find thatit is feasible to reach human-level object recognition capacity at sub-humanscales of model size, data size, and image size, if these factors are scaled upsimultaneously. To give a concrete example, we estimate that a 2.5B parameterViT model trained with 20K hours (2.3 years) of human-like video data with aspatial resolution of 952x952 pixels should be able to reach roughlyhuman-level accuracy on ImageNet. Human-level competence is thus achievable fora fundamental perceptual capability from human-like perceptual experience(human-like in both amount and type) with extremely generic learning algorithmsand architectures and without any substantive inductive biases.", "output": "Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multimodal Large Language Models (MLLMs) have recently sparked significantinterest, which demonstrates emergent capabilities to serve as ageneral-purpose model for various vision-language tasks. However, existingmethods mainly focus on limited types of instructions with a single image asvisual context, which hinders the widespread availability of MLLMs. In thispaper, we introduce the I4 benchmark to comprehensively evaluate theinstruction following ability on complicated interleaved vision-languageinstructions, which involve intricate image-text sequential context, covering adiverse range of scenarios (e.g., visually-rich webpages/textbooks, lectureslides, embodied dialogue). Systematic evaluation on our I4 benchmark reveals acommon defect of existing methods: the Visual Prompt Generator (VPG) trained onimage-captioning alignment objective tends to attend to common foregroundinformation for captioning but struggles to extract specific informationrequired by particular tasks. To address this issue, we propose a generic andlightweight controllable knowledge re-injection module, which utilizes thesophisticated reasoning ability of LLMs to control the VPG to conditionallyextract instruction-specific visual information and re-inject it into the LLM.Further, we introduce an annotation-free cross-attention guided counterfactualimage training strategy to methodically learn the proposed module bycollaborating a cascade of foundation models. Enhanced by the proposed moduleand training strategy, we present Cheetor, a Transformer-based MLLM that caneffectively handle a wide variety of interleaved vision-language instructionsand achieves state-of-the-art zero-shot performance across all tasks of I4,without high-quality multimodal instruction tuning data. Cheetor also exhibitscompetitive performance compared with state-of-the-art instruction tuned modelson MME benchmark.", "output": "Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Text design is one of the most critical procedures in poster design, as itrelies heavily on the creativity and expertise of humans to design text imagesconsidering the visual harmony and text-semantic. This study introducesTextPainter, a novel multimodal approach that leverages contextual visualinformation and corresponding text semantics to generate text images.Specifically, TextPainter takes the global-local background image as a hint ofstyle and guides the text image generation with visual harmony. Furthermore, weleverage the language model and introduce a text comprehension module toachieve both sentence-level and word-level style variations. Besides, weconstruct the PosterT80K dataset, consisting of about 80K posters annotatedwith sentence-level bounding boxes and text contents. We hope this dataset willpave the way for further research on multimodal text image generation.Extensive quantitative and qualitative experiments demonstrate that TextPaintercan generate visually-and-semantically-harmonious text images for posters.", "output": "TextPainter: Multimodal Text Image Generation withVisual-harmony and Text-comprehension for Poster Design."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent advances in full-head reconstruction have been obtained by optimizinga neural field through differentiable surface or volume rendering to representa single scene. While these techniques achieve an unprecedented accuracy, theytake several minutes, or even hours, due to the expensive optimization processrequired. In this work, we introduce InstantAvatar, a method that recoversfull-head avatars from few images (down to just one) in a few seconds oncommodity hardware. In order to speed up the reconstruction process, we proposea system that combines, for the first time, a voxel-grid neural fieldrepresentation with a surface renderer. Notably, a naive combination of thesetwo techniques leads to unstable optimizations that do not converge to validsolutions. In order to overcome this limitation, we present a novel statisticalmodel that learns a prior distribution over 3D head signed distance functionsusing a voxel-grid based architecture. The use of this prior model, incombination with other design choices, results into a system that achieves 3Dhead reconstructions with comparable accuracy as the state-of-the-art with a100x speed-up.", "output": "InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Video shakiness is an unpleasant distortion of User Generated Content (UGC)videos, which is usually caused by the unstable hold of cameras. In recentyears, many video stabilization algorithms have been proposed, yet no specificand accurate metric enables comprehensively evaluating the stability of videos.Indeed, most existing quality assessment models evaluate video quality as awhole without specifically taking the subjective experience of video stabilityinto consideration. Therefore, these models cannot measure the video stabilityexplicitly and precisely when severe shakes are present. In addition, there isno large-scale video database in public that includes various degrees of shakyvideos with the corresponding subjective scores available, which hinders thedevelopment of Video Quality Assessment for Stability (VQA-S). To this end, webuild a new database named StableDB that contains 1,952 diversely-shaky UGCvideos, where each video has a Mean Opinion Score (MOS) on the degree of videostability rated by 34 subjects. Moreover, we elaborately design a novel VQA-Smodel named StableVQA, which consists of three feature extractors to acquirethe optical flow, semantic, and blur features respectively, and a regressionlayer to predict the final stability score. Extensive experiments demonstratethat the StableVQA achieves a higher correlation with subjective opinions thanthe existing VQA-S models and generic VQA models. The database and codes areavailable at ", "output": "StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot SemanticSegmentation (FSS) to simultaneously segment unseen classes and seen classesduring evaluation. Previous works leverage additional branch or prototypicalaggregation to eliminate the constrained setting of FSS. However,representation division and embedding prejudice, which heavily results in poorperformance of GFSS, have not been synthetical considered. We address theaforementioned problems by jointing the prototypical kernel learning andopen-set foreground perception. Specifically, a group of learnable kernels isproposed to perform segmentation with each kernel in charge of a stuff class.Then, we explore to merge the prototypical learning to the update of base-classkernels, which is consistent with the prototype knowledge aggregation offew-shot novel classes. In addition, a foreground contextual perception modulecooperating with conditional bias based inference is adopted to performclass-agnostic as well as open-set foreground detection, thus to mitigate theembedding prejudice and prevent novel targets from being misclassified asbackground. Moreover, we also adjust our method to the Class IncrementalFew-shot Semantic Segmentation (CIFSS) which takes the knowledge of novelclasses in a incremental stream. Extensive experiments on PASCAL-5i andCOCO-20i datasets demonstrate that our method performs better than previousstate-of-the-art.", "output": "Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The availability of large-scale authentic face databases has been crucial tothe significant advances made in face recognition research over the pastdecade. However, legal and ethical concerns led to the recent retraction ofmany of these databases by their creators, raising questions about thecontinuity of future face recognition research without one of its keyresources. Synthetic datasets have emerged as a promising alternative toprivacy-sensitive authentic data for face recognition development. However,recent synthetic datasets that are used to train face recognition models suffereither from limitations in intra-class diversity or cross-class (identity)discrimination, leading to less optimal accuracies, far away from theaccuracies achieved by models trained on authentic data. This paper targetsthis issue by proposing IDiff-Face, a novel approach based on conditionallatent diffusion models for synthetic identity generation with realisticidentity variations for face recognition training. Through extensiveevaluations, our proposed synthetic-based face recognition approach pushed thelimits of state-of-the-art performances, achieving, for example, 98.00%accuracy on the Labeled Faces in the Wild (LFW) benchmark, far ahead from therecent synthetic-based face recognition solutions with 95.40% and bridging thegap to authentic-based face recognition with 99.82% accuracy.", "output": "IDiff-Face: Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Many segmentation networks have been proposed for 3D volumetric segmentationof tumors and organs at risk. Hospitals and clinical institutions seek toaccelerate and minimize the efforts of specialists in image segmentation.Still, in case of errors generated by these networks, clinicians would have tomanually edit the generated segmentation maps. Given a 3D volume and itsputative segmentation map, we propose an approach to identify and measureerroneous regions in the segmentation map. Our method can estimate error at anypoint or node in a 3D mesh generated from a possibly erroneous volumetricsegmentation map, serving as a Quality Assurance tool. We propose a graphneural network-based transformer based on the Nodeformer architecture tomeasure and classify the segmentation errors at any point. We have evaluatedour network on a high-resolution micro-CT dataset of the human inner-ear bonylabyrinth structure by simulating erroneous 3D segmentation maps. Our networkincorporates a convolutional encoder to compute node-centric features from theinput micro-CT data, the Nodeformer to learn the latent graph embeddings, and aMulti-Layer Perceptron (MLP) to compute and classify the node-wise errors. Ournetwork achieves a mean absolute error of ~0.042 over other Graph NeuralNetworks (GNN) and an accuracy of 79.53% over other GNNs in estimating andclassifying the node-wise errors, respectively. We also put forth vertex-normalprediction as a custom pretext task for pre-training the CNN encoder to improvethe network's overall performance. Qualitative analysis shows the efficiency ofour network in correctly classifying errors and reducing misclassifications.", "output": "Geometric Learning-Based Transformer Network for Estimation of Segmentation Errors."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Lesion segmentation of ultrasound medical images based on deep learningtechniques is a widely used method for diagnosing diseases. Although there is alarge amount of ultrasound image data in medical centers and other places,labeled ultrasound datasets are a scarce resource, and it is likely that nodatasets are available for new tissues/organs. Transfer learning provides thepossibility to solve this problem, but there are too many features in naturalimages that are not related to the target domain. As a source domain, redundantfeatures that are not conducive to the task will be extracted. Migrationbetween ultrasound images can avoid this problem, but there are few types ofpublic datasets, and it is difficult to find sufficiently similar sourcedomains. Compared with natural images, ultrasound images have less information,and there are fewer transferable features between different ultrasound images,which may cause negative transfer. To this end, a multi-source adversarialtransfer learning network for ultrasound image segmentation is proposed.Specifically, to address the lack of annotations, the idea of adversarialtransfer learning is used to adaptively extract common features between acertain pair of source and target domains, which provides the possibility toutilize unlabeled ultrasound data. To alleviate the lack of knowledge in asingle source domain, multi-source transfer learning is adopted to fuseknowledge from multiple source domains. In order to ensure the effectiveness ofthe fusion and maximize the use of precious data, a multi-source domainindependent strategy is also proposed to improve the estimation of the targetdomain data distribution, which further increases the learning ability of themulti-source adversarial migration learning network in multiple domains.", "output": "Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper presents an investigation into machine learning techniques forviolence detection in videos and their adaptation to a federated learningcontext. The study includes experiments with spatio-temporal features extractedfrom benchmark video datasets, comparison of different methods, and proposal ofa modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\"Additionally, various machine learning techniques, including super-convergenceand transfer learning, are explored, and a method for adapting centralizeddatasets to a federated learning context is developed. The research achievesbetter accuracy results compared to state-of-the-art models by training thebest violence detection model in a federated learning context.", "output": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Stroke is a significant cause of mortality and morbidity, necessitating earlypredictive strategies to minimize risks. Traditional methods for evaluatingpatients, such as Acute Physiology and Chronic Health Evaluation (APACHE II,IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracyand interpretability. This paper proposes a novel approach: an interpretable,attention-based transformer model for early stroke mortality prediction. Thismodel seeks to address the limitations of previous predictive models, providingboth interpretability (providing clear, understandable explanations of themodel) and fidelity (giving a truthful explanation of the model's dynamics frominput to output). Furthermore, the study explores and compares fidelity andinterpretability scores using Shapley values and attention-based scores toimprove model explainability. The research objectives include designing aninterpretable attention-based transformer model, evaluating its performancecompared to existing models, and providing feature importance derived from themodel.", "output": "Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Phosphorylation is central to numerous fundamental cellular processes,influencing the onset and progression of a variety of diseases. Identificationof phosphorylation sites is thus an important step for understanding themolecular mechanisms of cells and virus infection, which potentially leads tonew therapeutic targets. In this study, we present PTransIPs, a novel deeplearning model for the identification of phosphorylation sites. PTransIPstreats amino acids in protein sequences as words in natural language,extracting unique encodings based on the types along with position of aminoacids in the sequence. It also incorporates embeddings from large pre-trainedprotein models as additional data inputs. PTransIPS is further trained on acombination model of convolutional neural network with residual connections andTransformer model equipped with multi-head attention mechanisms. At last, themodel outputs classification results through a fully connected layer. Theresults of independent testing reveal that PTransIPs outperforms existingstate-of-the-art methodologies, achieving AUROCs of 0.9232 and 0.9660 foridentifying phosphorylated S/T and Y sites respectively. In addition, ablationstudies prove that pretrained model embeddings contribute to the performance ofPTransIPs. Furthermore, PTransIPs has interpretable amino acid preference,visible training process and shows generalizability on other bioactivityclassification tasks. To facilitate usage, our code and data are publiclyaccessible at url{", "output": "PTransIPs: Identification of phosphorylation sites based on protein pretrained language model and Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper demonstrates the utility of organized numerical representations ofgenes in research involving flat string gene formats (i.e., FASTA/FASTQ5).FASTA/FASTQ files have several current limitations, such as their large filesizes, slow processing speeds for mapping and alignment, and contextualdependencies. These challenges significantly hinder investigations and tasksthat involve finding similar sequences. The solution lies in transformingsequences into an alternative representation that facilitates easier clusteringinto similar groups compared to the raw sequences themselves. By assigning aunique vector embedding to each short sequence, it is possible to moreefficiently cluster and improve upon compression performance for the stringrepresentations of cDNA libraries. Furthermore, through learning alternativecoordinate vector embeddings based on the contexts of codon triplets, we candemonstrate clustering based on amino acid properties. Finally, using thissequence embedding method to encode barcodes and cDNA sequences, we can improvethe time complexity of the similarity search by coupling vector embeddings withan algorithm that determines the proximity of vectors in Euclidean space; thisallows us to perform sequence similarity searches in a quicker and more modularfashion.", "output": "Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, the field of data-driven neural network-based machinelearning (ML) algorithms has grown significantly and spurred research in itsapplicability to instrumentation and control systems. While they are promisingin operational contexts, the trustworthiness of such algorithms is notadequately assessed. Failures of ML-integrated systems are poorly understood;the lack of comprehensive risk modeling can degrade the trustworthiness ofthese systems. In recent reports by the National Institute for Standards andTechnology, trustworthiness in ML is a critical barrier to adoption and willplay a vital role in intelligent systems' safe and accountable operation. Thus,in this work, we demonstrate a real-time model-agnostic method to evaluate therelative reliability of ML predictions by incorporating out-of-distributiondetection on the training dataset. It is well documented that ML algorithmsexcel at interpolation (or near-interpolation) tasks but significantly degradeat extrapolation. This occurs when new samples are \"far\" from training samples.The method, referred to as the Laplacian distributed decay for reliability(LADDR), determines the difference between the operational and trainingdatasets, which is used to calculate a prediction's relative reliability. LADDRis demonstrated on a feedforward neural network-based model used to predictsafety significant factors during different loss-of-flow transients. LADDR isintended as a \"data supervisor\" and determines the appropriateness ofwell-trained ML models in the context of operational conditions. Ultimately,LADDR illustrates how training data can be used as evidence to support thetrustworthiness of ML predictions when utilized for conventional interpolationtasks.", "output": "Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation & Control Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The multifactorial etiology of autism spectrum disorder (ASD) suggests thatits study would benefit greatly from multimodal approaches that combine datafrom widely varying platforms, e.g., neuroimaging, genetics, and clinicalcharacterization. Prior neuroimaging-genetic analyses often apply naive featureconcatenation approaches in data-driven work or use the findings from onemodality to guide posthoc analysis of another, missing the opportunity toanalyze the paired multimodal data in a truly unified approach. In this paper,we develop a more integrative model for combining genetic, demographic, andneuroimaging data. Inspired by the influence of genotype on phenotype, wepropose using an attention-based approach where the genetic data guidesattention to neuroimaging features of importance for model prediction. Thegenetic data is derived from copy number variation parameters, while theneuroimaging data is from functional magnetic resonance imaging. We evaluatethe proposed approach on ASD classification and severity prediction tasks,using a sex-balanced dataset of 228 ASD and typically developing subjects in a10-fold cross-validation framework. We demonstrate that our attention-basedmodel combining genetic information, demographic data, and functional magneticresonance imaging results in superior prediction performance compared to othermultimodal approaches.", "output": "Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The capacity to identify and analyze protein-protein interactions, along withtheir internal modular organization, plays a crucial role in comprehending theintricate mechanisms underlying biological processes at the molecular level. Wecan learn a lot about the structure and dynamics of these interactions by usingnetwork analysis. We can improve our understanding of the biological roots ofdisease pathogenesis by recognizing network communities. This knowledge, inturn, holds significant potential for driving advancements in drug discoveryand facilitating personalized medicine approaches for disease treatment. Inthis study, we aimed to uncover the communities within the variant B.1.1.529(Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and fourwidely recognized algorithms: Girvan-Newman, Louvain, Leiden, and LabelPropagation algorithm. Each of these algorithms has established prominence inthe field and offers unique perspectives on identifying communities withincomplex networks. We also compare the networks by the global properties,statistic summary, subgraph count, graphlet and validate by the modulaity. Byemploying these approaches, we sought to gain deeper insights into thestructural organization and interconnections present within the Omicron virusnetwork.", "output": "Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A significant number of machine learning models are vulnerable to modelextraction attacks, which focus on stealing the models by using speciallycurated queries against the target model. This task is well accomplished byusing part of the training data or a surrogate dataset to train a new modelthat mimics a target model in a white-box environment. In pragmatic situations,however, the target models are trained on private datasets that areinaccessible to the adversary. The data-free model extraction techniquereplaces this problem when it comes to using queries artificially curated by agenerator similar to that used in Generative Adversarial Nets. We propose forthe first time, to the best of our knowledge, an adversary black box attackextending to a regression problem for predicting bounding box coordinates inobject detection. As part of our study, we found that defining a loss functionand using a novel generator setup is one of the key aspects in extracting thetarget model. We find that the proposed model extraction method achievessignificant results by using reasonable queries. The discovery of this objectdetection vulnerability will support future prospects for securing such models.", "output": "Data-Free Model Extraction Attacks in the Context of Object Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "While many studies have assessed the fairness of AI algorithms in the medicalfield, the causes of differences in prediction performance are often unknown.This lack of knowledge about the causes of bias hampers the efficacy of biasmitigation, as evidenced by the fact that simple dataset balancing still oftenperforms best in reducing performance gaps but is unable to resolve allperformance differences. In this work, we investigate the causes of gender biasin machine learning-based chest X-ray diagnosis. In particular, we explore thehypothesis that breast tissue leads to underexposure of the lungs and causeslower model performance. Methodologically, we propose a new sampling methodwhich addresses the highly skewed distribution of recordings per patient in twowidely used public datasets, while at the same time reducing the impact oflabel errors. Our comprehensive analysis of gender differences across diseases,datasets, and gender representations in the training set shows that datasetimbalance is not the sole cause of performance differences. Moreover, relativegroup performance differs strongly between datasets, indicating importantdataset-specific factors influencing male/female group performance. Finally, weinvestigate the effect of breast tissue more specifically, by cropping out thebreasts from recordings, finding that this does not resolve the observedperformance gaps. In conclusion, our results indicate that dataset-specificfactors, not fundamental physiological differences, are the main drivers ofmale--female performance gaps in chest X-ray analyses on widely used NIH andCheXpert Dataset.", "output": "Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The primary method for identifying mental disorders automatically hastraditionally involved using binary classifiers. These classifiers are trainedusing behavioral data obtained from an interview setup. In this trainingprocess, data from individuals with the specific disorder under considerationare categorized as the positive class, while data from all other participantsconstitute the negative class. In practice, it is widely recognized thatcertain mental disorders share similar symptoms, causing the collectedbehavioral data to encompass a variety of attributes associated with multipledisorders. Consequently, attributes linked to the targeted mental disordermight also be present within the negative class. This data impurity may lead tosub-optimal training of the classifier for a mental disorder of interest. Inthis study, we investigate this hypothesis in the context of major depressivedisorder (MDD) and post-traumatic stress disorder detection (PTSD). The resultsshow that upon removal of such data impurity, MDD and PTSD detectionperformances are significantly improved.", "output": "Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We address the challenge of sound propagation simulations in $3$D virtualrooms with moving sources, which have applications in virtual/augmentedreality, game audio, and spatial computing. Solutions to the wave equation candescribe wave phenomena such as diffraction and interference. However,simulating them using conventional numerical discretization methods withhundreds of source and receiver positions is intractable, making stimulating asound field with moving sources impractical. To overcome this limitation, wepropose using deep operator networks to approximate linear wave-equationoperators. This enables the rapid prediction of sound propagation in realistic3D acoustic scenes with moving sources, achieving millisecond-scalecomputations. By learning a compact surrogate model, we avoid the offlinecalculation and storage of impulse responses for all relevant source/listenerpairs. Our experiments, including various complex scene geometries, show goodagreement with reference solutions, with root mean squared errors ranging from0.02 Pa to 0.10 Pa. Notably, our method signifies a paradigm shift as no priormachine learning approach has achieved precise predictions of complete wavefields within realistic domains. We anticipate that our findings will drivefurther exploration of deep neural operator methods, advancing research inimmersive user experiences within virtual environments.", "output": "Sound propagation in realistic interactive 3D scenes with parameterized sources using deep neural operators."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The present work discusses the use of a weakly-supervised deep learningalgorithm that reduces the cost of labelling pixel-level masks for complexradio galaxies with multiple components. The algorithm is trained on weakclass-level labels of radio galaxies to get class activation maps (CAMs). TheCAMs are further refined using an inter-pixel relations network (IRNet) to getinstance segmentation masks over radio galaxies and the positions of theirinfrared hosts. We use data from the Australian Square Kilometre ArrayPathfinder (ASKAP) telescope, specifically the Evolutionary Map of the Universe(EMU) Pilot Survey, which covered a sky area of 270 square degrees with an RMSsensitivity of 25-35 $mu$Jy/beam. We demonstrate that weakly-supervised deeplearning algorithms can achieve high accuracy in predicting pixel-levelinformation, including masks for the extended radio emission encapsulating allgalaxy components and the positions of the infrared host galaxies. We evaluatethe performance of our method using mean Average Precision (mAP) acrossmultiple classes at a standard intersection over union (IoU) threshold of 0.5.We show that the model achieves a mAP$_{50}$ of 67.5% and 76.8% for radiomasks and infrared host positions, respectively. The network architecture canbe found at the following link: ", "output": "Deep Learning for Morphological Identification of Extended Radio Galaxies using Weak Labels."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Epilepsy is a prevalent neurological disorder characterized by recurrent andunpredictable seizures, necessitating accurate prediction for effectivemanagement and patient care. Application of machine learning (ML) onelectroencephalogram (EEG) recordings, along with its ability to providevaluable insights into brain activity during seizures, is able to make accurateand robust seizure prediction an indispensable component in relevant studies.In this research, we present a comprehensive comparative analysis of fivemachine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees(ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the predictionof epileptic seizures using EEG data. The dataset underwent meticulouspreprocessing, including cleaning, normalization, outlier handling, andoversampling, ensuring data quality and facilitating accurate model training.These preprocessing techniques played a crucial role in enhancing the models'performance. The results of our analysis demonstrate the performance of eachmodel in terms of accuracy. The LR classifier achieved an accuracy of 56.95%,while GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of98.99%, while the ET model exhibited the best performance with an accuracy of99.29%. Our findings reveal that the ET model outperformed not only the othermodels in the comparative analysis but also surpassed the state-of-the-artresults from previous research. The superior performance of the ET model makesit a compelling choice for accurate and robust epileptic seizure predictionusing EEG data.", "output": "Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This PhD. Thesis concerns the study and development of hierarchicalrepresentations for spatio-temporal visual attention modeling and understandingin video sequences. More specifically, we propose two computational models forvisual attention. First, we present a generative probabilistic model forcontext-aware visual attention modeling and understanding. Secondly, we developa deep network architecture for visual attention modeling, which firstestimates top-down spatio-temporal visual attention, and ultimately serves formodeling attention in the temporal domain.", "output": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, the state of the art in the field of pedestrian trajectoryprediction is evaluated alongside the constant velocity model (CVM) withrespect to its applicability in autonomous vehicles. The evaluation isconducted on the widely-used ETH/UCY dataset where the Average DisplacementError (ADE) and the Final Displacement Error (FDE) are reported. To align withrequirements in real-world applications, modifications are made to the inputfeatures of the initially proposed models. An ablation study is conducted toexamine the influence of the observed motion history on the predictionperformance, thereby establishing a better understanding of its impact.Additionally, the inference time of each model is measured to evaluate thescalability of each model when confronted with varying amounts of agents. Theresults demonstrate that simple models remain competitive when generatingsingle trajectories, and certain features commonly thought of as useful havelittle impact on the overall performance across different architectures. Basedon these findings, recommendations are proposed to guide the future developmentof trajectory prediction algorithms.", "output": "Evaluating Pedestrian Trajectory Prediction Methods for the Application in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose CONF-TSASR, a non-autoregressive end-to-end time-frequency domainarchitecture for single-channel target-speaker automatic speech recognition(TS-ASR). The model consists of a TitaNet based speaker embedding module, aConformer based masking as well as ASR modules. These modules are jointlyoptimized to transcribe a target-speaker, while ignoring speech from otherspeakers. For training we use Connectionist Temporal Classification (CTC) lossand introduce a scale-invariant spectrogram reconstruction loss to encouragethe model better separate the target-speaker's spectrogram from mixture. Weobtain state-of-the-art target-speaker word error rate (TS-WER) onWSJ0-2mix-extr (4.2%). Further, we report for the first time TS-WER onWSJ0-3mix-extr (12.4%), LibriSpeech2Mix (4.2%) and LibriSpeech3Mix (7.6%)datasets, establishing new benchmarks for TS-ASR. The proposed model will beopen-sourced through NVIDIA NeMo toolkit.", "output": "Conformer-based Target-Speaker Automatic Speech Recognition for Single-Channel Audio."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we introduce a strategy for identifying textual saliency inlarge-scale language models applied to classification tasks. In visual networkswhere saliency is more well-studied, saliency is naturally localized throughthe convolutional layers of the network; however, the same is not true inmodern transformer-stack networks used to process natural language. We adaptgradient-based saliency methods for these networks, propose a method forevaluating the degree of semantic coherence of each layer, and demonstrateconsistent improvement over numerous other methods for textual saliency onmultiple benchmark classification datasets. Our approach requires no additionaltraining or access to labelled data, and is comparatively very computationallyefficient.", "output": "Decoding Layer Saliency in Language Transformers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Optics is an exciting route for the next generation of computing hardware formachine learning, promising several orders of magnitude enhancement in bothcomputational speed and energy efficiency. However, to reach the full capacityof an optical neural network it is necessary that the computing not only forthe inference, but also for the training be implemented optically. The primaryalgorithm for training a neural network is backpropagation, in which thecalculation is performed in the order opposite to the information flow forinference. While straightforward in a digital computer, optical implementationof backpropagation has so far remained elusive, particularly because of theconflicting requirements for the optical element that implements the nonlinearactivation function. In this work, we address this challenge for the first timewith a surprisingly simple and generic scheme. Saturable absorbers are employedfor the role of the activation units, and the required properties are achievedthrough a pump-probe process, in which the forward propagating signal acts asthe pump and backward as the probe. Our approach is adaptable to various analogplatforms, materials, and network structures, and it demonstrates thepossibility of constructing neural networks entirely reliant on analog opticalprocesses for both training and inference tasks.", "output": "Training neural networks with end-to-end optical backpropagation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Surgical instrument segmentation is recognised as a key enabler to provideadvanced surgical assistance and improve computer assisted interventions. Inthis work, we propose SegMatch, a semi supervised learning method to reduce theneed for expensive annotation for laparoscopic and robotic surgical images.SegMatch builds on FixMatch, a widespread semi supervised classificationpipeline combining consistency regularization and pseudo labelling, and adaptsit for the purpose of segmentation. In our proposed SegMatch, the unlabelledimages are weakly augmented and fed into the segmentation model to generate apseudo-label to enforce the unsupervised loss against the output of the modelfor the adversarial augmented image on the pixels with a high confidence score.Our adaptation for segmentation tasks includes carefully considering theequivariance and invariance properties of the augmentation functions we relyon. To increase the relevance of our augmentations, we depart from using onlyhandcrafted augmentations and introduce a trainable adversarial augmentationstrategy. Our algorithm was evaluated on the MICCAI Instrument SegmentationChallenge datasets Robust-MIS 2019 and EndoVis 2017. Our results demonstratethat adding unlabelled data for training purposes allows us to surpass theperformance of fully supervised approaches which are limited by theavailability of training data in these challenges. SegMatch also outperforms arange of state-of-the-art semi-supervised learning semantic segmentation modelsin different labelled to unlabelled data ratios.", "output": "SegMatch: A semi-supervised learning method for surgical instrument segmentation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Environmental perception is a key element of autonomous driving because theinformation received from the perception module influences core drivingdecisions. An outstanding challenge in real-time perception for autonomousdriving lies in finding the best trade-off between detection quality andlatency. Major constraints on both computation and power have to be taken intoaccount for real-time perception in autonomous vehicles. Larger objectdetection models tend to produce the best results, but are also slower atruntime. Since the most accurate detectors cannot run in real-time locally, weinvestigate the possibility of offloading computation to edge and cloudplatforms, which are less resource-constrained. We create a synthetic datasetto train object detection models and evaluate different offloading strategies.Using real hardware and network simulations, we compare different trade-offsbetween prediction quality and end-to-end delay. Since sending raw frames overthe network implies additional transmission delays, we also explore the use ofJPEG and H.265 compression at varying qualities and measure their impact onprediction metrics. We show that models with adequate compression can be run inreal-time on the cloud while outperforming local detection performance.", "output": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Convolutional Neural Networks (CNNs) are models that are utilized extensivelyfor the hierarchical extraction of features. Vision transformers (ViTs),through the use of a self-attention mechanism, have recently achieved superiormodeling of global contextual information compared to CNNs. However, to realizetheir image classification strength, ViTs require substantial trainingdatasets. Where the available training data are limited, current advancedmulti-layer perceptrons (MLPs) can provide viable alternatives to both deepCNNs and ViTs. In this paper, we developed the SGU-MLP, a learning algorithmthat effectively uses both MLPs and spatial gating units (SGUs) for preciseland use land cover (LULC) mapping. Results illustrated the superiority of thedeveloped SGU-MLP classification algorithm over several CNN and CNN-ViT-basedmodels, including HybridSN, ResNet, iFormer, EfficientFormer and CoAtNet. Theproposed SGU-MLP algorithm was tested through three experiments in Houston,USA, Berlin, Germany and Augsburg, Germany. The SGU-MLP classification modelwas found to consistently outperform the benchmark CNN and CNN-ViT-basedalgorithms. For example, for the Houston experiment, SGU-MLP significantlyoutperformed HybridSN, CoAtNet, Efficientformer, iFormer and ResNet byapproximately 15%, 19%, 20%, 21%, and 25%, respectively, in terms of averageaccuracy. The code will be made publicly available at", "output": "Spatial Gated Multi-Layer Perceptron for Land Use and Land Cover Mapping."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this research, a comparative study of four Quantum Machine Learning (QML)models was conducted for fraud detection in finance. We proved that the QuantumSupport Vector Classifier model achieved the highest performance, with F1scores of 0.98 for fraud and non-fraud classes. Other models like theVariational Quantum Classifier, Estimator Quantum Neural Network (QNN), andSampler QNN demonstrate promising results, propelling the potential of QMLclassification for financial applications. While they exhibit certainlimitations, the insights attained pave the way for future enhancements andoptimisation strategies. However, challenges exist, including the need for moreefficient Quantum algorithms and larger and more complex datasets. The articleprovides solutions to overcome current limitations and contributes new insightsto the field of Quantum Machine Learning in fraud detection, with importantimplications for its future development.", "output": "Financial Fraud Detection: A Comparative Study of Quantum Machine Learning Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Several architecture frameworks for software, systems, and enterprises havebeen proposed in the literature. They identified various stakeholders anddefined architecture viewpoints and views to frame and address stakeholderconcerns. However, the stakeholders with data science and Machine Learning (ML)related concerns, such as data scientists and data engineers, are yet to beincluded in existing architecture frameworks. Therefore, they failed to addressthe architecture viewpoints and views responsive to the concerns of the datascience community. In this paper, we address this gap by establishing thearchitecture frameworks adapted to meet the requirements of modern applicationsand organizations where ML artifacts are both prevalent and crucial. Inparticular, we focus on ML-enabled Cyber-Physical Systems (CPSs) and proposetwo sets of merit criteria for their efficient development and performanceassessment, namely the criteria for evaluating and benchmarking ML-enabledCPSs, and the criteria for evaluation and benchmarking of the tools intended tosupport users through the modeling and development pipeline. In this study, wedeploy multiple empirical and qualitative research methods based on literaturereview and survey instruments including expert interviews and an onlinequestionnaire. We collect, analyze, and integrate the opinions of 77 expertsfrom more than 25 organizations in over 10 countries to devise and validate theproposed framework.", "output": "AI-Enabled Software and System Architecture Frameworks: Focusing on smart Cyber-Physical Systems (CPS)."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces a novel deep-learning based generator of syntheticgraphs that represent intra-Autonomous System (AS) in the Internet, namedDeep-generative graphs for the Internet (DGGI). It also presents a novelmassive dataset of real intra-AS graphs extracted from the project InternetTopology Data Kit (ITDK), called Internet Graphs (IGraphs). To create IGraphs,the Filtered Recurrent Multi-level (FRM) algorithm for community extraction wasdeveloped. It is shown that DGGI creates synthetic graphs which accuratelyreproduce the properties of centrality, clustering, assortativity, and nodedegree. The DGGI generator overperforms existing Internet topology generators.On average, DGGI improves the Maximum Mean Discrepancy (MMD) metric 84.4%,95.1%, 97.9%, and 94.7% for assortativity, betweenness, clustering, and nodedegree, respectively.", "output": "Data-driven Intra-Autonomous Systems Graph Generator."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In recent years, heterogeneous graph few-shot learning has been proposed toaddress the label sparsity issue in heterogeneous graphs (HGs), which containvarious types of nodes and edges. The existing methods have achieved goodperformance by transferring generalized knowledge extracted from rich-labeledclasses in source HG(s) to few-labeled classes in a target HG. However, thesemethods only consider the single-heterogeneity scenario where the source andtarget HGs share a fixed set of node/edge types, ignoring the more generalscenario of cross-heterogeneity, where each HG can have a different andnon-fixed set of node/edge types. To this end, we focus on the unexploredcross-heterogeneity scenario and propose a novel model for Cross-heterogeneityGraph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patternsto capture heterogeneous information and propose a multi-view heterogeneousgraph neural network (MHGN) to learn meta-patterns across HGs. Then, we proposea score module to measure the informativeness of labeled samples and determinethe transferability of each source HG. Finally, by integrating MHGN and thescore module into a meta-learning mechanism, CGFL can effectively transfergeneralized knowledge to predict new classes with few-labeled data. Extensiveexperiments on four real-world datasets have demonstrated the superiorperformance of CGFL over the state-of-the-art methods.", "output": "Cross-heterogeneity Graph Few-shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Effective disaster response is critical for affected communities. Respondersand decision-makers would benefit from reliable, timely measures of the issuesimpacting their communities during a disaster, and social media offers apotentially rich data source. Social media can reflect public concerns anddemands during a disaster, offering valuable insights for decision-makers tounderstand evolving situations and optimize resource allocation. We usedBidirectional Encoder Representations from Transformers (BERT) topic modelingto cluster topics from Twitter data. Then, we conducted a temporal-spatialanalysis to examine the distribution of these topics across different regionsduring the 2020 western U.S. wildfire season. Our results show that Twitterusers mainly focused on three topics:\"health impact,\" \"damage,\" and\"evacuation.\" We used the Susceptible-Infected-Recovered (SIR) theory toexplore the magnitude and velocity of topic diffusion on Twitter. The resultsdisplayed a clear relationship between topic trends and wildfire propagationpatterns. The estimated parameters obtained from the SIR model in selectedcities revealed that residents exhibited a high level of several concernsduring the wildfire. Our study details how the SIR model and topic modelingusing social media data can provide decision-makers with a quantitativeapproach to measure disaster response and support their decision-makingprocesses.", "output": "Investigating disaster response through social media data and the Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S. wildfire season."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper studies Byzantine-robust stochastic optimization over adecentralized network, where every agent periodically communicates with itsneighbors to exchange local models, and then updates its own local model bystochastic gradient descent (SGD). The performance of such a method is affectedby an unknown number of Byzantine agents, which conduct adversarially duringthe optimization process. To the best of our knowledge, there is no existingwork that simultaneously achieves a linear convergence speed and a smalllearning error. We observe that the learning error is largely dependent on theintrinsic stochastic gradient noise. Motivated by this observation, weintroduce two variance reduction methods, stochastic average gradient algorithm(SAGA) and loopless stochastic variance-reduced gradient (LSVRG), toByzantine-robust decentralized stochastic optimization for eliminating thenegative effect of the stochastic gradient noise. The two resulting methods,BRAVO-SAGA and BRAVO-LSVRG, enjoy both linear convergence speeds and stochasticgradient noise-independent learning errors. Such learning errors are optimalfor a class of methods based on total variation (TV)-norm regularization andstochastic subgradient update. We conduct extensive numerical experiments todemonstrate their effectiveness under various Byzantine attacks.", "output": "Byzantine-Robust Decentralized Stochastic Optimization with Stochastic Gradient Noise-Independent Learning Error."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Medical image segmentation is an important step in medical image analysis,especially as a crucial prerequisite for efficient disease diagnosis andtreatment. The use of deep learning for image segmentation has become aprevalent trend. The widely adopted approach currently is U-Net and itsvariants. Additionally, with the remarkable success of pre-trained models innatural language processing tasks, transformer-based models like TransUNet haveachieved desirable performance on multiple medical image segmentation datasets.In this paper, we conduct a survey of the most representative four medicalimage segmentation models in recent years. We theoretically analyze thecharacteristics of these models and quantitatively evaluate their performanceon two benchmark datasets (i.e., Tuberculosis Chest X-rays and ovarian tumors).Finally, we discuss the main challenges and future trends in medical imagesegmentation. Our work can assist researchers in the related field to quicklyestablish medical segmentation models tailored to specific regions.", "output": "From CNN to Transformer: A Review of Medical Image Segmentation Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph clustering is a fundamental task in graph analysis, and recent advancesin utilizing graph neural networks (GNNs) have shown impressive results.Despite the success of existing GNN-based graph clustering methods, they oftenoverlook the quality of graph structure, which is inherent in real-world graphsdue to their sparse and multifarious nature, leading to subpar performance.Graph structure learning allows refining the input graph by adding missinglinks and removing spurious connections. However, previous endeavors in graphstructure learning have predominantly centered around supervised settings, andcannot be directly applied to our specific clustering tasks due to the absenceof ground-truth labels. To bridge the gap, we propose a novel method calledtextbf{ho}mophily-enhanced structure textbf{le}arning for graph clustering(HoLe). Our motivation stems from the observation that subtly enhancing thedegree of homophily within the graph structure can significantly improve GNNsand clustering outcomes. To realize this objective, we develop twoclustering-oriented structure learning modules, i.e., hierarchical correlationestimation and cluster-aware sparsification. The former module enables a moreaccurate estimation of pairwise node relationships by leveraging guidance fromlatent and clustering spaces, while the latter one generates a sparsifiedstructure based on the similarity matrix and clustering assignments.Additionally, we devise a joint optimization approach alternating betweentraining the homophily-enhanced structure learning and GNN-based clustering,thereby enforcing their reciprocal effects. Extensive experiments on sevenbenchmark datasets of various types and scales, across a range of clusteringmetrics, demonstrate the superiority of HoLe against state-of-the-artbaselines.", "output": "Homophily-enhanced Structure Learning for Graph Clustering."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Multiple sequence alignments (MSAs) of proteins encode rich biologicalinformation and have been workhorses in bioinformatic methods for tasks likeprotein design and protein structure prediction for decades. Recentbreakthroughs like AlphaFold2 that use transformers to attend directly overlarge quantities of raw MSAs have reaffirmed their importance. Generation ofMSAs is highly computationally intensive, however, and no datasets comparableto those used to train AlphaFold2 have been made available to the researchcommunity, hindering progress in machine learning for proteins. To remedy thisproblem, we introduce OpenProteinSet, an open-source corpus of more than 16million MSAs, associated structural homologs from the Protein Data Bank, andAlphaFold2 protein structure predictions. We have previously demonstrated theutility of OpenProteinSet by successfully retraining AlphaFold2 on it. Weexpect OpenProteinSet to be broadly useful as training and validation data for1) diverse tasks focused on protein structure, function, and design and 2)large-scale multimodal machine learning research.", "output": "OpenProteinSet: Training data for structural biology at scale."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Inspired by the recent success of large language models (LLMs) like ChatGPT,researchers start to explore the adoption of LLMs for agile hardware design,such as generating design RTL based on natural-language instructions. However,in existing works, their target designs are all relatively simple and in asmall scale, and proposed by the authors themselves, making a fair comparisonamong different LLM solutions challenging. In addition, many prior works onlyfocus on the design correctness, without evaluating the design qualities ofgenerated design RTL. In this work, we propose an open-source benchmark namedRTLLM, for generating design RTL with natural language instructions. Tosystematically evaluate the auto-generated design RTL, we summarized threeprogressive goals, named syntax goal, functionality goal, and design qualitygoal. This benchmark can automatically provide a quantitative evaluation of anygiven LLM-based solution. Furthermore, we propose an easy-to-use yetsurprisingly effective prompt engineering technique named self-planning, whichproves to significantly boost the performance of GPT-3.5 in our proposedbenchmark.", "output": "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this paper, we describe a new algorithm called Preferential Attachmentk-class Classifier (PreAttacK) for detecting fake accounts in a social network.Recently, several algorithms have obtained high accuracy on this problem.However, they have done so by relying on information about fake accounts'friendships or the content they share with others--the very things we seek toprevent. PreAttacK represents a significant departure from these approaches. Weprovide some of the first detailed distributional analyses of how new fake (andreal) accounts first attempt to request friends after joining a major network(Facebook). We show that even before a new account has made friends or sharedcontent, these initial friend request behaviors evoke a natural multi-classextension of the canonical Preferential Attachment model of social networkgrowth. We use this model to derive a new algorithm, PreAttacK. We prove thatin relevant problem instances, PreAttacK near-optimally approximates theposterior probability that a new account is fake under this multi-classPreferential Attachment model of new accounts' (not-yet-answered) friendrequests. These are the first provable guarantees for fake account detectionthat apply to new users, and that do not require strong homophily assumptions.This principled approach also makes PreAttacK the only algorithm with provableguarantees that obtains state-of-the-art performance on new users on the globalFacebook network, where it converges to AUC=0.9 after new users send + receivea total of just 20 not-yet-answered friend requests. For comparison,state-of-the-art benchmarks do not obtain this AUC even after observingadditional data on new users' first 100 friend requests. Thus, unlikemainstream algorithms, PreAttacK converges before the median new fake accounthas made a single friendship (accepted friend request) with a human.", "output": "Preemptive Detection of Fake Accounts on Social Networks via Multi-Class Preferential Attachment Classifiers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning classifiers achieve state-of-the-art performance in variousrisk detection applications. They explore rich semantic representations and aresupposed to automatically discover risk behaviors. However, due to the lack oftransparency, the behavioral semantics cannot be conveyed to downstreamsecurity experts to reduce their heavy workload in security analysis. Althoughfeature attribution (FA) methods can be used to explain deep learning, theunderlying classifier is still blind to what behavior is suspicious, and thegenerated explanation cannot adapt to downstream tasks, incurring poorexplanation fidelity and intelligibility. In this paper, we propose FINER, thefirst framework for risk detection classifiers to generate high-fidelity andhigh-intelligibility explanations. The high-level idea is to gather explanationefforts from model developer, FA designer, and security experts. To improvefidelity, we fine-tune the classifier with an explanation-guided multi-tasklearning strategy. To improve intelligibility, we engage task knowledge toadjust and ensemble FA methods. Extensive evaluations show that FINER improvesexplanation quality for risk detection. Moreover, we demonstrate that FINERoutperforms a state-of-the-art tool in facilitating malware analysis.", "output": "FINER: Enhancing State-of-the-art Classifiers with Feature Attribution to Facilitate Security Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Efficient and timely calculations of Machine Learning (ML) algorithms areessential for emerging technologies like autonomous driving, the Internet ofThings (IoT), and edge computing. One of the primary ML algorithms used in suchsystems is Convolutional Neural Networks (CNNs), which demand highcomputational resources. This requirement has led to the use of ML acceleratorslike GPGPUs to meet design constraints. However, selecting the most suitableaccelerator involves Design Space Exploration (DSE), a process that is usuallytime-consuming and requires significant manual effort. Our work presentsapproaches to expedite the DSE process by identifying the most appropriateGPGPU for CNN inferencing systems. We have developed a quick and precisetechnique for forecasting the power and performance of CNNs during inference,with a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computerarchitects to estimate power and performance in the early stages ofdevelopment, reducing the necessity for numerous prototypes. This saves timeand money while also improving the time-to-market period.", "output": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This work considers gradient-based mesh optimization, where we iterativelyoptimize for a 3D surface mesh by representing it as the isosurface of a scalarfield, an increasingly common paradigm in applications includingphotogrammetry, generative modeling, and inverse physics. Existingimplementations adapt classic isosurface extraction algorithms like MarchingCubes or Dual Contouring; these techniques were designed to extract meshes fromfixed, known fields, and in the optimization setting they lack the degrees offreedom to represent high-quality feature-preserving meshes, or suffer fromnumerical instabilities. We introduce FlexiCubes, an isosurface representationspecifically designed for optimizing an unknown mesh with respect to geometric,visual, or even physical objectives. Our main insight is to introduceadditional carefully-chosen parameters into the representation, which allowlocal flexible adjustments to the extracted mesh geometry and connectivity.These parameters are updated along with the underlying scalar field viaautomatic differentiation when optimizing for a downstream task. We base ourextraction scheme on Dual Marching Cubes for improved topological properties,and present extensions to optionally generate tetrahedral andhierarchically-adaptive meshes. Extensive experiments validate FlexiCubes onboth synthetic benchmarks and real-world applications, showing that it offerssignificant improvements in mesh quality and geometric fidelity.", "output": "Flexible Isosurface Extraction for Gradient-Based Mesh Optimization."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ensuring alignment, which refers to making models behave in accordance withhuman intentions [1,2], has become a critical task before deploying largelanguage models (LLMs) in real-world applications. For instance, OpenAI devotedsix months to iteratively aligning GPT-4 before its release [3]. However, amajor challenge faced by practitioners is the lack of clear guidance onevaluating whether LLM outputs align with social norms, values, andregulations. This obstacle hinders systematic iteration and deployment of LLMs.To address this issue, this paper presents a comprehensive survey of keydimensions that are crucial to consider when assessing LLM trustworthiness. Thesurvey covers seven major categories of LLM trustworthiness: reliability,safety, fairness, resistance to misuse, explainability and reasoning, adherenceto social norms, and robustness. Each major category is further divided intoseveral sub-categories, resulting in a total of 29 sub-categories.Additionally, a subset of 8 sub-categories is selected for furtherinvestigation, where corresponding measurement studies are designed andconducted on several widely-used LLMs. The measurement results indicate that,in general, more aligned models tend to perform better in terms of overalltrustworthiness. However, the effectiveness of alignment varies across thedifferent trustworthiness categories considered. This highlights the importanceof conducting more fine-grained analyses, testing, and making continuousimprovements on LLM alignment. By shedding light on these key dimensions of LLMtrustworthiness, this paper aims to provide valuable insights and guidance topractitioners in the field. Understanding and addressing these concerns will becrucial in achieving reliable and ethically sound deployment of LLMs in variousapplications.", "output": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In a fashion e-commerce platform where customers can't physically examine theproducts on their own, being able to see other customers' text and imagereviews of the product is critical while making purchase decisions. Given thehigh reliance on these reviews, over the years we have observed customersproactively sharing their reviews. With an increase in the coverage of UserGenerated Content (UGC), there has been a corresponding increase in the numberof customer images. It is thus imperative to display the most relevant imageson top as it may influence users' online shopping choices and behavior. In thispaper, we propose a simple yet effective training procedure for rankingcustomer images. We created a dataset consisting of Myntra (A Major IndianFashion e-commerce company) studio posts and highly engaged (upvotes/downvotes)UGC images as our starting point and used selected distortion techniques on theimages of the above dataset to bring their quality at par with those of bad UGCimages. We train our network to rank bad-quality images lower than high-qualityones. Our proposed method outperforms the baseline models on two metrics,namely correlation coefficient, and accuracy, by substantial margins.", "output": "Product Review Image Ranking for Fashion E-commerce."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With a rapidly increasing amount and diversity of remote sensing (RS) datasources, there is a strong need for multi-view learning modeling. This is acomplex task when considering the differences in resolution, magnitude, andnoise of RS data. The typical approach for merging multiple RS sources has beeninput-level fusion, but other - more advanced - fusion strategies mayoutperform this traditional approach. This work assesses different fusionstrategies for crop classification in the CropHarvest dataset. The fusionmethods proposed in this work outperform models based on individual views andprevious fusion methods. We do not find one single fusion method thatconsistently outperforms all other approaches. Instead, we present a comparisonof multi-view fusion methods for three different datasets and show that,depending on the test region, different methods obtain the best performance.Despite this, we suggest a preliminary criterion for the selection of fusionmethods.", "output": "A Comparative Assessment of Multi-view fusion learning for Crop Classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Artificial Intelligence in Medicine has made significant progress withemerging applications in medical imaging, patient care, and other areas. Whilethese applications have proven successful in retrospective studies, very few ofthem were applied in practice.The field of Medical AI faces various challenges,in terms of building user trust, complying with regulations, using dataethically.Explainable AI (XAI) aims to enable humans understand AI and trustits results. This paper presents a literature review on the recent developmentsof XAI solutions for medical decision support, based on a representative sampleof 198 articles published in recent years. The systematic synthesis of therelevant articles resulted in several findings. (1) model-agnostic XAItechniques were mostly employed in these solutions, (2) deep learning modelsare utilized more than other types of machine learning models, (3)explainability was applied to promote trust, but very few works reported thephysicians participation in the loop, (4) visual and interactive user interfaceis more useful in understanding the explanation and the recommendation of thesystem. More research is needed in collaboration between medical and AIexperts, that could guide the development of suitable frameworks for thedesign, implementation, and evaluation of XAI solutions in medicine.", "output": "Explainable AI applications in the Medical Domain: a systematic review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the big popularity and success of Judea Pearl's original causality book,this review covers the main topics updated in the second edition in 2009 andillustrates an easy-to-follow causal inference strategy in a forecast scenario.It further discusses some potential benefits and challenges for causalinference with time series forecasting when modeling the counterfactuals,estimating the uncertainty and incorporating prior knowledge to estimate causaleffects in different forecasting scenarios.", "output": "A Forecaster's Review of Judea Pearl's Causality: Models, Reasoning and Inference, Second Edition, 2009."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Node classification is the task of predicting the labels of unlabeled nodesin a graph. State-of-the-art methods based on graph neural networks achieveexcellent performance when all labels are available during training. But inreal-life, models are often applied on data with new classes, which can lead tomassive misclassification and thus significantly degrade performance. Hence,developing open-set classification methods is crucial to determine if a givensample belongs to a known class. Existing methods for open-set nodeclassification generally use transductive learning with part or all of thefeatures of real unseen class nodes to help with open-set classification. Inthis paper, we propose a novel generative open-set node classification method,i.e. $mathcal{G}^2Pxy$, which follows a stricter inductive learning settingwhere no information about unknown classes is available during training andvalidation. Two kinds of proxy unknown nodes, inter-class unknown proxies andexternal unknown proxies are generated via mixup to efficiently anticipate thedistribution of novel classes. Using the generated proxies, a closed-setclassifier can be transformed into an open-set one, by augmenting it with anextra proxy classifier. Under the constraints of both cross entropy loss andcomplement entropy loss, $mathcal{G}^2Pxy$ achieves superior effectiveness forunknown class detection and known class classification, which is validated byexperiments on benchmark graph datasets. Moreover, $mathcal{G}^2Pxy$ does nothave specific requirement on the GNN architecture and shows goodgeneralizations.", "output": "$\\mathcal{G}^2Pxy$: Generative Open-Set Node Classification on Graphs with Proxy Unknowns."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement learning (RL) under changing environment models many real-worldapplications via nonstationary Markov Decision Processes (MDPs), and hencegains considerable interest. However, theoretical studies on nonstationary MDPsin the literature have mainly focused on tabular and linear (mixture) MDPs,which do not capture the nature of unknown representation in deep RL. In thispaper, we make the first effort to investigate nonstationary RL under episodiclow-rank MDPs, where both transition kernels and rewards may vary over time,and the low-rank model contains unknown representation in addition to thelinear state embedding function. We first propose a parameter-dependent policyoptimization algorithm called PORTAL, and further improve PORTAL to itsparameter-free version of Ada-PORTAL, which is able to tune itshyper-parameters adaptively without any prior knowledge of nonstationarity. Forboth algorithms, we provide upper bounds on the average dynamic suboptimalitygap, which show that as long as the nonstationarity is not significantly large,PORTAL and Ada-PORTAL are sample-efficient and can achieve arbitrarily smallaverage dynamic suboptimality gap with polynomial sample complexity.", "output": "Provably Efficient Algorithm for Nonstationary Low-Rank MDPs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deceptive text classification is a critical task in natural languageprocessing that aims to identify deceptive or fraudulent content. This studypresents a comparative analysis of machine learning and transformer-basedapproaches for deceptive text classification. We investigate the effectivenessof traditional machine learning algorithms and state-of-the-art transformermodels, such as BERT, XLNET, DistilBERT, and RoBERTa, in detecting deceptivetext. A labeled dataset consisting of deceptive and non-deceptive texts is usedfor training and evaluation purposes. Through extensive experimentation, wecompare the performance metrics, including accuracy, precision, recall, and F1score, of the different approaches. The results of this study shed light on thestrengths and limitations of machine learning and transformer-based methods fordeceptive text classification, enabling researchers and practitioners to makeinformed decisions when dealing with deceptive content", "output": "Exploring Machine Learning and Transformer-based Approaches for Deceptive Text Classification: A Comparative Analysis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Database administrators (DBAs) play a crucial role in managing, maintainingand optimizing a database system to ensure data availability, performance, andreliability. However, it is hard and tedious for DBAs to manage a large numberof database instances (e.g., millions of instances on the cloud databases).Recently large language models (LLMs) have shown great potential to understandvaluable documents and accordingly generate reasonable answers. Thus, wepropose D-Bot, a LLM-based database administrator that can continuously acquiredatabase maintenance experience from textual sources, and provide reasonable,well-founded, in-time diagnosis and optimization advice for target databases.This paper presents a revolutionary LLM-centric framework for databasemaintenance, including (i) database maintenance knowledge detection fromdocuments and tools, (ii) tree of thought reasoning for root cause analysis,and (iii) collaborative diagnosis among multiple LLMs. Our preliminaryexperimental results that D-Bot can efficiently and effectively diagnose theroot causes and our code is available atgithub.com/TsinghuaDatabaseGroup/DB-GPT.", "output": "LLM As DBA."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Quality-Diversity (QD) methods are algorithms that aim to generate a set ofdiverse and high-performing solutions to a given problem. Originally developedfor evolutionary robotics, most QD studies are conducted on a limited set ofdomains - mainly applied to locomotion, where the fitness and the behaviorsignal are dense. Grasping is a crucial task for manipulation in robotics.Despite the efforts of many research communities, this task is yet to besolved. Grasping cumulates unprecedented challenges in QD literature: itsuffers from reward sparsity, behavioral sparsity, and behavior spacemisalignment. The present work studies how QD can address grasping. Experimentshave been conducted on 15 different methods on 10 grasping domains,corresponding to 2 different robot-gripper setups and 5 standard objects. Anevaluation framework that distinguishes the evaluation of an algorithm from itsinternal components has also been proposed for a fair comparison. The obtainedresults show that MAP-Elites variants that select successful solutions inpriority outperform all the compared methods on the studied metrics by a largemargin. We also found experimental evidence that sparse interaction can lead todeceptive novelty. To our knowledge, the ability to efficiently produceexamples of grasping trajectories demonstrated in this work has no precedent inthe literature.", "output": "Quality Diversity under Sparse Reward and Sparse Interaction: Application to Grasping in Robotics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper is devoted to studying the optimal expressive power of ReLU deepneural networks (DNNs) and its application in approximation via the KolmogorovSuperposition Theorem. We first constructively prove that any continuouspiecewise linear functions on $[0,1]$, comprising $O(N^2L)$ segments, can berepresented by ReLU DNNs with $L$ hidden layers and $N$ neurons per layer.Subsequently, we demonstrate that this construction is optimal regarding theparameter count of the DNNs, achieved through investigating the shatteringcapacity of ReLU DNNs. Moreover, by invoking the Kolmogorov SuperpositionTheorem, we achieve an enhanced approximation rate for ReLU DNNs of arbitrarywidth and depth when dealing with continuous functions in high-dimensionalspaces.", "output": "On the Optimal Expressive Power of ReLU DNNs and Its Application in Approximation with Kolmogorov Superposition Theorem."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Retrosynthesis consists of breaking down a chemical compound recursivelystep-by-step into molecular precursors until a set of commercially availablemolecules is found with the goal to provide a synthesis route. Its two primaryresearch directions, single-step retrosynthesis prediction, which models thechemical reaction logic, and multi-step synthesis planning, which tries to findthe correct sequence of reactions, are inherently intertwined. Still, thisconnection is not reflected in contemporary research. In this work, we combinethese two major research directions by applying multiple single-stepretrosynthesis models within multi-step synthesis planning and analyzing theirimpact using public and proprietary reaction data. We find a disconnectionbetween high single-step performance and potential route-finding success,suggesting that single-step models must be evaluated within synthesis planningin the future. Furthermore, we show that the commonly used single-stepretrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluationtask does not represent model performance and scalability on larger and morediverse datasets. For multi-step synthesis planning, we show that the choice ofthe single-step model can improve the overall success rate of synthesisplanning by up to +28% compared to the commonly used baseline model. Finally,we show that each single-step model finds unique synthesis routes, and differsin aspects such as route-finding success, the number of found synthesis routes,and chemical validity, making the combination of single-step retrosynthesisprediction and multi-step synthesis planning a crucial aspect when developingfuture methods.", "output": "Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The ability to cope accurately and fast with Out-Of-Distribution (OOD)samples is crucial in real-world safety demanding applications. In this work wefirst study the interplay between critical points of 3D point clouds and OODsamples. Our findings are that common corruptions and outliers are ofteninterpreted as critical points. We generalize the notion of critical pointsinto importance measures. We show that training a classification network basedonly on less important points dramatically improves robustness, at a cost ofminor performance loss on the clean set. We observe that normalized entropy ishighly informative for corruption analysis. An adaptive threshold based onnormalized entropy is suggested for selecting the set of uncritical points. Ourproposed importance measure is extremely fast to compute. We show it can beused for a variety of applications, such as Explainable AI (XAI), OutlierRemoval, Uncertainty Estimation, Robust Classification and Adversarial Defense.We reach SOTA results on the two latter tasks.", "output": "Critical Points ++: An Agile Point Cloud Importance Measure for Robust Classification, Adversarial Defense and Explainable AI."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large skew-t factor copula models are attractive for the modeling offinancial data because they allow for asymmetric and extreme tail dependence.We show that the copula implicit in the skew-t distribution of Azzalini andCapitanio (2003) allows for a higher level of pairwise asymmetric dependencethan two popular alternative skew-t copulas. Estimation of this copula in highdimensions is challenging, and we propose a fast and accurate Bayesianvariational inference (VI) approach to do so. The method uses a conditionallyGaussian generative representation of the skew-t distribution to define anaugmented posterior that can be approximated accurately. A fast stochasticgradient ascent algorithm is used to solve the variational optimization. Thenew methodology is used to estimate copula models for intraday returns from2017 to 2021 on 93 U.S. equities. The copula captures substantial heterogeneityin asymmetric dependence over equity pairs, in addition to the variability inpairwise correlations. We show that intraday predictive densities from theskew-t copula are more accurate than from some other copula models, whileportfolio selection strategies based on the estimated pairwise taildependencies improve performance relative to the benchmark index.", "output": "Efficient Variational Inference for Large Skew-t Copulas with Application to Intraday Equity Returns."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We introduce AutoGluon-TimeSeries - an open-source AutoML library forprobabilistic time series forecasting. Focused on ease of use and robustness,AutoGluon-TimeSeries enables users to generate accurate point and quantileforecasts with just 3 lines of Python code. Built on the design philosophy ofAutoGluon, AutoGluon-TimeSeries leverages ensembles of diverse forecastingmodels to deliver high accuracy within a short training time.AutoGluon-TimeSeries combines both conventional statistical models,machine-learning based forecasting approaches, and ensembling techniques. Inour evaluation on 29 benchmark datasets, AutoGluon-TimeSeries demonstratesstrong empirical performance, outperforming a range of forecasting methods interms of both point and quantile forecast accuracy, and often even improvingupon the best-in-hindsight combination of prior methods.", "output": "AutoGluon-TimeSeries: AutoML for Probabilistic Time Series Forecasting."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We examine whether symmetry can be used to defend tree-based ensembleclassifiers such as gradient-boosting decision trees (GBDTs) againstadversarial perturbation attacks. The idea is based on a recent symmetrydefense for convolutional neural network classifiers (CNNs) that utilizes CNNs'lack of invariance with respect to symmetries. CNNs lack invariance becausethey can classify a symmetric sample, such as a horizontally flipped image,differently from the original sample. CNNs' lack of invariance also means thatCNNs can classify symmetric adversarial samples differently from the incorrectclassification of adversarial samples. Using CNNs' lack of invariance, therecent CNN symmetry defense has shown that the classification of symmetricadversarial samples reverts to the correct sample classification. In order toapply the same symmetry defense to GBDTs, we examine GBDT invariance and arethe first to show that GBDTs also lack invariance with respect to symmetries.We apply and evaluate the GBDT symmetry defense for nine datasets against sixperturbation attacks with a threat model that ranges from zero-knowledge toperfect-knowledge adversaries. Using the feature inversion symmetry againstzero-knowledge adversaries, we achieve up to 100% accuracy on adversarialsamples even when default and robust classifiers have 0% accuracy. Using thefeature inversion and horizontal flip symmetries against perfect-knowledgeadversaries, we achieve up to over 95% accuracy on adversarial samples for theGBDT classifier of the F-MNIST dataset even when default and robust classifiershave 0% accuracy.", "output": "Symmetry Defense Against XGBoost Adversarial Perturbation Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep neural network (DNN) deployment has been confined to larger hardwaredevices due to their expensive computational requirements. This challenge hasrecently reached another scale with the emergence of large language models(LLMs). In order to reduce both their memory footprint and latency, a promisingtechnique is quantization. It consists in converting floating pointrepresentations to low bit-width fixed point representations, usually byassuming a uniform mapping onto a regular grid. This process, referred to inthe literature as uniform quantization, may however be ill-suited as most DNNweights and activations follow a bell-shaped distribution. This is even worseon LLMs whose weight distributions are known to exhibit large, high impact,outlier values. In this work, we propose an improvement over the most commonlyadopted way to tackle this limitation in deep learning models quantization,namely, non-uniform quantization. NUPES leverages automorphisms to preserve thescalar multiplications. Such transformations are derived from power functions.However, the optimization of the exponent parameter and weight values remains achallenging and novel problem which could not be solved with previous posttraining optimization techniques which only learn to round up or down weightvalues in order to preserve the predictive function. We circumvent thislimitation with a new paradigm: learning new quantized weights over the entirequantized space. Similarly, we enable the optimization of the power exponent,i.e. the optimization of the quantization operator itself during training byalleviating all the numerical instabilities. The resulting predictive functionis compatible with integer-only low-bit inference. We show the ability of themethod to achieve state-of-the-art compression rates in both, data-free anddata-driven configurations.", "output": "NUPES : Non-Uniform Post-Training Quantization via Power Exponent Search."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Inter-city highway transportation is significant for urban life. As one ofthe key functions in intelligent transportation system (ITS), trafficevaluation always plays significant role nowadays, and daily traffic flowprediction still faces challenges at network-wide toll stations. On the onehand, the data imbalance in practice among various locations deteriorates theperformance of prediction. On the other hand, complex correlativespatio-temporal factors cannot be comprehensively employed in long-termduration. In this paper, a prediction method is proposed for daily traffic flowin highway domain through spatio-temporal deep learning. In our method, datanormalization strategy is used to deal with data imbalance, due to long-taildistribution of traffic flow at network-wide toll stations. And then, based ongraph convolutional network, we construct networks in distinct semantics tocapture spatio-temporal features. Beside that, meteorology and calendarfeatures are used by our model in the full connection stage to extra externalcharacteristics of traffic flow. By extensive experiments and case studies inone Chinese provincial highway, our method shows clear improvement inpredictive accuracy than baselines and practical benefits in business.", "output": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As data shift or new data become available, updating clinical machinelearning models may be necessary to maintain or improve performance over time.However, updating a model can introduce compatibility issues when the behaviorof the updated model does not align with user expectations, resulting in pooruser-model team performance. Existing compatibility measures depend on modeldecision thresholds, limiting their applicability in settings where models areused to generate rankings based on estimated risk. To address this limitation,we propose a novel rank-based compatibility measure, $C^R$, and a new lossfunction that aims to optimize discriminative performance while encouraginggood compatibility. Applied to a case study in mortality risk stratificationleveraging data from MIMIC, our approach yields more compatible models whilemaintaining discriminative performance compared to existing model selectiontechniques, with an increase in $C^R$ of $0.019$ ($95%$ confidence interval:$0.005$, $0.035$). This work provides new tools to analyze and update riskstratification models used in clinical care.", "output": "Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In this short note, I show how to adapt to H\"{o}lder smoothness usingnormalized gradients in a black-box way. Moreover, the bound will depend on anovel notion of local H\"{o}lder smoothness. The main idea directly comes fromLevy [2017].", "output": "Normalized Gradients for All."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We replace the multiplication and sigmoid function of the conventionalrecurrent gate with addition and ReLU activation. This mechanism is designed tomaintain long-term memory for sequence processing but at a reducedcomputational cost, thereby opening up for more efficient execution or largermodels on restricted hardware. Recurrent Neural Networks (RNNs) with gatingmechanisms such as LSTM and GRU have been widely successful in learning fromsequential data due to their ability to capture long-term dependencies.Conventionally, the update based on current inputs and the previous statehistory is each multiplied with dynamic weights and combined to compute thenext state. However, multiplication can be computationally expensive,especially for certain hardware architectures or alternative arithmetic systemssuch as homomorphic encryption. It is demonstrated that the novel gatingmechanism can capture long-term dependencies for a standard synthetic sequencelearning task while significantly reducing computational costs such thatexecution time is reduced by half on CPU and by one-third under encryption.Experimental results on handwritten text recognition tasks furthermore showthat the proposed architecture can be trained to achieve comparable accuracy toconventional GRU and LSTM baselines. The gating mechanism introduced in thispaper may enable privacy-preserving AI applications operating under homomorphicencryption by avoiding the multiplication of encrypted variables. It can alsosupport quantization in (unencrypted) plaintext applications, with thepotential for substantial performance gains since the addition-basedformulation can avoid the expansion to double precision often required formultiplication.", "output": "ReLU and Addition-based Gated RNN."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated medical report generation has become increasingly important inmedical analysis. It can produce computer-aided diagnosis descriptions and thussignificantly alleviate the doctors' work. Inspired by the huge success ofneural machine translation and image captioning, various deep learning methodshave been proposed for medical report generation. However, due to the inherentproperties of medical data, including data imbalance and the length andcorrelation between report sequences, the generated reports by existing methodsmay exhibit linguistic fluency but lack adequate clinical accuracy. In thiswork, we propose an image-to-indicator hierarchical transformer (IIHT)framework for medical report generation. It consists of three modules, i.e., aclassifier module, an indicator expansion module and a generator module. Theclassifier module first extracts image features from the input medical imagesand produces disease-related indicators with their corresponding states. Thedisease-related indicators are subsequently utilised as input for the indicatorexpansion module, incorporating the \"data-text-data\" strategy. Thetransformer-based generator then leverages these extracted features along withimage features as auxiliary information to generate final reports. Furthermore,the proposed IIHT method is feasible for radiologists to modify diseaseindicators in real-world scenarios and integrate the operations into theindicator expansion module for fluent and accurate medical report generation.Extensive experiments and comparisons with state-of-the-art methods undervarious evaluation metrics demonstrate the great performance of the proposedmethod.", "output": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Code summarization aims to generate concise natural language descriptions forsource code. The prevailing approaches adopt transformer-based encoder-decoderarchitectures, where the Abstract Syntax Tree (AST) of the source code isutilized for encoding structural information. However, ASTs are much longerthan the corresponding source code, and existing methods ignore this sizeconstraint by directly feeding the entire linearized AST into the encoders.This simplistic approach makes it challenging to extract truly valuabledependency relations from the overlong input sequence and leads to significantcomputational overhead due to self-attention applied to all nodes in the AST.To address this issue effectively and efficiently, we present a model,AST-MHSA that uses multi-head attention to extract the important semanticinformation from the AST. The model consists of two main components: an encoderand a decoder. The encoder takes as input the abstract syntax tree (AST) of thecode and generates a sequence of hidden states. The decoder then takes thesehidden states as input and generates a natural language summary of the code.The multi-head attention mechanism allows the model to learn differentrepresentations of the input code, which can be combined to generate a morecomprehensive summary. The model is trained on a dataset of code and summaries,and the parameters of the model are optimized to minimize the loss between thegenerated summaries and the ground-truth summaries.", "output": "AST-MHSA : Code Summarization using Multi-Head Self-Attention."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The task of retrieving already debunked narratives aims to detect storiesthat have already been fact-checked. The successful detection of claims thathave already been debunked not only reduces the manual efforts of professionalfact-checkers but can also contribute to slowing the spread of misinformation.Mainly due to the lack of readily available data, this is an understudiedproblem, particularly when considering the cross-lingual task, i.e. theretrieval of fact-checking articles in a language different from the languageof the online post being checked. This paper fills this gap by (i) creating anovel dataset to enable research on cross-lingual retrieval of already debunkednarratives, using tweets as queries to a database of fact-checking articles;(ii) presenting an extensive experiment to benchmark fine-tuned andoff-the-shelf multilingual pre-trained Transformer models for this task; and(iii) proposing a novel multistage framework that divides this cross-lingualdebunk retrieval task into refinement and re-ranking stages. Results show thatthe task of cross-lingual retrieval of already debunked narratives ischallenging and off-the-shelf Transformer models fail to outperform a stronglexical-based baseline (BM25). Nevertheless, our multistage retrieval frameworkis robust, outperforming BM25 in most scenarios and enabling cross-domain andzero-shot learning, without significantly harming the model's performance.", "output": "Finding Already Debunked Narratives via Multistage Retrieval: Enabling Cross-Lingual, Cross-Dataset and Zero-Shot Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recently, methods for skeleton-based human activity recognition have beenshown to be vulnerable to adversarial attacks. However, these attack methodsrequire either the full knowledge of the victim (i.e. white-box attacks),access to training data (i.e. transfer-based attacks) or frequent model queries(i.e. black-box attacks). All their requirements are highly restrictive,raising the question of how detrimental the vulnerability is. In this paper, weshow that the vulnerability indeed exists. To this end, we consider a newattack task: the attacker has no access to the victim model or the trainingdata or labels, where we coin the term hard no-box attack. Specifically, wefirst learn a motion manifold where we define an adversarial loss to compute anew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Ourgradient contains information of the motion dynamics, which is different fromexisting gradient-based attack methods that compute the loss gradient assumingeach dimension in the data is independent. The SMI gradient can augment manygradient-based attack methods, leading to a new family of no-box attackmethods. Extensive evaluation and comparison show that our method imposes areal threat to existing classifiers. They also show that the SMI gradientimproves the transferability and imperceptibility of adversarial samples inboth no-box and transfer-based black-box settings.", "output": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Discovering causal relations among semantic factors is an emergent topic inrepresentation learning. Most causal representation learning (CRL) methods arefully supervised, which is impractical due to costly labeling. To resolve thisrestriction, weakly supervised CRL methods were introduced. To evaluate CRLperformance, four existing datasets, Pendulum, Flow, CelebA(BEARD) andCelebA(SMILE), are utilized. However, existing CRL datasets are limited tosimple graphs with few generative factors. Thus we propose two new datasetswith a larger number of diverse generative factors and more sophisticatedcausal graphs. In addition, current real datasets, CelebA(BEARD) andCelebA(SMILE), the originally proposed causal graphs are not aligned with thedataset distributions. Thus, we propose modifications to them.", "output": "Shadow Datasets, New challenging datasets for Causal Representation Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement learning (RL) is a promising approach for optimizing HVACcontrol. RL offers a framework for improving system performance, reducingenergy consumption, and enhancing cost efficiency. We benchmark two popularclassical and deep RL methods (Q-Learning and Deep-Q-Networks) across multipleHVAC environments and explore the practical consideration of modelhyper-parameter selection and reward tuning. The findings provide insight forconfiguring RL agents in HVAC systems, promoting energy-efficient andcost-effective operation.", "output": "A Comparison of Classical and Deep Reinforcement Learning Methods for HVAC Control."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep learning training training algorithms are a huge success in recent yearsin many fields including speech, text,image video etc. Deeper and deeper layersare proposed with huge success with resnet structures having around 152 layers.Shallow convolution neural networks(CNN's) are still an active research, wheresome phenomena are still unexplained. Activation functions used in the networkare of utmost importance, as they provide non linearity to the networks. Relu'sare the most commonly used activation function.We show a complex piece-wiselinear(PWL) activation in the hidden layer. We show that these PWL activationswork much better than relu activations in our networks for convolution neuralnetworks and multilayer perceptrons. Result comparison in PyTorch for shallowand deep CNNs are given to further strengthen our case.", "output": "Optimizing Performance of Feedforward and Convolutional Neural Networks through Dynamic Activation Functions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent work has shown that it is possible to resynthesize high-quality speechbased, not on text, but on low bitrate discrete units that have been learned ina self-supervised fashion and can therefore capture expressive aspects ofspeech that are hard to transcribe (prosody, voice styles, non-verbalvocalization). The adoption of these methods is still limited by the fact thatmost speech synthesis datasets are read, severely limiting spontaneity andexpressivity. Here, we introduce Expresso, a high-quality expressive speechdataset for textless speech synthesis that includes both read speech andimprovised dialogues rendered in 26 spontaneous expressive styles. Weillustrate the challenges and potentials of this dataset with an expressiveresynthesis benchmark where the task is to encode the input in low-bitrateunits and resynthesize it in a target voice while preserving content and style.We evaluate resynthesis quality with automatic metrics for differentself-supervised discrete encoders, and explore tradeoffs between quality,bitrate and invariance to speaker and style. All the dataset, evaluationmetrics and baseline models are open source", "output": "EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech Resynthesis."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Automated driving has the potential to revolutionize personal, public, andfreight mobility. Besides the enormous challenge of perception, i.e. accuratelyperceiving the environment using available sensor data, automated drivingcomprises planning a safe, comfortable, and efficient motion trajectory. Topromote safety and progress, many works rely on modules that predict the futuremotion of surrounding traffic. Modular automated driving systems commonlyhandle prediction and planning as sequential separate tasks. While thisaccounts for the influence of surrounding traffic on the ego-vehicle, it failsto anticipate the reactions of traffic participants to the ego-vehicle'sbehavior. Recent works suggest that integrating prediction and planning in aninterdependent joint step is necessary to achieve safe, efficient, andcomfortable driving. While various models implement such integrated systems, acomprehensive overview and theoretical understanding of different principlesare lacking. We systematically review state-of-the-art deep learning-basedprediction, planning, and integrated prediction and planning models. Differentfacets of the integration ranging from model architecture and model design tobehavioral aspects are considered and related to each other. Moreover, wediscuss the implications, strengths, and limitations of different integrationmethods. By pointing out research gaps, describing relevant future challenges,and highlighting trends in the research field, we identify promising directionsfor future research.", "output": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Time-dependent partial differential equations (PDEs) are ubiquitous inscience and engineering. Recently, mostly due to the high computational cost oftraditional solution techniques, deep neural network based surrogates havegained increased interest. The practical utility of such neural PDE solversrelies on their ability to provide accurate, stable predictions over long timehorizons, which is a notoriously hard problem. In this work, we present alarge-scale analysis of common temporal rollout strategies, identifying theneglect of non-dominant spatial frequency information, often associated withhigh frequencies in PDE solutions, as the primary pitfall limiting stable,accurate rollout performance. Based on these insights, we draw inspiration fromrecent advances in diffusion models to introduce PDE-Refiner; a novel modelclass that enables more accurate modeling of all frequency components via amultistep refinement process. We validate PDE-Refiner on challenging benchmarksof complex fluid dynamics, demonstrating stable and accurate rollouts thatconsistently outperform state-of-the-art models, including neural, numerical,and hybrid neural-numerical architectures. We further demonstrate thatPDE-Refiner greatly enhances data efficiency, since the denoising objectiveimplicitly induces a novel form of spectral data augmentation. Finally,PDE-Refiner's connection to diffusion models enables an accurate and efficientassessment of the model's predictive uncertainty, allowing us to estimate whenthe surrogate becomes inaccurate.", "output": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Tracking and following objects of interest is critical to several roboticsuse cases, ranging from industrial automation to logistics and warehousing, tohealthcare and security. In this paper, we present a robotic system to detect,track, and follow any object in real-time. Our approach, dubbed ``followanything'' (FAn), is an open-vocabulary and multimodal model -- it is notrestricted to concepts seen at training time and can be applied to novelclasses at inference time using text, images, or click queries. Leveraging richvisual descriptors from large-scale pre-trained models (foundation models), FAncan detect and segment objects by matching multimodal queries (text, images,clicks) against an input image sequence. These detected and segmented objectsare tracked across image frames, all while accounting for occlusion and objectre-emergence. We demonstrate FAn on a real-world robotic system (a micro aerialvehicle) and report its ability to seamlessly follow the objects of interest ina real-time control loop. FAn can be deployed on a laptop with a lightweight(6-8 GB) graphics card, achieving a throughput of 6-20 frames per second. Toenable rapid adoption, deployment, and extensibility, we open-source all ourcode on our project webpage at  .We also encourage the reader the watch our 5-minutes explainer video in this .", "output": "Follow Anything: Open-set detection, tracking, and following in real-time."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Gradient-based optimization is now ubiquitous across graphics, butunfortunately can not be applied to problems with undefined or zero gradients.To circumvent this issue, the loss function can be manually replaced by a\"surrogate\" that has similar minima but is differentiable. Our proposedframework, ZeroGrads, automates this process by learning a neural approximationof the objective function, the surrogate, which in turn can be used todifferentiate through arbitrary black-box graphics pipelines. We train thesurrogate on an actively smoothed version of the objective and encouragelocality, focusing the surrogate's capacity on what matters at the currenttraining episode. The fitting is performed online, alongside the parameteroptimization, and self-supervised, without pre-computed data or pre-trainedmodels. As sampling the objective is expensive (it requires a full rendering orsimulator run), we devise an efficient sampling scheme that allows fortractable run-times and competitive performance at little overhead. Wedemonstrate optimizing diverse non-convex, non-differentiable black-boxproblems in graphics, such as visibility in rendering, discrete parameterspaces in procedural modelling or optimal control in physics-driven animation.In contrast to more traditional algorithms, our approach scales well to higherdimensions, which we demonstrate on problems with up to 35k interlinkedvariables.", "output": "Zero Grads Ever Given: Learning Local Surrogate Losses for Non-Differentiable Graphics."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The recent proliferation of 3D content that can be consumed on hand-helddevices necessitates efficient tools for transmitting large geometric data,e.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose achallenge to storage as well as transmission bandwidth, and level-of-detailtechniques are often used to transmit an asset using an appropriate bandwidthbudget. It is especially desirable for these methods to transmit dataprogressively, improving the quality of the geometry with more data. Our keyinsight is that the geometric details of 3D meshes often exhibit similar localpatterns even across different shapes, and thus can be effectively representedwith a shared learned generative space. We learn this space using asubdivision-based encoder-decoder architecture trained in advance on a largecollection of surfaces. We further observe that additional residual featurescan be transmitted progressively between intermediate levels of subdivisionthat enable the client to control the tradeoff between bandwidth cost andquality of reconstruction, providing a neural progressive mesh representation.We evaluate our method on a diverse set of complex 3D shapes and demonstratethat it outperforms baselines in terms of compression ratio and reconstructionquality.", "output": "Neural Progressive Meshes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Here, we show that the InfoNCE objective is equivalent to the ELBO in a newclass of probabilistic generative model, the recognition parameterised model(RPM). When we learn the optimal prior, the RPM ELBO becomes equal to themutual information (MI; up to a constant), establishing a connection topre-existing self-supervised learning methods such as InfoNCE. However,practical InfoNCE methods do not use the MI as an objective; the MI isinvariant to arbitrary invertible transformations, so using an MI objective canlead to highly entangled representations (Tschannen et al., 2019). Instead, theactual InfoNCE objective is a simplified lower bound on the MI which is looseeven in the infinite sample limit. Thus, an objective that works (i.e. theactual InfoNCE objective) appears to be motivated as a loose bound on anobjective that does not work (i.e. the true MI which gives arbitrarilyentangled representations). We give an alternative motivation for the actualInfoNCE objective. In particular, we show that in the infinite sample limit,and for a particular choice of prior, the actual InfoNCE objective is equal tothe ELBO (up to a constant); and the ELBO is equal to the marginal likelihoodwith a deterministic recognition model. Thus, we argue that our VAE perspectivegives a better motivation for InfoNCE than MI, as the actual InfoNCE objectiveis only loosely bounded by the MI, but is equal to the ELBO/marginal likelihood(up to a constant).", "output": "InfoNCE is variational inference in a recognition parameterised model."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We propose an efficient distributed out-of-memory implementation of theNon-negative Matrix Factorization (NMF) algorithm for heterogeneoushigh-performance-computing (HPC) systems. The proposed implementation is basedon prior work on NMFk, which can perform automatic model selection and extractlatent variables and patterns from data. In this work, we extend NMFk by addingsupport for dense and sparse matrix operation on multi-node, multi-GPU systems.The resulting algorithm is optimized for out-of-memory (OOM) problems where thememory required to factorize a given matrix is greater than the available GPUmemory. Memory complexity is reduced by batching/tiling strategies, and sparseand dense matrix operations are significantly accelerated with GPU cores (ortensor cores when available). Input/Output (I/O) latency associated with batchcopies between host and device is hidden using CUDA streams to overlap datatransfers and compute asynchronously, and latency associated with collectivecommunications (both intra-node and inter-node) is reduced using optimizedNVIDIA Collective Communication Library NCCL based communicators. Benchmarkresults show significant improvement, from 32X to 76x speedup, with the newimplementation using GPUs over the CPU-based NMFk. Good weak scaling wasdemonstrated on up to 4096 multi-GPU cluster nodes with approximately 25,000GPUs when decomposing a dense 340 Terabyte-size matrix and an 11 Exabyte-sizesparse matrix of density 10e-6.", "output": "Distributed Out-of-Memory NMF on CPU/GPU Architectures."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Learning disentangled representations with variational autoencoders (VAEs) isoften attributed to the regularisation component of the loss. In this work, wehighlight the interaction between data and the reconstruction term of the lossas the main contributor to disentanglement in VAEs. We show that standardbenchmark datasets have unintended correlations between their subjectiveground-truth factors and perceived axes in the data according to typical VAEreconstruction losses. Our work exploits this relationship to provide a theoryfor what constitutes an adversarial dataset under a given reconstruction loss.We verify this by constructing an example dataset that prevents disentanglementin state-of-the-art frameworks while maintaining human-intuitive ground-truthfactors. Finally, we re-enable disentanglement by designing an examplereconstruction loss that is once again able to perceive the ground-truthfactors. Our findings demonstrate the subjective nature of disentanglement andthe importance of considering the interaction between the ground-truth factors,data and notably, the reconstruction loss, which is under-recognised in theliterature.", "output": "Overlooked Implications of the Reconstruction Loss for VAE Disentanglement."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As a successful approach to self-supervised learning, contrastive learningaims to learn invariant information shared among distortions of the inputsample. While contrastive learning has yielded continuous advancements insampling strategy and architecture design, it still remains two persistentdefects: the interference of task-irrelevant information and sampleinefficiency, which are related to the recurring existence of trivial constantsolutions. From the perspective of dimensional analysis, we find out that thedimensional redundancy and dimensional confounder are the intrinsic issuesbehind the phenomena, and provide experimental evidence to support ourviewpoint. We further propose a simple yet effective approach MetaMask, shortfor the dimensional Mask learned by Meta-learning, to learn representationsagainst dimensional redundancy and confounder. MetaMask adopts theredundancy-reduction technique to tackle the dimensional redundancy issue andinnovatively introduces a dimensional mask to reduce the gradient effects ofspecific dimensions containing the confounder, which is trained by employing ameta-learning paradigm with the objective of improving the performance ofmasked representations on a typical self-supervised task. We provide solidtheoretical analyses to prove MetaMask can obtain tighter risk bounds fordownstream classification compared to typical contrastive methods. Empirically,our method achieves state-of-the-art performance on various benchmarks.", "output": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "When applied to autonomous vehicle (AV) settings, action recognition canenhance an environment model's situational awareness. This is especiallyprevalent in scenarios where traditional geometric descriptions and heuristicsin AVs are insufficient. However, action recognition has traditionally beenstudied for humans, and its limited adaptability to noisy, un-clipped,un-pampered, raw RGB data has limited its application in other fields. To pushfor the advancement and adoption of action recognition into AVs, this workproposes a novel two-stage action recognition system, termed RALACs. RALACsformulates the problem of action recognition for road scenes, and bridges thegap between it and the established field of human action recognition. This workshows how attention layers can be useful for encoding the relations acrossagents, and stresses how such a scheme can be class-agnostic. Furthermore, toaddress the dynamic nature of agents on the road, RALACs constructs a novelapproach to adapting Region of Interest (ROI) Alignment to agent tracks fordownstream action classification. Finally, our scheme also considers theproblem of active agent detection, and utilizes a novel application of fusingoptical flow maps to discern relevant agents in a road scene. We show that ourproposed scheme can outperform the baseline on the ICCV2021 Road Challengedataset and by deploying it on a real vehicle platform, we provide preliminaryinsight to the usefulness of action recognition in decision making.", "output": "RALACs: Action Recognition in Autonomous Vehicles using Interaction Encoding and Optical Flow."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper uses symmetry to make Convolutional Neural Network classifiers(CNNs) robust against adversarial perturbation attacks. Such attacks addperturbation to original images to generate adversarial images that foolclassifiers such as road sign classifiers of autonomous vehicles. Althoughsymmetry is a pervasive aspect of the natural world, CNNs are unable to handlesymmetry well. For example, a CNN can classify an image differently from itsmirror image. For an adversarial image that misclassifies with a wrong label$l_w$, CNN inability to handle symmetry means that a symmetric adversarialimage can classify differently from the wrong label $l_w$. Further than that,we find that the classification of a symmetric adversarial image reverts to thecorrect label. To classify an image when adversaries are unaware of thedefense, we apply symmetry to the image and use the classification label of thesymmetric image. To classify an image when adversaries are aware of thedefense, we use mirror symmetry and pixel inversion symmetry to form a symmetrygroup. We apply all the group symmetries to the image and decide on the outputlabel based on the agreement of any two of the classification labels of thesymmetry images. Adaptive attacks fail because they need to rely on lossfunctions that use conflicting CNN output values for symmetric images. Withoutattack knowledge, the proposed symmetry defense succeeds against bothgradient-based and random-search attacks, with up to near-default accuraciesfor ImageNet. The defense even improves the classification accuracy of originalimages.", "output": "Symmetry Defense Against CNN Adversarial Perturbation Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Differential privacy (DP) is by far the most widely accepted framework formitigating privacy risks in machine learning. However, exactly how small theprivacy parameter $epsilon$ needs to be to protect against certain privacyrisks in practice is still not well-understood. In this work, we study datareconstruction attacks for discrete data and analyze it under the framework ofmultiple hypothesis testing. We utilize different variants of the celebratedFano's inequality to derive upper bounds on the inferential power of a datareconstruction adversary when the model is trained differentially privately.Importantly, we show that if the underlying private data takes values from aset of size $M$, then the target privacy parameter $epsilon$ can be $O(logM)$ before the adversary gains significant inferential power. Our analysisoffers theoretical evidence for the empirical effectiveness of DP against datareconstruction attacks even at relatively large values of $epsilon$.", "output": "Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis Testing: A Lesson From Fano."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "In private federated learning (FL), a server aggregates differentiallyprivate updates from a large number of clients in order to train a machinelearning model. The main challenge in this setting is balancing privacy withboth classification accuracy of the learnt model as well as the number of bitscommunicated between the clients and server. Prior work has achieved a goodtrade-off by designing a privacy-aware compression mechanism, called theminimum variance unbiased (MVU) mechanism, that numerically solves anoptimization problem to determine the parameters of the mechanism. This paperbuilds upon it by introducing a new interpolation procedure in the numericaldesign process that allows for a far more efficient privacy analysis. Theresult is the new Interpolated MVU mechanism that is more scalable, has abetter privacy-utility trade-off, and provides SOTA results oncommunication-efficient private FL on a variety of datasets.", "output": "Privacy-Aware Compression for Federated Learning Through Numerical Mechanism Design."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper surveys some recent developments in measures of associationrelated to a new coefficient of correlation introduced by the author. Astraightforward extension of this coefficient to standard Borel spaces (whichincludes all Polish spaces), overlooked in the literature so far, is proposedat the end of the survey.", "output": "A survey of some recent developments in measures of association."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The application of deep learning to non-stationary temporal datasets can leadto overfitted models that underperform under regime changes. In this work, wepropose a modular machine learning pipeline for ranking predictions on temporalpanel datasets which is robust under regime changes. The modularity of thepipeline allows the use of different models, including Gradient BoostingDecision Trees (GBDTs) and Neural Networks, with and without featureengineering. We evaluate our framework on financial data for stock portfolioprediction, and find that GBDT models with dropout display high performance,robustness and generalisability with reduced complexity and computational cost.We then demonstrate how online learning techniques, which require no retrainingof models, can be used post-prediction to enhance the results. First, we showthat dynamic feature projection improves robustness by reducing drawdown inregime changes. Second, we demonstrate that dynamical model ensembling based onselection of models with good recent performance leads to improved Sharpe andCalmar ratios of out-of-sample predictions. We also evaluate the robustness ofour pipeline across different data splits and random seeds with goodreproducibility.", "output": "Online learning techniques for prediction of temporal tabular datasets with regime changes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "It is desirable for statistical models to detect signals of interestindependently of their position. If the data is generated by some smoothprocess, this additional structure should be taken into account. We introduce anew class of neural networks that are shift invariant and preserve smoothnessof the data: functional neural networks (FNNs). For this, we use methods fromfunctional data analysis (FDA) to extend multi-layer perceptrons andconvolutional neural networks to functional data. We propose different modelarchitectures, show that the models outperform a benchmark model from FDA interms of accuracy and successfully use FNNs to classify electroencephalography(EEG) data.", "output": "Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The state-of-the-art predictive maintenance (PdM) techniques have shown greatsuccess in reducing maintenance costs and downtime of complicated machineswhile increasing overall productivity through extensive utilization ofInternet-of-Things (IoT) and Deep Learning (DL). Unfortunately, IoT sensors andDL algorithms are both prone to cyber-attacks. For instance, DL algorithms areknown for their susceptibility to adversarial examples. Such adversarialattacks are vastly under-explored in the PdM domain. This is because theadversarial attacks in the computer vision domain for classification taskscannot be directly applied to the PdM domain for multivariate time series (MTS)regression tasks. In this work, we propose an end-to-end methodology to designadversarially robust PdM systems by extensively analyzing the effect ofdifferent types of adversarial attacks and proposing a novel adversarialdefense technique for DL-enabled PdM models. First, we propose novel MTSProjected Gradient Descent (PGD) and MTS PGD with random restarts (PGD_r)attacks. Then, we evaluate the impact of MTS PGD and PGD_r along with MTS FastGradient Sign Method (FGSM) and MTS Basic Iterative Method (BIM) on LongShort-Term Memory (LSTM), Gated Recurrent Unit (GRU), Convolutional NeuralNetwork (CNN), and Bi-directional LSTM based PdM system. Our results usingNASA's turbofan engine dataset show that adversarial attacks can cause a severedefect (up to 11X) in the RUL prediction, outperforming the effectiveness ofthe state-of-the-art PdM attacks by 3X. Furthermore, we present a novelapproximate adversarial training method to defend against adversarial attacks.We observe that approximate adversarial training can significantly improve therobustness of PdM models (up to 54X) and outperforms the state-of-the-art PdMdefense methods by offering 3X more robustness.", "output": "RobustPdM: Designing Robust Predictive Maintenance against Adversarial Attacks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We show that taking the width and depth to infinity in a deep neural networkwith skip connections, when branches are scaled by $1/sqrt{depth}$ (the onlynontrivial scaling), result in the same covariance structure no matter how thatlimit is taken. This explains why the standard infinite-width-then-depthapproach provides practical insights even for networks with depth of the sameorder as width. We also demonstrate that the pre-activations, in this case,have Gaussian distributions which has direct applications in Bayesian deeplearning. We conduct extensive simulations that show an excellent match withour theoretical findings.", "output": "Width and Depth Limits Commute in Residual Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Riemannian submanifold optimization with momentum is computationallychallenging because, to ensure that the iterates remain on the submanifold, weoften need to solve difficult differential equations. Here, we simplify suchdifficulties for a class of sparse or structured symmetric positive-definitematrices with the affine-invariant metric. We do so by proposing a generalizedversion of the Riemannian normal coordinates that dynamically orthonormalizesthe metric and locally converts the problem into an unconstrained problem inthe Euclidean space. We use our approach to simplify existing approaches forstructured covariances and develop matrix-inverse-free $2^text{nd}$-orderoptimizers for deep learning with low precision by using only matrixmultiplications. Code: ", "output": "Simplifying Momentum-based Positive-definite Submanifold Optimization with Applications to Deep Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Electronic Health Records (EHRs) contain sensitive patient information, whichpresents privacy concerns when sharing such data. Synthetic data generation isa promising solution to mitigate these risks, often relying on deep generativemodels such as Generative Adversarial Networks (GANs). However, recent studieshave shown that diffusion models offer several advantages over GANs, such asgeneration of more realistic synthetic data and stable training in generatingdata modalities, including image, text, and sound. In this work, we investigatethe potential of diffusion models for generating realistic mixed-type tabularEHRs, comparing TabDDPM model with existing methods on four datasets in termsof data quality, utility, privacy, and augmentation. Our experimentsdemonstrate that TabDDPM outperforms the state-of-the-art models across allevaluation metrics, except for privacy, which confirms the trade-off betweenprivacy and utility.", "output": "Synthesizing Mixed-type Electronic Health Records using Diffusion Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This study proposes a hybrid deep-learning-metaheuristic framework with abi-level architecture for road network design problems (NDPs). We train a graphneural network (GNN) to approximate the solution of the user equilibrium (UE)traffic assignment problem and use inferences made by the trained model tocalculate fitness function evaluations of a genetic algorithm (GA) toapproximate solutions for NDPs. Using three test networks, two NDP variants andan exact solver as benchmark, we show that on average, our proposed frameworkcan provide solutions within 1.5% gap of the best results in less than 0.5% ofthe time used by the exact solution procedure. Our framework can be utilizedwithin an expert system for infrastructure planning to determine the bestinfrastructure planning and management decisions under different scenarios.Given the flexibility of the framework, it can easily be adapted to many otherdecision problems that can be modeled as bi-level problems on graphs. Moreover,we foreseen interesting future research directions, thus we also put forward abrief research agenda for this topic. The key observation from our researchthat can shape future research is that the fitness function evaluation timeusing the inferences made by the GNN model was in the order of milliseconds,which points to an opportunity and a need for novel heuristics that 1) can copewell with noisy fitness function values provided by deep learning models, and2) can use the significantly enlarged efficiency of the evaluation step toexplore the search space effectively (rather than efficiently). This opens anew avenue for a modern class of metaheuristics that are crafted for use withAI-powered predictors.", "output": "A hybrid deep-learning-metaheuristic framework for bi-level network design problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The decentralized and privacy-preserving nature of federated learning (FL)makes it vulnerable to backdoor attacks aiming to manipulate the behavior ofthe resulting model on specific adversary-chosen inputs. However, most existingdefenses based on statistical differences take effect only against specificattacks, especially when the malicious gradients are similar to benign ones orthe data are highly non-independent and identically distributed (non-IID). Inthis paper, we revisit the distance-based defense methods and discover that i)Euclidean distance becomes meaningless in high dimensions and ii) maliciousgradients with diverse characteristics cannot be identified by a single metric.To this end, we present a simple yet effective defense strategy withmulti-metrics and dynamic weighting to identify backdoors adaptively.Furthermore, our novel defense has no reliance on predefined assumptions overattack settings or data distributions and little impact on benign performance.To evaluate the effectiveness of our approach, we conduct comprehensiveexperiments on different datasets under various attack settings, where ourmethod achieves the best defensive performance. For instance, we achieve thelowest backdoor accuracy of 3.06% under the difficult Edge-case PGD, showingsignificant superiority over previous defenses. The results also demonstratethat our method can be well-adapted to a wide range of non-IID degrees withoutsacrificing the benign performance.", "output": "Multi-metrics adaptively identifies backdoors in Federated learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "We present a robust deep incremental learning framework for regression taskson financial temporal tabular datasets which is built upon the incremental useof commonly available tabular and time series prediction models to adapt todistributional shifts typical of financial datasets. The framework uses asimple basic building block (decision trees) to build self-similar models ofany required complexity to deliver robust performance under adverse situationssuch as regime changes, fat-tailed distributions, and low signal-to-noiseratios. As a detailed study, we demonstrate our scheme using XGBoost modelstrained on the Numerai dataset and show that a two layer deep ensemble ofXGBoost models over different model snapshots delivers high quality predictionsunder different market regimes. We also show that the performance of XGBoostmodels with different number of boosting rounds in three scenarios (small,standard and large) is monotonically increasing with respect to model size andconverges towards the generalisation upper bound. We also evaluate therobustness of the model under variability of different hyperparameters, such asmodel complexity and data sampling settings. Our model has low hardwarerequirements as no specialised neural architectures are used and each basemodel can be independently trained in parallel.", "output": "Deep incremental learning models for financial temporal tabular datasets with distribution shifts."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural network approaches to approximate the ground state of quantumhamiltonians require the numerical solution of a highly nonlinear optimizationproblem. We introduce a statistical learning approach that makes theoptimization trivial by using kernel methods. Our scheme is an approximaterealization of the power method, where supervised learning is used to learn thenext step of the power iteration. We show that the ground state properties ofarbitrary gapped quantum hamiltonians can be reached with polynomial resourcesunder the assumption that the supervised learning is efficient. Using kernelridge regression, we provide numerical evidence that the learning assumption isverified by applying our scheme to find the ground states of severalprototypical interacting many-body quantum systems, both in one and twodimensions, showing the flexibility of our approach.", "output": "Learning ground states of gapped quantum Hamiltonians with Kernel Methods."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "As the use of machine learning continues to expand, the importance ofensuring its safety cannot be overstated. A key concern in this regard is theability to identify whether a given sample is from the training distribution,or is an \"Out-Of-Distribution\" (OOD) sample. In addition, adversaries canmanipulate OOD samples in ways that lead a classifier to make a confidentprediction. In this study, we present a novel approach for certifying therobustness of OOD detection within a $ell_2$-norm around the input, regardlessof network architecture and without the need for specific components oradditional training. Further, we improve current techniques for detectingadversarial attacks on OOD samples, while providing high levels of certifiedand adversarial robustness on in-distribution samples. The average of all OODdetection metrics on CIFAR10/100 shows an increase of $sim 13 % / 5%$relative to previous approaches.", "output": "Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Graph neural network (GNN) models are increasingly being used for theclassification of electroencephalography (EEG) data. However, GNN-baseddiagnosis of neurological disorders, such as Alzheimer's disease (AD), remainsa relatively unexplored area of research. Previous studies have relied onfunctional connectivity methods to infer brain graph structures and used simpleGNN architectures for the diagnosis of AD. In this work, we propose a noveladaptive gated graph convolutional network (AGGCN) that can provide explainablepredictions. AGGCN adaptively learns graph structures by combiningconvolution-based node feature enhancement with a well-known correlation-basedmeasure of functional connectivity. Furthermore, the gated graph convolutioncan dynamically weigh the contribution of various spatial scales. The proposedmodel achieves high accuracy in both eyes-closed and eyes-open conditions,indicating the stability of learned representations. Finally, we demonstratethat the proposed AGGCN model generates consistent explanations of itspredictions that might be relevant for further study of AD-related alterationsof brain networks.", "output": "Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The performance of Large Language Models (LLMs) in reasoning tasks dependsheavily on prompt design, with Chain-of-Thought (CoT) and self-consistencybeing critical methods that enhance this ability. However, these methods do notfully exploit the answers generated by the LLM to guide subsequent responses.This paper proposes a new prompting method, named Progressive-Hint Prompting(PHP), that enables automatic multiple interactions between users and LLMs byusing previously generated answers as hints to progressively guide toward thecorrect answers. PHP is orthogonal to CoT and self-consistency, making it easyto combine with state-of-the-art techniques to further improve performance. Weconducted extensive and comprehensive experiments on seven benchmarks. Theresults show that PHP significantly improves accuracy while remaining highlyefficient. For instance, with text-davinci-003, we observed a 4.2% improvementon GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reductionin sample paths with self-consistency. With GPT-4 and PHP, we achievestate-of-the-art performances on SVAMP (89.1% -&gt; 91.9%), GSM8K (92% -&gt; 95.5%),AQuA (76.4% -&gt; 79.9%) and MATH (50.3% -&gt; 53.9%).", "output": "Progressive-Hint Prompting Improves Reasoning in Large Language Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "A framework to learn a multi-modal distribution is proposed, denoted as theConditional Quantum Generative Adversarial Network (C-qGAN). The neural networkstructure is strictly within a quantum circuit and, as a consequence, is shownto represent a more efficient state preparation procedure than current methods.This methodology has the potential to speed-up algorithms, such as Monte Carloanalysis. In particular, after demonstrating the effectiveness of the networkin the learning task, the technique is applied to price Asian optionderivatives, providing the foundation for further research on otherpath-dependent options.", "output": "Conditional Generative Models for Learning Stochastic Processes."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Turbulent fluctuations of the atmospheric refraction index, so-called opticalturbulence, can significantly distort propagating laser beams. Therefore,modeling the strength of these fluctuations ($C_n^2$) is highly relevant forthe successful development and deployment of future free-space opticalcommunication links. In this letter, we propose a physics-informed machinelearning (ML) methodology, $Pi$-ML, based on dimensional analysis and gradientboosting to estimate $C_n^2$. Through a systematic feature importance analysis,we identify the normalized variance of potential temperature as the dominatingfeature for predicting $C_n^2$. For statistical robustness, we train anensemble of models which yields high performance on the out-of-sample data of$R^2=0.958pm0.001$.", "output": "{\\Pi}-ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Image-based precision medicine aims to personalize treatment decisions basedon an individual's unique imaging features so as to improve their clinicaloutcome. Machine learning frameworks that integrate uncertainty estimation aspart of their treatment recommendations would be safer and more reliable.However, little work has been done in adapting uncertainty estimationtechniques and validation metrics for precision medicine. In this paper, we useBayesian deep learning for estimating the posterior distribution over factualand counterfactual outcomes on several treatments. This allows for estimatingthe uncertainty for each treatment option and for the individual treatmenteffects (ITE) between any two treatments. We train and evaluate this model topredict future new and enlarging T2 lesion counts on a large, multi-centerdataset of MR brain images of patients with multiple sclerosis, exposed toseveral treatments during randomized controlled trials. We evaluate thecorrelation of the uncertainty estimate with the factual error, and, given thelack of ground truth counterfactual outcomes, demonstrate how uncertainty forthe ITE prediction relates to bounds on the ITE error. Lastly, we demonstratehow knowledge of uncertainty could modify clinical decision-making to improveindividual patient and clinical trial outcomes.", "output": "Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Autonomous experimentation has emerged as an efficient approach to acceleratethe pace of materials discovery. Although instruments for autonomous synthesishave become popular in molecular and polymer science, solution processing ofhybrid materials and nanoparticles, examples of autonomous tools for physicalvapor deposition are scarce yet important for the semiconductor industry. Here,we report the design and implementation of an autonomous workflow for sputterdeposition of thin films with controlled composition, leveraging a highlyautomated sputtering reactor custom-controlled by Python, optical emissionspectroscopy (OES), and a Bayesian optimization algorithm. We modeled filmcomposition, measured by x-ray fluorescence, as a linear function of emissionlines monitored during the co-sputtering from elemental Zn and Ti targets inN$_2$ atmosphere. A Bayesian control algorithm, informed by OES, navigates thespace of sputtering power to fabricate films with user-defined composition, byminimizing the absolute error between desired and measured emission signals. Wevalidated our approach by autonomously fabricating Zn$_x$Ti$_{1-x}$N$_y$ filmswith deviations from the targeted cation composition within relative 3.5 %,even for 15 nm thin films, demonstrating that the proposed approach canreliably synthesize thin films with specific composition and minimal humaninterference. Moreover, the proposed method can be extended to more difficultsynthesis experiments where plasma intensity depends non-linearly on pressure,or the elemental sticking coefficients strongly depend on the substratetemperature.", "output": "Autonomous sputter synthesis of thin film nitrides with composition controlled by Bayesian optimization of optical plasma emission."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Random Search is one of the most widely-used method for HyperparameterOptimization, and is critical to the success of deep learning models. Despiteits astonishing performance, little non-heuristic theory has been developed todescribe the underlying working mechanism. This paper gives a theoreticalaccounting of Random Search. We introduce the concept of emph{scatteringdimension} that describes the landscape of the underlying function, andquantifies the performance of random search. We show that, when the environmentis noise-free, the output of random search converges to the optimal value inprobability at rate $ widetilde{mathcal{O}} left( left( frac{1}{T}right)^{ frac{1}{d_s} } right) $, where $ d_s ge 0 $ is the scatteringdimension of the underlying function. When the observed function values arecorrupted by bounded $iid$ noise, the output of random search converges to theoptimal value in probability at rate $ widetilde{mathcal{O}} left( left(frac{1}{T} right)^{ frac{1}{d_s + 1} } right) $. In addition, based on theprinciples of random search, we introduce an algorithm, called BLiN-MOS, forLipschitz bandits in doubling metric spaces that are also endowed with aprobability measure, and show that BLiN-MOS achieves a regret rate of order $widetilde{mathcal{O}} left( T^{ frac{d_z}{d_z + 1} } right) $, where $d_z$is the zooming dimension of the problem instance.", "output": "From Random Search to Bandit Learning in Metric Measure Spaces."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Forecasting irregularly sampled time series with missing values is a crucialtask for numerous real-world applications such as healthcare, astronomy, andclimate sciences. State-of-the-art approaches to this problem rely on OrdinaryDifferential Equations (ODEs) which are known to be slow and often requireadditional features to handle missing values. To address this issue, we proposea novel model using Graphs for Forecasting Irregularly Sampled Time Series withmissing values which we call GraFITi. GraFITi first converts the time series toa Sparsity Structure Graph which is a sparse bipartite graph, and thenreformulates the forecasting problem as the edge weight prediction task in thegraph. It uses the power of Graph Neural Networks to learn the graph andpredict the target edge weights. GraFITi has been tested on 3 real-world and 1synthetic irregularly sampled time series dataset with missing values andcompared with various state-of-the-art models. The experimental resultsdemonstrate that GraFITi improves the forecasting accuracy by up to 17% andreduces the run time up to 5 times compared to the state-of-the-art forecastingmodels.", "output": "Forecasting Irregularly Sampled Time Series using Graphs."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Neural networks (NN) have demonstrated remarkable capabilities in varioustasks, but their computation-intensive nature demands faster and moreenergy-efficient hardware implementations. Optics-based platforms, usingtechnologies such as silicon photonics and spatial light modulators, offerpromising avenues for achieving this goal. However, training multiple trainablelayers in tandem with these physical systems poses challenges, as they aredifficult to fully characterize and describe with differentiable functions,hindering the use of error backpropagation algorithm. The recently introducedForward-Forward Algorithm (FFA) eliminates the need for perfectcharacterization of the learning system and shows promise for efficienttraining with large numbers of programmable parameters. The FFA does notrequire backpropagating an error signal to update the weights, rather theweights are updated by only sending information in one direction. The localloss function for each set of trainable weights enables low-power analoghardware implementations without resorting to metaheuristic algorithms orreinforcement learning. In this paper, we present an experiment utilizingmultimode nonlinear wave propagation in an optical fiber demonstrating thefeasibility of the FFA approach using an optical system. The results show thatincorporating optical transforms in multilayer NN architectures trained withthe FFA, can lead to performance improvements, even with a relatively smallnumber of trainable weights. The proposed method offers a new path to thechallenge of training optical NNs and provides insights into leveragingphysical transformations for enhancing NN performance.", "output": "Forward-Forward Training of an Optical Neural Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Large pre-trained transformers are show-stealer in modern-day deep learning,and it becomes crucial to comprehend the parsimonious patterns that existwithin them as they grow in scale. With exploding parameter counts, LotteryTicket Hypothesis (LTH) and its variants, have lost their pragmatism insparsifying them due to high computation and memory bottleneck of repetitivetrain-prune-retrain routine of iterative magnitude pruning (IMP) which worsenswith increasing model size. This paper comprehensively studies induced sparsepatterns across multiple large pre-trained vision and language transformers. Wepropose the existence of -- essential sparsity defined with a sharp droppingpoint beyond which the performance declines much faster w.r.t the rise ofsparsity level, when we directly remove weights with the smallest magnitudes inone-shot without re-training. We also find essential sparsity to hold valid forN:M sparsity patterns as well as on modern-scale large language models(Vicuna-7B). We also present an intriguing emerging phenomenon of abruptsparsification during the pre-training of BERT, i.e., BERT suddenly becomesheavily sparse in pre-training after certain iterations. Moreover, ourobservations also indicate a counter-intuitive finding that BERT trained with alarger amount of pre-training data tends to have a better ability to condenseknowledge in comparatively relatively fewer parameters. Lastly, we investigatethe effect of the pre-training loss on essential sparsity and discover thatself-supervised learning (SSL) objectives trigger stronger emergentsparsification properties than supervised learning (SL). Our codes areavailable at url{", "output": "The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Hypernetworks, or hypernets in short, are neural networks that generateweights for another neural network, known as the target network. They haveemerged as a powerful deep learning technique that allows for greaterflexibility, adaptability, dynamism, faster training, information sharing, andmodel compression etc. Hypernets have shown promising results in a variety ofdeep learning problems, including continual learning, causal inference,transfer learning, weight pruning, uncertainty quantification, zero-shotlearning, natural language processing, and reinforcement learning etc. Despitetheir success across different problem settings, currently, there is no reviewavailable to inform the researchers about the developments and to help inutilizing hypernets. To fill this gap, we review the progress in hypernets. Wepresent an illustrative example to train deep neural networks using hypernetsand propose categorizing hypernets based on five design criteria as inputs,outputs, variability of inputs and outputs, and architecture of hypernets. Wealso review applications of hypernets across different deep learning problemsettings, followed by a discussion of general scenarios where hypernets can beeffectively employed. Finally, we discuss the challenges and future directionsthat remain under-explored in the field of hypernets. We believe thathypernetworks have the potential to revolutionize the field of deep learning.They offer a new way to design and train neural networks, and they have thepotential to improve the performance of deep learning models on a variety oftasks. Through this review, we aim to inspire further advancements in deeplearning through hypernetworks.", "output": "A Brief Review of Hypernetworks in Deep Learning."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper introduces FALL-E, a foley synthesis system and itstraining/inference strategies. The FALL-E model employs a cascaded approachcomprising low-resolution spectrogram generation, spectrogram super-resolution,and a vocoder. We trained every sound-related model from scratch using ourextensive datasets, and utilized a pre-trained language model. We conditionedthe model with dataset-specific texts, enabling it to learn sound quality andrecording environment based on text input. Moreover, we leveraged externallanguage models to improve text descriptions of our datasets and performedprompt engineering for quality, coherence, and diversity. FALL-E was evaluatedby an objective measure as well as listening tests in the DCASE 2023 challengeTask 7. The submission achieved the second place on average, while achievingthe best score for diversity, second place for audio quality, and third placefor class fitness.", "output": "FALL-E: A Foley Sound Synthesis Model and Strategies."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Promotions play a crucial role in e-commerce platforms, and various coststructures are employed to drive user engagement. This paper focuses onpromotions with response-dependent costs, where expenses are incurred only whena purchase is made. Such promotions include discounts and coupons. Whileexisting uplift model approaches aim to address this challenge, theseapproaches often necessitate training multiple models, like meta-learners, orencounter complications when estimating profit due to zero-inflated valuesstemming from non-converted individuals with zero cost and profit.To address these challenges, we introduce Incremental Profit per Conversion(IPC), a novel uplift measure of promotional campaigns' efficiency in uniteconomics. Through a proposed response transformation, we demonstrate that IPCrequires only converted data, its propensity, and a single model to beestimated. As a result, IPC resolves the issues mentioned above whilemitigating the noise typically associated with the class imbalance inconversion datasets and biases arising from the many-to-one mapping betweensearch and purchase data. Lastly, we validate the efficacy of our approach bypresenting results obtained from a synthetic simulation of a discount couponcampaign.", "output": "Incremental Profit per Conversion: a Response Transformation for Uplift Modeling in E-Commerce Promotions."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Reinforcement Learning (RL), bolstered by the expressive capabilities of DeepNeural Networks (DNNs) for function approximation, has demonstratedconsiderable success in numerous applications. However, its practicality inaddressing various real-world scenarios, characterized by diverse andunpredictable dynamics, noisy signals, and large state and action spaces,remains limited. This limitation stems from issues such as poor dataefficiency, limited generalization capabilities, a lack of safety guarantees,and the absence of interpretability, among other factors. To overcome thesechallenges and improve performance across these crucial metrics, one promisingavenue is to incorporate additional structural information about the probleminto the RL learning process. Various sub-fields of RL have proposed methodsfor incorporating such inductive biases. We amalgamate these diversemethodologies under a unified framework, shedding light on the role ofstructure in the learning problem, and classify these methods into distinctpatterns of incorporating structure. By leveraging this comprehensiveframework, we provide valuable insights into the challenges of structured RLand lay the groundwork for a design pattern perspective on RL research. Thisnovel perspective paves the way for future advancements and aids in developingmore effective and efficient RL algorithms that can potentially handlereal-world scenarios better.", "output": "Structure in Reinforcement Learning: A Survey and Open Problems."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "The connection between Residual Neural Networks (ResNets) and continuous-timecontrol systems (known as NeurODEs) has led to a mathematical analysis ofneural networks which has provided interesting results of both theoretical andpractical significance. However, by construction, NeurODEs have been limited todescribing constant-width layers, making them unsuitable for modeling deeplearning architectures with layers of variable width. In this paper, we proposea continuous-time Autoencoder, which we call AutoencODE, based on amodification of the controlled field that drives the dynamics. This adaptationenables the extension of the mean-field control framework originally devisedfor conventional NeurODEs. In this setting, we tackle the case of low Tikhonovregularization, resulting in potentially non-convex cost landscapes. While theglobal results obtained for high Tikhonov regularization may not hold globally,we show that many of them can be recovered in regions where the loss functionis locally convex. Inspired by our theoretical findings, we develop a trainingmethod tailored to this specific type of Autoencoders with residualconnections, and we validate our approach through numerical experimentsconducted on various examples.", "output": "From NeurODEs to AutoencODEs: a mean-field control framework for width-varying Neural Networks."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Unsupervised domain adaptation (DA) with the aid of pseudo labelingtechniques has emerged as a crucial approach for domain-adaptive 3D objectdetection. While effective, existing DA methods suffer from a substantial dropin performance when applied to a multi-class training setting, due to theco-existence of low-quality pseudo labels and class imbalance issues. In thispaper, we address this challenge by proposing a novel ReDB framework tailoredfor learning to detect all classes at once. Our approach produces Reliable,Diverse, and class-Balanced pseudo 3D boxes to iteratively guide theself-training on a distributionally different target domain. To alleviatedisruptions caused by the environmental discrepancy (e.g., beam numbers), theproposed cross-domain examination (CDE) assesses the correctness of pseudolabels by copy-pasting target instances into a source environment and measuringthe prediction consistency. To reduce computational overhead and mitigate theobject shift (e.g., scales and point densities), we design an overlapped boxescounting (OBC) metric that allows to uniformly downsample pseudo-labeledobjects across different geometric characteristics. To confront the issue ofinter-class imbalance, we progressively augment the target point clouds with aclass-balanced set of pseudo-labeled target instances and source objects, whichboosts recognition accuracies on both frequently appearing and rare classes.Experimental results on three benchmark datasets using both voxel-based (i.e.,SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that ourproposed ReDB approach outperforms existing 3D domain adaptation methods by alarge margin, improving 23.15% mAP on the nuScenes $rightarrow$ KITTI task.The code is available at ", "output": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper details the challenges in applying two computer vision systems, anEfficientDET supervised learning model and the unsupervised RX spectralclassifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search andrescue (WSAR) effort in Japan and identifies 3 directions for future research.There have been at least 19 proposed approaches and 3 datasets aimed atlocating missing persons in drone imagery, but only 3 approaches (2unsupervised and 1 of an unknown structure) are referenced in the literature ashaving been used in an actual WSAR operation. Of these proposed approaches, theEfficientDET architecture and the unsupervised spectral RX classifier wereselected as the most appropriate for this setting. The EfficientDET model wasapplied to the HERIDAL dataset and despite achieving performance that isstatistically equivalent to the state-of-the-art, the model fails to translateto the real world in terms of false positives (e.g., identifying tree limbs androcks as people), and false negatives (e.g., failing to identify members of thesearch team). The poor results in practice for algorithms that showed goodresults on datasets suggest 3 areas of future research: more realistic datasetsfor wilderness SAR, computer vision models that are capable of seamlesslyhandling the variety of imagery that can be collected during actual WSARoperations, and better alignment on performance measures.", "output": "Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Recent research in language-guided visual navigation has demonstrated asignificant demand for the diversity of traversable environments and thequantity of supervision for training generalizable agents. To tackle the commondata scarcity issue in existing vision-and-language navigation datasets, wepropose an effective paradigm for generating large-scale data for learning,which applies 1200+ photo-realistic environments from HM3D and Gibson datasetsand synthesizes 4.9 million instruction trajectory pairs using fully-accessibleresources on the web. Importantly, we investigate the influence of eachcomponent in this paradigm on the agent's performance and study how toadequately apply the augmented data to pre-train and fine-tune an agent. Thanksto our large-scale dataset, the performance of an existing agent can be pushedup (+11% absolute with regard to previous SoTA) to a significantly new best of80% single-run success rate on the R2R test split by simple imitation learning.The long-lasting generalization gap between navigating in seen and unseenenvironments is also reduced to less than 1% (versus 8% in the previous bestmethod). Moreover, our paradigm also facilitates different models to achievenew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuousenvironments.", "output": "Scaling Data Generation in Vision-and-Language Navigation."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Deep Neural Networks (DNNs) for 3D point cloud recognition are vulnerable toadversarial examples, threatening their practical deployment. Despite the manyresearch endeavors have been made to tackle this issue in recent years, thediversity of adversarial examples on 3D point clouds makes them morechallenging to defend against than those on 2D images. For examples, attackerscan generate adversarial examples by adding, shifting, or removing points.Consequently, existing defense strategies are hard to counter unseen pointcloud adversarial examples. In this paper, we first establish a comprehensive,and rigorous point cloud adversarial robustness benchmark to evaluateadversarial robustness, which can provide a detailed understanding of theeffects of the defense and attack methods. We then collect existing defensetricks in point cloud adversarial defenses and then perform extensive andsystematic experiments to identify an effective combination of these tricks.Furthermore, we propose a hybrid training augmentation methods that considervarious types of point cloud adversarial examples to adversarial training,significantly improving the adversarial robustness. By combining these tricks,we construct a more robust defense framework achieving an average accuracy of83.45% against various attacks, demonstrating its capability to enablingrobust learners. Our codebase are open-sourced on:url{", "output": "Benchmarking and Analyzing Robust Point Cloud Recognition: Bag of Tricks for Defending Adversarial Examples."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Ocean modeling is a powerful tool for simulating the physical, chemical, andbiological processes of the ocean, which is the foundation for marine scienceresearch and operational oceanography. Modern numerical ocean modeling mainlyconsists of governing equations and numerical algorithms. Nonlinearinstability, computational expense, low reusability efficiency and highcoupling costs have gradually become the main bottlenecks for the furtherdevelopment of numerical ocean modeling. Recently, artificialintelligence-based modeling in scientific computing has shown revolutionarypotential for digital twins and scientific simulations, but the bottlenecks ofnumerical ocean modeling have not been further solved. Here, we presentAI-GOMS, a large AI-driven global ocean modeling system, for accurate andefficient global ocean daily prediction. AI-GOMS consists of a backbone modelwith the Fourier-based Masked Autoencoder structure for basic ocean variableprediction and lightweight fine-tuning models incorporating regionaldownscaling, wave decoding, and biochemistry coupling modules. AI-GOMS hasachieved the best performance in 30 days of prediction for the global oceanbasic variables with 15 depth layers at 1/4{deg} spatial resolution. Beyondthe good performance in statistical metrics, AI-GOMS realizes the simulation ofmesoscale eddies in the Kuroshio region at 1/12{deg} spatial resolution andocean stratification in the tropical Pacific Ocean. AI-GOMS provides a newbackbone-downstream paradigm for Earth system modeling, which makes the systemtransferable, scalable and reusable.", "output": "AI-GOMS: Large AI-Driven Global Ocean Modeling System."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Nucleus image segmentation is a crucial step in the analysis, pathologicaldiagnosis, and classification, which heavily relies on the quality of nucleussegmentation. However, the complexity of issues such as variations in nucleussize, blurred nucleus contours, uneven staining, cell clustering, andoverlapping cells poses significant challenges. Current methods for nucleussegmentation primarily rely on nuclear morphology or contour-based approaches.Nuclear morphology-based methods exhibit limited generalization ability andstruggle to effectively predict irregular-shaped nuclei, while contour-basedextraction methods face challenges in accurately segmenting overlapping nuclei.To address the aforementioned issues, we propose a dual-branch network usinghybrid attention based residual U-blocks for nucleus instance segmentation. Thenetwork simultaneously predicts target information and target contours.Additionally, we introduce a post-processing method that combines the targetinformation and target contours to distinguish overlapping nuclei and generatean instance segmentation image. Within the network, we propose a context fusionblock (CF-block) that effectively extracts and merges contextual informationfrom the network. Extensive quantitative evaluations are conducted to assessthe performance of our method. Experimental results demonstrate the superiorperformance of the proposed method compared to state-of-the-art approaches onthe BNS, MoNuSeg, CoNSeg, and CPM-17 datasets.", "output": "Enhancing Nucleus Segmentation with HARU-Net: A Hybrid Attention Based Residual U-Blocks Network."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "This paper asks whether current self-supervised learning methods, ifsufficiently scaled up, would be able to reach human-level visual objectrecognition capabilities with the same type and amount of visual experiencehumans learn from. Previous work on this question only considered the scalingof data size. Here, we consider the simultaneous scaling of data size, modelsize, and image resolution. We perform a scaling experiment with visiontransformers up to 633M parameters in size (ViT-H/14) trained with up to 5Khours of human-like video data (long, continuous, mostly egocentric videos)with image resolutions of up to 476x476 pixels. The efficiency of maskedautoencoders (MAEs) as a self-supervised learning algorithm makes it possibleto run this scaling experiment on an unassuming academic budget. We find thatit is feasible to reach human-level object recognition capacity at sub-humanscales of model size, data size, and image size, if these factors are scaled upsimultaneously. To give a concrete example, we estimate that a 2.5B parameterViT model trained with 20K hours (2.3 years) of human-like video data with aspatial resolution of 952x952 pixels should be able to reach roughlyhuman-level accuracy on ImageNet. Human-level competence is thus achievable fora fundamental perceptual capability from human-like perceptual experience(human-like in both amount and type) with extremely generic learning algorithmsand architectures and without any substantive inductive biases.", "output": "Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Causal inference is a crucial goal of science, enabling researchers to arriveat meaningful conclusions regarding the predictions of hypotheticalinterventions using observational data. Path models, Structural Equation Models(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means tounambiguously specify assumptions regarding the causal structure underlying aphenomenon. Unlike DAGs, which make very few assumptions about the functionaland parametric form, SEM assumes linearity. This can result in functionalmisspecification which prevents researchers from undertaking reliable effectsize estimation. In contrast, we propose Super Learner Equation Modeling, apath modeling technique integrating machine learning Super Learner ensembles.We empirically demonstrate its ability to provide consistent and unbiasedestimates of causal effects, its competitive performance for linear models whencompared with SEM, and highlight its superiority over SEM when dealing withnon-linear relationships. We provide open-source code, and a tutorial notebookwith example usage, accentuating the easy-to-use nature of the method.", "output": "SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Machine learning (ML)-based malware detection systems are becomingincreasingly important as malware threats increase and get more sophisticated.PDF files are often used as vectors for phishing attacks because they arewidely regarded as trustworthy data resources, and are accessible acrossdifferent platforms. Therefore, researchers have developed many different PDFmalware detection methods. Performance in detecting PDF malware is greatlyinfluenced by feature selection. In this research, we propose a small featuresset that don't require too much domain knowledge of the PDF file. We evaluateproposed features with six different machine learning models. We report thebest accuracy of 99.75% when using Random Forest model. Our proposed featureset, which consists of just 12 features, is one of the most conciseness in thefield of PDF malware detection. Despite its modest size, we obtain comparableresults to state-of-the-art that employ a much larger set of features.", "output": "A Feature Set of Small Size for the PDF Malware Detection."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "With the increasing volume of astronomical data generated by modern surveytelescopes, automated pipelines and machine learning techniques have becomecrucial for analyzing and extracting knowledge from these datasets. Anomalydetection, i.e. the task of identifying irregular or unexpected patterns in thedata, is a complex challenge in astronomy. In this paper, we proposeMulti-Class Deep Support Vector Data Description (MCDSVDD), an extension of thestate-of-the-art anomaly detection algorithm One-Class Deep SVDD, specificallydesigned to handle different inlier categories with distinct datadistributions. MCDSVDD uses a neural network to map the data into hyperspheres,where each hypersphere represents a specific inlier category. The distance ofeach sample from the centers of these hyperspheres determines the anomalyscore. We evaluate the effectiveness of MCDSVDD by comparing its performancewith several anomaly detection algorithms on a large dataset of astronomicallight-curves obtained from the Zwicky Transient Facility. Our resultsdemonstrate the efficacy of MCDSVDD in detecting anomalous sources whileleveraging the presence of different inlier categories. The code and the dataneeded to reproduce our results are publicly available at", "output": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories."}, {"instruction": "If you are an expert in writing papers, please generate a good paper title for this paper based on other authors' descriptions of their abstracts.", "input": "Lesion segmentation of ultrasound medical images based on deep learningtechniques is a widely used method for diagnosing diseases. Although there is alarge amount of ultrasound image data in medical centers and other places,labeled ultrasound datasets are a scarce resource, and it is likely that nodatasets are available for new tissues/organs. Transfer learning provides thepossibility to solve this problem, but there are too many features in naturalimages that are not related to the target domain. As a source domain, redundantfeatures that are not conducive to the task will be extracted. Migrationbetween ultrasound images can avoid this problem, but there are few types ofpublic datasets, and it is difficult to find sufficiently similar sourcedomains. Compared with natural images, ultrasound images have less information,and there are fewer transferable features between different ultrasound images,which may cause negative transfer. To this end, a multi-source adversarialtransfer learning network for ultrasound image segmentation is proposed.Specifically, to address the lack of annotations, the idea of adversarialtransfer learning is used to adaptively extract common features between acertain pair of source and target domains, which provides the possibility toutilize unlabeled ultrasound data. To alleviate the lack of knowledge in asingle source domain, multi-source transfer learning is adopted to fuseknowledge from multiple source domains. In order to ensure the effectiveness ofthe fusion and maximize the use of precious data, a multi-source domainindependent strategy is also proposed to improve the estimation of the targetdomain data distribution, which further increases the learning ability of themulti-source adversarial migration learning network in multiple domains.", "output": "Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity."}]